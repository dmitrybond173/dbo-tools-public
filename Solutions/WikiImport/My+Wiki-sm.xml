<mediawiki xmlns="http://www.mediawiki.org/xml/export-0.3/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.mediawiki.org/xml/export-0.3/ http://www.mediawiki.org/xml/export-0.3.xsd" version="0.3" xml:lang="en">
  <siteinfo>
    <sitename>BTO Wiki</sitename>
    <base>http://btowiki.jda.corp.local/index.php/Main_Page</base>
    <generator>MediaWiki 1.15.5</generator>
    <case>first-letter</case>
    <namespaces>
      <namespace key="-2">Media</namespace>
      <namespace key="-1">Special</namespace>
      <namespace key="0" />
      <namespace key="1">Talk</namespace>
      <namespace key="2">User</namespace>
      <namespace key="3">User talk</namespace>
      <namespace key="4">BTO Wiki</namespace>
      <namespace key="5">BTO Wiki talk</namespace>
      <namespace key="6">File</namespace>
      <namespace key="7">File talk</namespace>
      <namespace key="8">MediaWiki</namespace>
      <namespace key="9">MediaWiki talk</namespace>
      <namespace key="10">Template</namespace>
      <namespace key="11">Template talk</namespace>
      <namespace key="12">Help</namespace>
      <namespace key="13">Help talk</namespace>
      <namespace key="14">Category</namespace>
      <namespace key="15">Category talk</namespace>
    </namespaces>
  </siteinfo>
  <page>
    <title>$OCSSTRAN.LOG</title>
    <id>317</id>
    <revision>
      <id>1422</id>
      <timestamp>2010-05-05T13:22:13Z</timestamp>
      <contributor>
        <username>RP-NCO</username>
        <id>6</id>
      </contributor>
      <minor/>
      <text xml:space="preserve">[[Category:Order Management]][[Category:LogFiles]]

'''No valid drawing versions:'''
&lt;pre&gt;
20100428,213859 ***** Request={M=X37; P=D055; O=01NQR4; S=; T=OCS_TRANSLATE; Fn=; L=US; RT=2010-04-28-12.36.16.077001; U=norgaard; E=
 * Task.Options: { Action=0; OrderType=0; IfMultipleDrw:2; Anchor:Current; SaveBomDiff=0; DebugLevel=5 }
 Searching for ORDER (01NQR4/2010-04-28-12.36.16.077001)...
 * Order found: Seq=0; CustNo=; CallOff=2010-04-28-12.36.15.000000; Rev=2010-04-28-12.36.15.937326
 Anchor value: 2010-04-28-21.38.59.664000
 Searching for drawing...
  + Drawing [13333527/OPEL]
  + Drawing [13334335/OPEL]
  + Drawing [13337869/OPEL]
 * 3 drawing headers loaded
 ! ERROR(OcsError): Fail to load active drawings list from table OCSDRWVS. SqlCode: 0
&lt;/pre&gt;

'''No usable drawing keys:'''
&lt;pre&gt;
20100428,214603 ***** Request={M=X37; P=D055; O=01NQR4; S=; T=OCS_TRANSLATE; Fn=; L=US; RT=2010-04-28-12.36.16.077001; U=norgaard; E=
 * Task.Options: { Action=0; OrderType=0; IfMultipleDrw:2; Anchor:Current; SaveBomDiff=0; DebugLevel=5 }
 Searching for ORDER (01NQR4/2010-04-28-12.36.16.077001)...
 * Order found: Seq=0; CustNo=; CallOff=2010-04-28-12.36.15.000000; Rev=2010-04-28-12.36.15.937326
 Anchor value: 2010-04-28-21.46.03.725000
 Searching for drawing...
  + Drawing [13333527/OPEL]
  + Drawing [13334335/OPEL]
  + Drawing [13337869/OPEL]
 * 3 drawing headers loaded
  + Drawing Version [13337869/#1]
 * 1 active drawing versions loaded
 ! ERROR(OcsError): Fail to load drawing keys from table OCSDRWCF. SqlCode: 0
&lt;/pre&gt;


'''No active rules:'''
&lt;pre&gt;
20100428,214813 ***** Request={M=X37; P=D055; O=01NQR4; S=; T=OCS_TRANSLATE; Fn=; L=US; RT=2010-04-28-12.36.16.077001; U=norgaard; E=
 * Task.Options: { Action=0; OrderType=0; IfMultipleDrw:2; Anchor:Current; SaveBomDiff=0; DebugLevel=5 }
 Searching for ORDER (01NQR4/2010-04-28-12.36.16.077001)...
 * Order found: Seq=0; CustNo=; CallOff=2010-04-28-12.36.15.000000; Rev=2010-04-28-12.36.15.937326
 Anchor value: 2010-04-28-21.48.13.370000
 Searching for drawing...
  + Drawing [13333527/OPEL]
  + Drawing [13334335/OPEL]
  + Drawing [13337869/OPEL]
 * 3 drawing headers loaded
  + Drawing Version [13337869/#1]
 * 1 active drawing versions loaded
 * 1 drawing key records loaded. 1 drawing keys found.
  Loading OCBOM...
  Loading ORDERSUB...
  * 1 ORDERSUB records loaded
  * 133 OCBOM records loaded
  * 133 records collected in references list
   * key # 1 - comparing OCBOM.OPTCODE[=01B] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=0GA69] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=1AC] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=2CP] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=3CG] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=4AB] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=6X1] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=6Y4] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=7X1] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=8X2] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=9X2] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=A23] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=A45] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=A51] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=A69] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=A6D] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=A70] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=A90] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=AEF] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=AER] vs [AER]: Match.
   * key # 1 - comparing OCBOM.OPTCODE[=AFA] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=AG1] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=AHS] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=AKN] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=AKW] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=APG] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=APH] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=ASV] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=ATG] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=AXG] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=AXJ] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=AY0] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=AY9] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=B9K] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=BAH] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=C2B] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=C32] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=C59] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=C95] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=C99] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=CE1] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=CE4] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=CJ2] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=CT3] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=D61] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=D7A] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=DA1] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=DD8] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=DE8] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=DH6] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=DK6] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=DP6] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=DT4] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=DWH] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=EA1] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=EA2] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=EPY] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=F45] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=F46] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=FBE] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=FW4] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=FX3] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=G96] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=GEV] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=GNA] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=GNE] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=J61] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=J71] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=K13] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=K34] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=K3U] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=KA1] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=KB5] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=KD4] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=KG9] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=KI7] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=KRH] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=KRJ] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=LBS] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=LHD] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=M53] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=MDE] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=MM3] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=MR6] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=N34] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=N37] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=NC0] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=NE9] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=NV7] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=OAR] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=OHD] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=PEM] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=Q56] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=QKD] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=RUE] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=T61] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=T74] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=T79] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=T96] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=TQ5] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=TR0] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=TR7] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=TSP] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=TSQ] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=TT2] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=TTW] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=U18] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=U65] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=UD5] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=UDC] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=UDK] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=UH1] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=ULS] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=UPH] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=URC] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=US3] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=USR] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=UXX] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=V83] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=VK8] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=VRL] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=VY7] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=W1Y] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=W4Y] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=W7Z] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=WFF] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=WGC] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=WRA] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=WRB] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=WTR] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=XJ2] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=XL8] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=Z1Y] vs [AER]: Not-Match!
  1 matched records left in references list
   [BtoOcBom]=(Match=Yes){OC;                      ;AER;;1.000000;}
  * drawing [13337869] is ok to use.
 ! drawing selection finished. 1 items in list.
 ! Selected drawing version is [13337869/1]
  * Drw[13337869/1]: 30 build rules loaded.
  * Drw[13337869/1]: 30 rule parts loaded.
  * Options in [OC]: 01B;0GA69;1AC;2CP;3CG;4AB;6X1;6Y4;7X1;8X2;9X2;A23;A45;A51;A69;A6D;A70;A90;AEF;AER;AFA;AG1;AHS;AKN;AKW;APG;APH;ASV;ATG;AXG;AXJ;AY0;AY9;B9K;BAH;C2B;C32;C59;C95;C99;CE1;CE4;CJ2;CT3;D61;D7A;DA1;DD8;DE8;DH6;DK6;DP6;DT4;DWH;EA1;EA2;EPY;F45;F46;FBE;FW4;FX3;G96;GEV;GNA;GNE;J61;J71;K13;K34;K3U;KA1;KB5;KD4;KG9;KI7;KRH;KRJ;LBS;LHD;M53;MDE;MM3;MR6;N34;N37;NC0;NE9;NV7;OAR;OHD;PEM;Q56;QKD;RUE;T61;T74;T79;T96;TQ5;TR0;TR7;TSP;TSQ;TT2;TTW;U18;U65;UD5;UDC;UDK;UH1;ULS;UPH;URC;US3;USR;UXX;V83;VK8;VRL;VY7;W1Y;W4Y;W7Z;WFF;WGC;WRA;WRB;WTR;XJ2;XL8;Z1Y;
  * Full options list: 01B;0GA69;1AC;2CP;3CG;4AB;6X1;6Y4;7X1;8X2;9X2;A23;A45;A51;A69;A6D;A70;A90;AEF;AER;AFA;AG1;AHS;AKN;AKW;APG;APH;ASV;ATG;AXG;AXJ;AY0;AY9;B9K;BAH;C2B;C32;C59;C95;C99;CE1;CE4;CJ2;CT3;D61;D7A;DA1;DD8;DE8;DH6;DK6;DP6;DT4;DWH;EA1;EA2;EPY;F45;F46;FBE;FW4;FX3;G96;GEV;GNA;GNE;J61;J71;K13;K34;K3U;KA1;KB5;KD4;KG9;KI7;KRH;KRJ;LBS;LHD;M53;MDE;MM3;MR6;N34;N37;NC0;NE9;NV7;OAR;OHD;PEM;Q56;QKD;RUE;T61;T74;T79;T96;TQ5;TR0;TR7;TSP;TSQ;TT2;TTW;U18;U65;UD5;UDC;UDK;UH1;ULS;UPH;URC;US3;USR;UXX;V83;VK8;VRL;VY7;W1Y;W4Y;W7Z;WFF;WGC;WRA;WRB;WTR;XJ2;XL8;Z1Y;
 --- 30 rules to process...
  - Skip Rule {/1}: as non-active (1)
  - Skip Rule {/2}: as non-active (1)
  - Skip Rule {/3}: as non-active (1)
  - Skip Rule {/4}: as non-active (1)
  - Skip Rule {/5}: as non-active (1)
  - Skip Rule {/6}: as non-active (1)
  - Skip Rule {/7}: as non-active (1)
  - Skip Rule {/8}: as non-active (1)
  - Skip Rule {/9}: as non-active (1)
  - Skip Rule {/10}: as non-active (1)
  - Skip Rule {/11}: as non-active (1)
  - Skip Rule {/12}: as non-active (1)
  - Skip Rule {/13}: as non-active (1)
  - Skip Rule {/14}: as non-active (1)
  - Skip Rule {/15}: as non-active (1)
  - Skip Rule {/16}: as non-active (1)
  - Skip Rule {/17}: as non-active (1)
  - Skip Rule {/18}: as non-active (1)
  - Skip Rule {/19}: as non-active (1)
  - Skip Rule {/20}: as non-active (1)
  - Skip Rule {/21}: as non-active (1)
  - Skip Rule {/22}: as non-active (1)
  - Skip Rule {/23}: as non-active (1)
  - Skip Rule {/24}: as non-active (1)
  - Skip Rule {/25}: as non-active (1)
  - Skip Rule {/26}: as non-active (1)
  - Skip Rule {/27}: as non-active (1)
  - Skip Rule {/28}: as non-active (1)
  - Skip Rule {/29}: as non-active (1)
  - Skip Rule {/30}: as non-active (1)
 ! Filling materials info...
 ! Changes in materials list detected! [0000-00-00-00.00.00.000000] vs [2010-06-03-00.00.00.000000]
 ! Loading materials...
  13452 materials found. Sqlcode: 0
 * Sorting part refs...
 ! ERROR(OcsError): No build rules met for order 01NQR4/2010-04-28-12.36.16.077001 in drawing 13337869/#1
  * cast &quot;NRUL&quot;
&lt;/pre&gt;


'''Successfull translation:'''
&lt;pre&gt;
20100428,215507 ***** Request={M=X37; P=D055; O=01NQR4; S=; T=OCS_TRANSLATE; Fn=; L=US; RT=2010-04-28-12.36.16.077001; U=norgaard; E=
 * Task.Options: { Action=0; OrderType=0; IfMultipleDrw:2; Anchor:Current; SaveBomDiff=0; DebugLevel=5 }
 Searching for ORDER (01NQR4/2010-04-28-12.36.16.077001)...
 * Order found: Seq=0; CustNo=; CallOff=2010-04-28-12.36.15.000000; Rev=2010-04-28-12.36.15.937326
 Anchor value: 2010-04-28-21.55.07.320000
 Searching for drawing...
  + Drawing [13333527/OPEL]
  + Drawing [13334335/OPEL]
  + Drawing [13337869/OPEL]
 * 3 drawing headers loaded
  + Drawing Version [13337869/#1]
 * 1 active drawing versions loaded
 * 1 drawing key records loaded. 1 drawing keys found.
  Loading OCBOM...
  Loading ORDERSUB...
  * 1 ORDERSUB records loaded
  * 133 OCBOM records loaded
  * 133 records collected in references list
   * key # 1 - comparing OCBOM.OPTCODE[=01B] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=0GA69] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=1AC] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=2CP] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=3CG] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=4AB] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=6X1] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=6Y4] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=7X1] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=8X2] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=9X2] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=A23] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=A45] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=A51] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=A69] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=A6D] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=A70] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=A90] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=AEF] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=AER] vs [AER]: Match.
   * key # 1 - comparing OCBOM.OPTCODE[=AFA] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=AG1] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=AHS] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=AKN] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=AKW] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=APG] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=APH] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=ASV] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=ATG] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=AXG] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=AXJ] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=AY0] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=AY9] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=B9K] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=BAH] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=C2B] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=C32] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=C59] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=C95] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=C99] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=CE1] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=CE4] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=CJ2] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=CT3] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=D61] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=D7A] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=DA1] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=DD8] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=DE8] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=DH6] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=DK6] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=DP6] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=DT4] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=DWH] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=EA1] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=EA2] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=EPY] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=F45] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=F46] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=FBE] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=FW4] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=FX3] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=G96] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=GEV] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=GNA] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=GNE] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=J61] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=J71] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=K13] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=K34] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=K3U] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=KA1] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=KB5] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=KD4] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=KG9] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=KI7] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=KRH] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=KRJ] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=LBS] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=LHD] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=M53] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=MDE] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=MM3] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=MR6] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=N34] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=N37] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=NC0] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=NE9] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=NV7] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=OAR] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=OHD] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=PEM] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=Q56] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=QKD] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=RUE] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=T61] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=T74] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=T79] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=T96] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=TQ5] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=TR0] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=TR7] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=TSP] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=TSQ] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=TT2] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=TTW] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=U18] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=U65] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=UD5] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=UDC] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=UDK] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=UH1] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=ULS] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=UPH] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=URC] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=US3] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=USR] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=UXX] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=V83] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=VK8] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=VRL] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=VY7] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=W1Y] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=W4Y] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=W7Z] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=WFF] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=WGC] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=WRA] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=WRB] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=WTR] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=XJ2] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=XL8] vs [AER]: Not-Match!
   * key # 1 - comparing OCBOM.OPTCODE[=Z1Y] vs [AER]: Not-Match!
  1 matched records left in references list
   [BtoOcBom]=(Match=Yes){OC;                      ;AER;;1.000000;}
  * drawing [13337869] is ok to use.
 ! drawing selection finished. 1 items in list.
 ! Selected drawing version is [13337869/1]
  * Drw[13337869/1]: 30 build rules loaded.
  * Drw[13337869/1]: 30 rule parts loaded.
  * Options in [OC]: 01B;0GA69;1AC;2CP;3CG;4AB;6X1;6Y4;7X1;8X2;9X2;A23;A45;A51;A69;A6D;A70;A90;AEF;AER;AFA;AG1;AHS;AKN;AKW;APG;APH;ASV;ATG;AXG;AXJ;AY0;AY9;B9K;BAH;C2B;C32;C59;C95;C99;CE1;CE4;CJ2;CT3;D61;D7A;DA1;DD8;DE8;DH6;DK6;DP6;DT4;DWH;EA1;EA2;EPY;F45;F46;FBE;FW4;FX3;G96;GEV;GNA;GNE;J61;J71;K13;K34;K3U;KA1;KB5;KD4;KG9;KI7;KRH;KRJ;LBS;LHD;M53;MDE;MM3;MR6;N34;N37;NC0;NE9;NV7;OAR;OHD;PEM;Q56;QKD;RUE;T61;T74;T79;T96;TQ5;TR0;TR7;TSP;TSQ;TT2;TTW;U18;U65;UD5;UDC;UDK;UH1;ULS;UPH;URC;US3;USR;UXX;V83;VK8;VRL;VY7;W1Y;W4Y;W7Z;WFF;WGC;WRA;WRB;WTR;XJ2;XL8;Z1Y;
  * Full options list: 01B;0GA69;1AC;2CP;3CG;4AB;6X1;6Y4;7X1;8X2;9X2;A23;A45;A51;A69;A6D;A70;A90;AEF;AER;AFA;AG1;AHS;AKN;AKW;APG;APH;ASV;ATG;AXG;AXJ;AY0;AY9;B9K;BAH;C2B;C32;C59;C95;C99;CE1;CE4;CJ2;CT3;D61;D7A;DA1;DD8;DE8;DH6;DK6;DP6;DT4;DWH;EA1;EA2;EPY;F45;F46;FBE;FW4;FX3;G96;GEV;GNA;GNE;J61;J71;K13;K34;K3U;KA1;KB5;KD4;KG9;KI7;KRH;KRJ;LBS;LHD;M53;MDE;MM3;MR6;N34;N37;NC0;NE9;NV7;OAR;OHD;PEM;Q56;QKD;RUE;T61;T74;T79;T96;TQ5;TR0;TR7;TSP;TSQ;TT2;TTW;U18;U65;UD5;UDC;UDK;UH1;ULS;UPH;URC;US3;USR;UXX;V83;VK8;VRL;VY7;W1Y;W4Y;W7Z;WFF;WGC;WRA;WRB;WTR;XJ2;XL8;Z1Y;
 --- 30 rules to process...
 =====&lt;&lt;[ BuildID:  ]&gt;&gt;===== 
  * Rule {/1}: Not-Match		(-F45)
  * Rule {/2}: Match		(&amp;F45)
   + Add Part(13332724, qty:1.000000)
  * Rule {/3}: Match		(&amp;LLU#&amp;2H0#&amp;LDK#&amp;LHU#&amp;LBR#&amp;LBS#&amp;LBY#&amp;LBQ)
   + Add Part(13332725, qty:1.000000)
  * Rule {/4}: Match		(&amp;LBW#&amp;LAU#&amp;LDE)
   + Add Part(13332726, qty:1.000000)
  * Rule {/5}: Match		(&amp;LBR#&amp;LBS#&amp;LBY#&amp;LBQ)
   + Add Part(13332727, qty:1.000000)
  * Rule {/6}: Match		(&amp;LDE#&amp;2H0#&amp;LLU)
   + Add Part(13332728, qty:1.000000)
  * Rule {/7}: Match		(&amp;LBW#&amp;LAU#&amp;LHU#&amp;LDK)
   + Add Part(13332729, qty:1.000000)
  * Rule {/8}: Match		(&amp;0GA35#&amp;0GA68)
   + Add Part(13332730, qty:1.000000)
  * Rule {/9}: Match		(&amp;0GA69)
   + Add Part(13332731, qty:1.000000)
  * Rule {/10}: Match		(&amp;CE4)
   + Add Part(13332732, qty:1.000000)
  * Rule {/11}: Match		(&amp;LBW#&amp;LAU#&amp;LHU#&amp;LDK#&amp;LBR#&amp;LBS#&amp;LBY#&amp;LBQ)
   + Add Part(13332733, qty:1.000000)
  * Rule {/12}: Match		(&amp;LBW#&amp;LAU#&amp;LHU#&amp;LDK#&amp;LDE#&amp;2H0#&amp;LLU)
   + Add Part(13332734, qty:1.000000)
  * Rule {/13}: Not-Match		(&amp;KU1)
  * Rule {/14}: Match		(&amp;LBW#&amp;LAU#&amp;F45)
   + Add Part(13332736, qty:1.000000)
  * Rule {/15}: Match		(&amp;0GA35#&amp;0GA68#&amp;0GA69)
   + Add Part(13332737, qty:1.000000)
  * Rule {/16}: Match		(&amp;UDP#&amp;UD5)
   + Add Part(13332738, qty:1.000000)
  * Rule {/17}: Match		(&amp;NV7#&amp;NXC)
   + Add Part(13332739, qty:1.000000)
  * Rule {/18}: Match		(&amp;NV7#&amp;NXC#&amp;UDP#&amp;UD5#&amp;KU1#&amp;F45)
   + Add Part(13332740, qty:1.000000)
  * Rule {/19}: Match		(&amp;T96)
   + Add Part(13332741, qty:1.000000)
  * Rule {/20}: Match		(&amp;TT2)
   + Add Part(13332742, qty:1.000000)
  * Rule {/21}: Not-Match		(&amp;TT4)
  * Rule {/22}: Not-Match		(&amp;TT2-T96)
  * Rule {/23}: Match		(&amp;TT4#&amp;T96)
   + Add Part(13332745, qty:1.000000)
  * Rule {/24}: Match		(&amp;UDC#&amp;CE4)
   + Add Part(13332746, qty:1.000000)
  * Rule {/25}: Not-Match		(&amp;UDP)
  * Rule {/26}: Not-Match		(&amp;UTR)
  * Rule {/27}: Not-Match		(&amp;UTV)
  * Rule {/28}: Match		(&amp;LLU#&amp;2H0)
   + Add Part(13332752, qty:1.000000)
  * Rule {/29}: Not-Match		(&amp;LDE)
  * Rule {/30}: Match		(&amp;LBW#&amp;LAU)
   + Add Part(13332754, qty:1.000000)
 ! Filling materials info...
 ! Changes in materials list detected! [0000-00-00-00.00.00.000000] vs [2010-06-03-00.00.00.000000]
 ! Loading materials...
  13452 materials found. Sqlcode: 0
   = Part [13332724], SubProd=H
   = Part [13332725], SubProd=H
   = Part [13332726], SubProd=H
   = Part [13332727], SubProd=H
   = Part [13332728], SubProd=H
   = Part [13332729], SubProd=H
   = Part [13332730], SubProd=H
   = Part [13332731], SubProd=H
   = Part [13332732], SubProd=H
   = Part [13332733], SubProd=H
   = Part [13332734], SubProd=H
   = Part [13332736], SubProd=H
   = Part [13332737], SubProd=H
   = Part [13332738], SubProd=H
   = Part [13332739], SubProd=H
   = Part [13332740], SubProd=H
   = Part [13332741], SubProd=H
   = Part [13332742], SubProd=H
   = Part [13332745], SubProd=H
   = Part [13332746], SubProd=H
   = Part [13332752], SubProd=H
   = Part [13332754], SubProd=H
 * Sorting part refs...
 ! 22 part refs converted to 22 BOM records, 1 new subprod records created
 ! Order [01NQR4/2010-04-28-12.36.16.077001] - flushing changes...
 ! Order [01NQR4/2010-04-28-12.36.16.077001] - changes successfully saved. 1 new subprod records, 22 new BOM records created.
  * cast &quot;TRN&quot;
&lt;/pre&gt;</text>
    </revision>
  </page>
  <page>
    <title>.ixf</title>
    <id>375</id>
    <revision>
      <id>1865</id>
      <timestamp>2010-06-07T07:32:09Z</timestamp>
      <contributor>
        <username>Rzacchi</username>
        <id>7</id>
      </contributor>
      <comment>moved [[.ixf]] to [[DB2 Export and import]]:&amp;#32;Improved chapter about DB2 export and import</comment>
      <text xml:space="preserve">#REDIRECT [[DB2 Export and import]]</text>
    </revision>
  </page>
  <page>
    <title>.swdefaults</title>
    <id>81</id>
    <revision>
      <id>1537</id>
      <timestamp>2010-05-20T09:22:18Z</timestamp>
      <contributor>
        <username>Dbondare</username>
        <id>4</id>
      </contributor>
      <minor/>
      <text xml:space="preserve">&lt;code&gt;&lt;pre&gt;
vshkil@~&gt;diff /usr/lib/sw/sys.defaults .swdefaults
1054c1054
&lt; #  swpackage.create_target_acls       = true
---
&gt;   swpackage.create_target_acls        = true
1112,1114c1112,1114
&lt; #  swcopy.distribution_source_directory               = /var/spool/sw
&lt; #  swinstall.distribution_source_directory    = /var/spool/sw
&lt; #  swpackage.distribution_source_directory    = /var/spool/sw
---
&gt;   swcopy.distribution_source_directory            = /home/vshkil/spool/sw
&gt;   swinstall.distribution_source_directory     = /home/vshkil/spool/sw
&gt;   swpackage.distribution_source_directory     = /home/vshkil/spool/sw
1122,1129c1122,1129
&lt; #  swacl.distribution_target_directory                = /var/spool/sw
&lt; #  swcopy.distribution_target_directory               = /var/spool/sw
&lt; #  swlist.distribution_target_directory               = /var/spool/sw
&lt; #  swmodify.distribution_target_directory     = /var/spool/sw
&lt; #  swpackage.distribution_target_directory    = /var/spool/sw
&lt; #  swreg.distribution_target_directory                = /var/spool/sw
&lt; #  swremove.distribution_target_directory     = /var/spool/sw
&lt; #  swverify.distribution_target_directory     = /var/spool/sw
---
&gt;   swacl.distribution_target_directory         = /home/vshkil/spool/sw
&gt;   swcopy.distribution_target_directory                = /home/vshkil/spool/sw
&gt;   swlist.distribution_target_directory                = /home/vshkil/spool/sw
&gt;   swmodify.distribution_target_directory      = /home/vshkil/spool/sw
&gt;   swpackage.distribution_target_directory     = /home/vshkil/spool/sw
&gt;   swreg.distribution_target_directory         = /home/vshkil/spool/sw
&gt;   swremove.distribution_target_directory      = /home/vshkil/spool/sw
&gt;   swverify.distribution_target_directory      = /home/vshkil/spool/sw

&lt;/pre&gt;&lt;/code&gt;

[[Category:Linux]]
[[Category:Development]]
[[Category:VShkil_Pages]]</text>
    </revision>
  </page>
  <page>
    <title>ADO DB</title>
    <id>478</id>
    <revision>
      <id>2303</id>
      <timestamp>2010-06-18T07:16:55Z</timestamp>
      <contributor>
        <username>Dbondare</username>
        <id>4</id>
      </contributor>
      <comment>Created page with 'ADO DB is a short from ''Active Data Objects Database''. It is a ''Microsoft'' technology which wraps most of existing ''Windows'' database interfaces (ODBC, OLE DB, etc) into a …'</comment>
      <text xml:space="preserve">ADO DB is a short from ''Active Data Objects Database''. It is a ''Microsoft'' technology which wraps most of existing ''Windows'' database interfaces (ODBC, OLE DB, etc) into a common interface called &quot;ADO DB&quot; (or without a space - &quot;ADODB&quot;).

The ''ADODB'' itself is just a set of system libraries pre-installed with Windows which provides a &lt;u&gt;common interface&lt;/u&gt; of ''connecting data source'', ''reading/writing data'', ''controlling database commands and transactions'', ''generic data containers to store data in run-time''.

Here are some of the most convenient things with ''ADODB'':
* possibility to connect and manipulate any type of data source without recompiling application. It is enough only to change ''connection string'' in application configuration to switch to other data source;
* possibility to use it from scripts (VBScript, JScript, VBA, etc);
* ''ADODB'' exists on any ''Windows'' version starting from ''Windows 2000'';
* in ''ADODB'' you can save a query resultset into a XML file and then load it back into a special container object in your application to continue processing

At the moment ''ADODB'' is a kind of ''deprecated'' interface, ''Microsoft'' wants to replace it with a next generation interface called ''Ado.Net''. But ''Ado.Net'' requires a ''.NET'' while ''ADODB'' still can work without ''.NET''.

== Useful Links ==
* http://connectionstrings.com</text>
    </revision>
  </page>
  <page>
    <title>About performance</title>
    <id>1006</id>
    <revision>
      <id>6746</id>
      <timestamp>2015-09-16T11:59:16Z</timestamp>
      <contributor>
        <username>Dbondare</username>
        <id>4</id>
      </contributor>
      <minor/>
      <text xml:space="preserve">= Introduction =
Diferent aspects of performance measurements and optimizations.

== Maintenance ==
=== Compression Level ===
By default export.exe use default level of ZIP compression.
Here are details: [http://search.cpan.org/~phred/Archive-Zip-1.50/lib/Archive/Zip.pm ZIP compression level in Perl].

{| border=&quot;1&quot; cellpadding=&quot;4&quot; cellspacing=&quot;0&quot; 
|- style=&quot;background:#dfefdf;&quot; 
! Compression Level !! Execution time !! Size 
|- 
| default(6) || 3:17 (197 sec) || zipped=285Mb, unzipped=4935Mb, ratio=5.8%
|-
| best/max(9) || 5:31 (331 sec) || zipped=261Mb, unzipped=4935Mb, ratio=5.3%
|}

With max-compression level we have:
* 9% smaller ZIP
* 65% more time spent on compression (roughly = 1.5 times slower)

Conclusion: I do not see a big value in using max-level of compression.

== C/C++ Primitives ==
=== QTrim() vs. QTRIM() ===
&lt;syntaxhighlight lang=&quot;cpp&quot;&gt;
#define QTrim(field) strcpy(field, RTrimStr(field, &quot; \t\r\n&quot;).c_str());

// vs.

Char* QTRIM(Char *pszStr)
{
  Char *psz = pszStr;
  int nLen = 0;
  while (*psz != 0) { psz++; nLen++; }
  if (nLen &gt; 0)
  {
    psz--; /* step back from \0 */
    nLen--;
    while (nLen &gt; 0 &amp;&amp; (*psz == ' ' || *psz == '\t')) { psz--; nLen--; }
    if (!(*psz == ' ' || *psz == '\t')) nLen++;
    pszStr[nLen] = '\0';
  }
  return pszStr;
}
&lt;/syntaxhighlight&gt;

Result:
&lt;pre&gt;
Profiler (loops count= 100.000):
QTrim()
    [00] delta:          349.496 mcs {ok}
QTRIM()
    [01] delta:           10.274 mcs {ok}
&lt;/pre&gt;

=== New ''ALTA::DateTime::load()'' Method ===
&lt;syntaxhighlight lang=&quot;cpp&quot;&gt;
  int count = 100000;
  Profiler::XHANDLE ht = Profiler::OpenTickPair(&quot;DataTime::load()&quot;);
  if (ht != (Profiler::XHANDLE)INVALID_HANDLE)
  {
    printf(&quot;testing DateTime::load()...&quot;);
    for (int i=0; i&lt;count; i++)
    {
      dt.load(szTsArr[i % 5]);
    }
    Profiler::CloseTickPair(ht);
  }
&lt;/syntaxhighlight&gt;
&lt;pre&gt;
Profiler (loops count= 100.000): // optimized version
DataTime::load()
    [00] delta:          417.178 mcs {ok}

Profiler (loops count= 100.000): // old version
DataTime::load()
    [00] delta:       27.288.046 mcs {ok}
&lt;/pre&gt;

=== ALTA::DateTime::Compare() vs. CompareTimestamps() ===
&lt;pre&gt;
Profiler (loops count= 100.000):
DataTime::Compare()
    [00] delta:           10.945 mcs {ok}
DataTime::load() + Compare()
    [01] delta:          429.968 mcs {ok}
CompareTimestamps()
    [02] delta:           26.538 mcs {ok}
&lt;/pre&gt;

=== std::sort() ===
Sorting vector of 100 items of &lt;code&gt;struct pdithu_type&lt;/code&gt; datatype items:
(note: sizeof(&lt;code&gt;struct pdithu_type&lt;/code&gt;) is 864)
&lt;pre&gt;
Profiler (loops count= 10.000):
Restore vector from backup
    [00] delta:          737.527 mcs {ok}
Restore vector and sort
    [01] delta:       10.776.597 mcs {ok}
&lt;/pre&gt;

The same test for vector of smaller items:
(note: sizeof(&lt;code&gt;struct pdithuco_type&lt;/code&gt;) is 296)
&lt;pre&gt;
Profiler (loops count= 10.000):
Restore vector from backup()
    [00] delta:          697.057 mcs {ok}
Restore vector and sort
    [01] delta:       10.862.406 mcs {ok}
&lt;/pre&gt;

As you can see the sorting itself is almost not depends on size of item in a vector.

One sort iteration costs about 10 milliseconds.</text>
    </revision>
  </page>
  <page>
    <title>Advance Shipping Note</title>
    <id>4</id>
    <revision>
      <id>1591</id>
      <timestamp>2010-05-20T09:38:59Z</timestamp>
      <contributor>
        <username>Dbondare</username>
        <id>4</id>
      </contributor>
      <minor/>
      <text xml:space="preserve">== Definition ==

* Electronic message, including electronic data interchange ([[EDI]]) or Extensible Markup Language ([[XML]]), giving notification of incoming goods prior to receipt. Also called ASN.

* Electronic message, like electronic data interchange ([[EDI]]) or Extensible Markup Language ([[XML]]), giving notification when a product is due prior to its receipt. ALTA [[PowerB2O]]™ includes both inbound and outbound Advance Shipment Notes (ASN).


== Formats ==

* VDA4913, VDA4913-40 ASN, VDA4913-30 Receipt
* EDIFACT DESADV

[[Category:Business_Interfaces]]</text>
    </revision>
  </page>
  <page>
    <title>AltaXML</title>
    <id>83</id>
    <revision>
      <id>1978</id>
      <timestamp>2010-06-08T11:04:26Z</timestamp>
      <contributor>
        <username>Dbondare</username>
        <id>4</id>
      </contributor>
      <minor/>
      <text xml:space="preserve">'''Master project''': ''T:\Products\ALTA PowerB2O\Libraries\AltaXML\Unix''
---------------
'''External libraries''':
 [[libxalan-c1_3]]
 [[libxerces-c1_6_0]]

----
Building ALTAXML on HPUX [[altaxml archive]]

'''Installation script''':
 [[build.sh]]
----

'''[[sha1sum]]'''

== RHEL ==
Current release version was built without STLPORT in Oct2007 on CentOS 4.4 

&lt;code&gt;&lt;pre&gt;
84c909934e02aba0e3742aaa6f35faee11794d6e *libaltaxml.a (without STLPORT) - in /usr/local/bto/lib/ (copy)
84c909934e02aba0e3742aaa6f35faee11794d6e *libaltaxml.a (without STLPORT) - in /home/vshkil/pb2o/altaxml/lib_from_kiev (build Oct2007 CentOS 4.4) 
1ea77af6bddd4e5d05ec5b27c5dc1d9f7662c0b2 *libaltaxml.a (with STLPORT) - in /home/vshkil/pb2o/altaxml/lib (build Jan2008 CPH CentOS 4.5)
&lt;/pre&gt;&lt;/code&gt;

== HPUX ==
Current release version was built without STLPORT in Oct2006 on HPUX 11.23 

&lt;code&gt;&lt;pre&gt;
bf87c9fbdec70f172f204c65d3f2b83a  ./pb2o/run_oct2007/tools/lib/libaltaxml.a
bf87c9fbdec70f172f204c65d3f2b83a  ./pb2o/backup/run_june2007/tools/lib/libaltaxml.a
bf87c9fbdec70f172f204c65d3f2b83a  ./pb2o/install_bto/bto_files/lib/libaltaxml.a
bf87c9fbdec70f172f204c65d3f2b83a  ./pb2o/install_bto/lib/libaltaxml.a
bf87c9fbdec70f172f204c65d3f2b83a  /home/bto/install_bto/lib/libaltaxml.a
bf87c9fbdec70f172f204c65d3f2b83a  /home/vshkil/pb2o/altaxml/backup_2006/libaltaxml.a
&lt;/pre&gt;&lt;/code&gt;

== Building  AltaXML library ==
AltaXML is building from a bit altered sources of ''Xerces 1.6.0'' and ''Xalan 1.3.0'' libraries.
It was already built on some Linux/UNIX platforms and here are you can find archived build sandboxes:
* ''T:\Products\ALTA PowerB2O\Libraries\AltaXML\Unix\HPUX'' &lt;-- here is HP-UX version
* ''T:\Products\ALTA PowerB2O\Libraries\AltaXML\Unix\HPUX'' &lt;-- here are Linux versions

The latest one we have recently built on our CentOS 5.4 VM is in the ''altaxml-CentOs54-good.tar.gz'' archive.

Inside there is a script called ''build-all.sh'' which calls the rest of used scripts. 

To build AltaXML from a ''altaxml-CentOs54-good.tar.gz'' you should create a ''btobuild'' user on Linux (assume home dir is = /home/btobuild) and login as that user.
Then download and extract ''altaxml-CentOs54-good.tar.gz'' archive to a ''/home/btobuild/sandbox/altaxml'', go to that directory and run the ''sh ./build-all.sh'' command to build it.

Next step - test the AltaXML lib to ensure it works.


== Testing AltaXML library ==
There is some code in MKS at &quot;test&quot; folder in the ''masterproject=&quot;T:/Products/ALTA PowerB2O/Libraries/AltaXML/AltaXML.pj&quot;''.
Also - there are some *.XML and *.XSL files to be used as test files and see also - ''commands.txt'' file which contains some commands examples:
&lt;pre&gt;
loadxml data, tmp.dataxml
loadxml xsl1, tmp.uswxsl1
loadxml xsl2, tmp.uswxsl2
loadxml xsl3, tmp.uswxsl3
applyxsl data, xsl1, tmp.out1
applyxsl data, xsl2, tmp.out2
applyxsl data, xsl3, tmp.out3
&lt;/pre&gt;

When you built the ''testxml.exe'' application you also can run it and then type &quot;help&quot; and press [Enter] it will display following information:
&lt;tt&gt;
Supported commands:
  help
    Print this information.

  exit or quit
    Exits application.

  loadxml &lt;id&gt;, &lt;filename&gt;
    Load xml from specified file, save in memory with specified id.

  applyxsl &lt;xmlId&gt;, &lt;xslId&gt; [, outputfilename]
    Apply to specified xml specified xsl. Both xml and xsl should be loaded to memory.
    You should specify not filenames but identifiers of loaded xml documents.
    If outputfilename specified it will save result to file, otherwise prints it.
&lt;/tt&gt;

[[Category:Linux]]
[[Category:Development]]
[[Category:VShkil_Pages]]</text>
    </revision>
  </page>
  <page>
    <title>Analyze Log Files</title>
    <id>829</id>
    <revision>
      <id>4743</id>
      <timestamp>2012-08-01T07:46:01Z</timestamp>
      <contributor>
        <username>Dbondare</username>
        <id>4</id>
      </contributor>
      <minor/>
      <text xml:space="preserve">= PowerShell Script to Analyze Timestamps in Log File =
&lt;syntaxhighlight lang=&quot;powershell&quot;&gt;
#
# Analyze CSLMON log files for gaps in timestamp values.
#

function AnalyzeFile($pFile)
{
  $t1 = Get-Date;
  &quot;Processing file content...&quot;;
  &quot;Started at &quot; + $t1;

  $iLine = 0;
  $maxDiff = 0;
  $prevAbsTime = 0;

  Get-Content $pFile |% { 
    $line = $_; 
    if ([regex]::IsMatch($line, &quot;^\d{2}:\d{2}:\d{2}&quot;))
    {
      $absTime = ExtractAbsTime($line)
      $diff = $absTime - $prevAbsTime;
      if ($prevAbsTime -ne 0)
      {
        if ($diff -gt 5)
        {
          &quot; More than &quot; + $diff + &quot; sec diff at &quot; + $line;
        }
        if ($diff -gt $maxDiff)
        {
          $maxDiff = $diff;
        }
      }
      $prevAbsTime = $absTime;
      if (($iLine -gt 0) -and ($iLine % 10000) -eq 0)
      {
        &quot; * line# &quot; + $iLine + &quot;, maxDiff = &quot; + $maxDiff + &quot; sec&quot;;
      }
      $iLine++;
    }
  }
  $t2 = Get-Date;
  &quot; &quot; + $iLine + &quot; lines processed. Finished at &quot; + $t2;
}

function ExtractAbsTime($pLine)
{
  $h = [Convert]::ToInt32($pLine.Substring(0, 2));
  $m = [Convert]::ToInt32($pLine.Substring(3, 2));
  $s = [Convert]::ToInt32($pLine.Substring(6, 2));
  return $h * 3600 + $m * 60 + $s;
}

if ($args.Length -lt 1)
{
  &quot;ERROR: no parameters specified!&quot;;
  return ;
}

&quot;--- Processing file: &quot; + $args[0];
AnalyzeFile($args[0]);
&lt;/syntaxhighlight&gt;


Usage example:
&lt;pre&gt;
./ChkLogTime.ps1 ./cslmon/logs/mo20120731.log
&lt;/pre&gt;


'''Note:''' average performance is 2000 text lines per second. So, log 105Mb file with 1.5M lines was processed in ~13 minutes.


[[Category:PowerShell]]</text>
    </revision>
  </page>
  <page>
    <title>Aptiv Support Process</title>
    <id>857</id>
    <revision>
      <id>8450</id>
      <timestamp>2020-06-17T07:13:16Z</timestamp>
      <contributor>
        <username>Chaitanya</username>
        <id>36</id>
      </contributor>
      <comment>/* Problem Management : Root cause Analysis (RCA) */</comment>
      <text xml:space="preserve">{| align=&quot;left&quot;
   | __TOC__
   |}

=Incident Management=
The below process flow explains how the Aptiv business end user creates the problem incident and handled by DXC service desk and JDA BTO support Team.&lt;br&gt;
[[File:Delphi support flow Update new.jpg]]

== Priority / Severity ==
The priority in ServiceNow is calculated based on
* Excent of Org Impact: (&quot;Global&quot;, &quot;Site&quot;, &quot;External Customer&quot;, &quot;Several Clients&quot;, &quot;One Client&quot;)
* Workaround (&quot;Yes&quot;, &quot;No&quot;)
* Criticality of service (&quot;Critical&quot;, &quot;High&quot;, &quot;Medium&quot;, &quot;Low&quot;)
* Incident Type (&quot;Informational&quot;, &quot;Request&quot;, &quot;Degradation&quot;, &quot;Interruption / Outage&quot;)
And the Priority is then one of following:
* P1: &quot;Customer is impacted&quot;
* P2: &quot;Production at Aptiv is impacted&quot;
* P3: &quot;Minor impact on production&quot;
* P4: used e.g. for new user request, password resets, etc
&lt;br&gt;

==Event Management==
Please click on this page [[Event Management]] for more details

== Crisis Management ==
Please see page [[Crisis Management]] for further description of Crisis Management at Aptiv

==Incident Downgrade process==
IM Team is responsible to confirming with User if business is impacted. &lt;br&gt;
In case of business is not impacted (user confirms)/user &amp; SDM is not reachable, then IM Team downgrade the severity of the incident and close the Problem Record.&lt;br&gt;
Downgrade of an incident can also be done on a DSSR call. &lt;br&gt;
In case of business impacted, IM Team Assign PTask to respective vendors based on discussion in DSSR call.

==Aptiv BTO user Entitlement process ==
In case user management requests(creation/update/deletion) raised as an incident, then please follow the below process.

For adding or change the BTO user for Aptiv business it is mandatory to follow the process. The requesting user needs to fill the BTO entitlement document and submit to service desk with incident number and SDM approval. 
The sample BTO entitlement document is located on T drive location :
 T:\Customers\Delphi\_Support\Documents\BTO2010 User Entitlement Form.xls
&lt;br&gt;
''Note: User management requests can also be raised as a Service Request Items. [[http://btowiki.jda.corp.local/index.php/JDA_BTO_Support#Handling_RITM_tasks]]''

=Support Tools =
==Service Now (SN)==
Aptiv is using the Service Now system to handle problem incidents, Root Cause Analysis (RCA), Request for Changes (RFC) and User Management Requests (SCTasks) for their support process for all the Aptiv vendors.&lt;br&gt; 
When a Aptiv business user discovers a production problem they can start chat/call the Aptiv SvD (which is handled by DXC Technology) based on the business impact Or they can create an incident themselves in Service Now.&lt;br&gt;
DXC help desk are responsible to open Service Now tickets (prefix : INCxxxxxxx)for the problem reported by the user and escalate it to the respective vendor support group. If the problem is in BTO application then Help desk will route the ticket to JDA BTO support (and call JDA BTO hot line number in case of P1/P2/Urgent-P3) and escalate the issue with Service Now case #.&lt;br&gt;
All Service Now records got a unique number, and the prefix describes the type of record:

{| border=&quot;1&quot; width=&quot;400&quot;
|-
! Service Now prefix
! Description
|-
| INCxxxxxxx
| Incident
|}
&lt;br&gt;

==JDA : Salesforce Support Cloud (SFSC or SF)==
JDA is using Sales force cloud internal ticketing system to manage the Aptiv support incidents, JDA BTO support group is responsible to create SFSC internal case when they get a SN incident.&lt;br&gt;
The SN incident number will be added in SFSC record in the customer case number field. BTO support team can create a SFSC case during internal monitoring (need not to have a SNOW INC number).&lt;br&gt;
When Aptiv SvD (Service Desk) escalate the customer reported issue BTO support group also responsible to notify customer back they are opened a SFSC internal case and stated working for the reported issue (via acknowledgement email from SFSC ticket).&lt;br&gt;
For high priority case (P1 or P2) it is very important to update the customer every 1 hour with the latest status of case and update the SFSC and SN incident records.&lt;br&gt;
&lt;br&gt;

== Emails==
Emails, related to an incident will only begin by BTO support team's end from SFSC case(for confirmation/Seeking more information/Suggestion etc. to user) and user can reply on that. User can only create an incident by contacting to Aptiv SvD(at DXC), not directly sending email to &quot;bto.support@jda.com&quot;. Below are the listed email ID details



{| border=&quot;1&quot; cellpadding=&quot;4&quot; cellspacing=&quot;0&quot; 
|- style=&quot;background:#dfefdf;&quot;
! Entity
! Email
! Description
|-
| Aptiv Helpdesk (by DXC)
| Aptiv@service-now.com
| Emails are handled in ServiceNow
|-
|rowspan=&quot;3&quot;|JDA BTO support
| support@jda.com&lt;br&gt;
| JDA Support System
|- 
| BTO.ChangeManagement@jda.com
| Change management (mailbox is accessible in Outlook)
|-
|Aptiv Incident Management
|siammajorincidentmanagement@aptiv.com
|Any queries related with high/critical incidents and request to initiate a bridge call when required
|-
|Aptiv Problem Management 
|siamproblemmanagement@aptiv.com
|Any queries related with problem records 
|}


In the new TCX ticketing system will not create an SF case automatically when user send an email to support@jda.com , creating new or to get update on existing BTO incidents Aptiv users should contact the Aptiv helpdesk  &lt;Br&gt; &lt;br&gt;
&lt;br&gt;

=Problem Management : Root cause Analysis (RCA)=
An RCA is performed to identify what happened, why it happened and then determine what improvements or changes are required. Correctly performed, a Root Cause Analysis can identify breakdowns in the processes or systems that contributed to the non-conformance and determine how to prevent it from happening again.

Usually RCA is done for the high priority incidents i.e., for P1 or P2 which impacts the business at very high level and for recurring issues. For such incidents RCA process is required to find the root cause and provide the permanent solution.

The timeline to complete this RCA process is 2 Weeks(14 days). First 7 days it will with BTO CoE team. BTO CoE team will complete the RCA document and send it to Mikael Clausen to review for next 7 days. Once reviewed &amp; approved by Mikael, it will be submitted to SIAM problem management. 

This timeline of 14 days is fixed on an agenda to ensure that the required data for RCA process is not lost from the system. 

The reactive RCAs pushed to the BlueYonder queue will be assigned to Mikael. Also, same timelines are followed for Non-Aptiv Customers.

The Root cause owners for an incident will be decided in the respective DSSR call.

BTO CoE team will accept the ownership of RCA only after confirming that the incident was occurred due to the BTO functionality/product.

We also present our points on the call and reject the RCA ownership if we are sure that the issue is not from BTO and RCA should be provided by any other respective team.

However, if we are not sure it will be informed on the call that it will be discussed internally and provide an update in the next DSSR call.

Sample RCA templates are located in &quot;T:\Customers\Delphi\_Support\Documents&quot;&lt;br&gt;
&lt;br&gt;

=Change Management =
The Production problem which needs a build or system change to apply the permanent solution will be processed by change management. For these incidents the work around solution will be applied and change will be process and will get approved by the CAB managers during the weekly CAB meetings. &lt;br&gt;
Aptiv system following the standard RFC templates and BTO support team will be requested to fill the details and submit to the Aptiv business , The change will be discussed during the CAB and will be approved. &lt;br&gt;
Once every thing approved change will be scheduled to build in production based on the business off down time.&lt;br&gt;
Sample RFC template's are located in  &quot;T:\Customers\Delphi\_Support\Documents\RFC&quot;&lt;br&gt;
&lt;br&gt;
==Checklist for Change Creation ==
=== Field: &quot;Requested for&quot; ===
This field is normally containing the name of the person who request this change. It could be an user or SDIM&lt;br&gt;
BUT - please remember : It must not be a person who should approve this change - which basically means: Do not add the same value as in field &quot;Approving IT Operations Manager&quot;.

=== Field: &quot;Requested by Date&quot; ===
Please be aware of the definition for Requested by date in SERVICENOW. &lt;br&gt;
It's the date that the requester would LIKE the change to be implemented.&lt;br&gt;
For example, below Requested by date is incorrect.&lt;br&gt;
[[File:correct.png]]
&lt;br&gt;

And this one is correct, the Requested by date should be equal to Scheduled Implementation End Date or later.&lt;br&gt;
[[File:incorrect.png]]
&lt;br&gt;
==Post Implementation Task==
After the implementation task completed successfully, we have to test &amp; verify whether the implementation is successful, by user. After the user confirmation only we
can close the Post Implementation task followed by the closing the change.

==Change process to be followed by COE for internal CAB processing requests==
Delan/Ishfaq/Henrik/Mikael/Barbara and whom-ever that will make changes in the future will send email to &quot;BTO.ChangeManagement@jda.com&quot; with information about the Change.&lt;br&gt;
This must also include a name of the user/manager at Aptiv who needs this and implementation/downtime that is agreed with the customer.&lt;br&gt;&lt;br&gt;

The further processing  must be handled by BTO Change Management team:&lt;br&gt;&lt;br&gt;
•	Make a CHG record in ServiceNow coordinator as Mikael and fill the Assessment/priority &lt;br&gt;
•	Make a Change record in Salesforce &lt;br&gt;
•       Attach RFC Form (for Major/Significat Changes) in both Salesforce and Service Now Record&lt;br&gt;
•       Bring Major/Significant Change for &quot;prep for CAB&quot; and Request Minor Changes for Mikael Approval &lt;br&gt;
•	Inform Mikael that, change record has been created &lt;br&gt;
•	Minor changes must be approved by Mikael before implementation&lt;br&gt;
•       For Major/significant changes, Mikael will review and approve/close “Prep for CAB” and will bring it for “Prep for CAB SIAM” &lt;br&gt;
•	Inform the SDIM about the change ( so (s)he can prepare and be ready to approved) &lt;br&gt;
•	Participate in CAB and ensure the CHG is approved &lt;br&gt;
•	Inform the JDA requester about the approval &lt;br&gt;
•	Follow up with JDA requester/implementer, so the two tickets can be finalized.&lt;br&gt;
•	We have to keep the base email [with attached RFC form] until the change record is created for that email. And also keep the latest email of it.&lt;br&gt;
•	Once the change record is created, then we can archive the base email. The latest email from this chain should be in Inbox. &lt;br&gt;

'''Note:'''   Minor Changes regarding BTO health checkup will be handled by CoE team. For these changes, change coordinator should be one of the CoE team member and he/she is responsible for approval of this change, before implementation.&lt;br&gt;


'''Note:'''   If we receive only email for JDA regarding IIB Maintenance activity and no child record, then we have to inform APTIV/DXC/TCS team to create a child record for JDA team. If still they are not creating any child record for us then we are not going to work for this activity. But if they are creating child record then we have to queue check in all projects.

=Meetings=
Aptiv system has DSSR and CAB weekly meetings to get the status from different vendors about the problem incident and  change management.&lt;br&gt;
Below are the weekly schedules BTO support team will join to update the status to customer. &lt;br&gt;
[[File:Weekly plan_1.png]]
&lt;br&gt;

==DSSR (Daily service status review)==
Aptiv BTO support team will join 3 DSSR meetings every day as per the schedule and the region.&lt;br&gt;
The purpose of this call is to discuss about the open high priority incident updates and the problem management. Different vendor team will join and update the status for their respective business area or applications.&lt;br&gt;
Below are the details to join the DSSR Meeting&lt;br&gt;
&lt;br&gt;

===Asia Pacific (APAC)===
When: Occurs every weekday  from 08:00 to 08:30 (GMT+05:30)&lt;br&gt;
To Join the meeting click https://meet.delphi.com/slav.stefanov/WR185DF9​​​​​​​ &lt;br&gt;
 
Agenda To Be Discussed &lt;br&gt;

•	Call statistics for previous day and month-to-date &lt;br&gt;
•	Review of ongoing P1 and P2 issues and necessity of RCA creation &lt;br&gt;


{| border=&quot;1&quot; cellpadding=&quot;4&quot; cellspacing=&quot;0&quot; 
|- style=&quot;background:#dfefdf;&quot; 
! Region	
! Number	
! Available Languages
|- 
| Denmark
| +45 8060 1879 Denmark Toll Free&lt;br&gt;+45 4331 4524 Denmark Caller Paid
| English (United States)
|- 
| India
| 0008004402363 India Toll Free	
| English (United States)
|- 
| United Kingdom
| 08001412578 United Kingdom Toll Free&lt;br&gt;02035645380 United Kingdom Caller Paid
| English (United States)
|}
&lt;br&gt;

===Europe, Middle East, Africa (EMEA) ===
When: Occurs every weekday effective 2017-05-15 from 13:00 to 13:30 (GMT+05:30).
Where: Online Meeting

To Join the meeting click  https://meet.delphi.com/dobrin.aretov/SLZ12S5G &lt;br&gt;

Agenda To Be Discussed &lt;br&gt;

•	Call statistics for previous day and month-to-date &lt;br&gt;
•	Review of ongoing P1 and P2 issues and necessity of RCA creation &lt;br&gt;
•       Review of Changes &lt;br&gt;
•	Review of open complaints/escalations &lt;br&gt;	
•	Round table &lt;br&gt; 

{| border=&quot;1&quot; cellpadding=&quot;4&quot; cellspacing=&quot;0&quot; 
|- style=&quot;background:#dfefdf;&quot; 
! Region	
! Number	
! Available Languages
|- 
| Denmark
| +45 8060 1879 Denmark Toll Free&lt;br&gt;+45 4331 4524 Denmark Caller Paid
| English (United States)
|- 
| India
| 0008004402363 India Toll Free
| English (United States)
|- 
| United Kingdom
| 08001412578 United Kingdom Toll Free&lt;br&gt;02035645380 United Kingdom Caller Paid
| English (United States)
|}
&lt;br&gt;

===America (AMER)===
To Join the meeting click https://meet.delphi.com/donald.robinson/GGGB4N16&lt;br&gt;

Agenda To Be Discussed &lt;br&gt;
•	Call statistics for previous day and month-to-date &lt;br&gt;
•	Review of ongoing P1 and P2 issues and necessity of RCA creation &lt;br&gt;

{| border=&quot;1&quot; cellpadding=&quot;4&quot; cellspacing=&quot;0&quot; 
|- style=&quot;background:#dfefdf;&quot; 
! Region	
! Number	
! Available Languages
|- 
| Denmark
| +45 8060 1879 Denmark Toll Free&lt;br&gt;+45 4331 4524 Denmark Caller Paid
| English (United States)
|- 
| India
| 0008004402363 India Toll Free	
| English (United States)
|- 
| United Kingdom
| 08001412578 United Kingdom Toll Free&lt;br&gt;02035645380 United Kingdom Caller Paid
| English (United States)
|}
&lt;br&gt;

== Change Advisory Board (CAB)==
Aptiv BTO support team will join 5 CAB meetings every week , The purpose of this meeting is to discuss about the ongoing production system changes and post implementation changes , CAB team will discuss about the purpose of the change requested and the production outage(down time) based on this inputs change will be approved and will be processed further.

===Asia Pacific (APAC)===
MS Lync   https://meet.delphi.com/slav.stefanov/9Z7818S2&lt;br&gt;
Full list of International dial-in numbers: https://dialin.Aptiv.com/&lt;br&gt;
&lt;br&gt;

=== Europe, Middle East, Africa (EMEA)===
MS Lync  https://meet.delphi.com/maria.atanasova/6GLDWN08 &lt;br&gt;
Full list of International dial-in numbers: https://dialin.Aptiv.com/   &lt;br&gt;
&lt;br&gt;

===America (AMER)===
MS Lync  https://meet.lync.com/cscportal/sspark/255LFHMS​​​​​​​&lt;br&gt;
Full list of International dial-in numbers: https://dialin.Aptiv.com/  &lt;br&gt;
&lt;br&gt;

===Enterprise===
MS Lync  https://meet.Aptiv.com/timothy.berger/1CIEJGXO&lt;br&gt;
Audio Conference Code: 46 11 67 83   &lt;br&gt;
Full list of International dial-in numbers: https://dialin.Aptiv.com/ &lt;br&gt;
&lt;br&gt;

==Aptiv BTO Internal Daily status meeting ==
&lt;br&gt;

=BTO support Hot line system=
The dedicated BTO support team Level-1 and Level-2 for Aptiv is located in Bangalore/India.High priority business impacting issues and system changes will be escalated to support group located in Copenhagen/Denmark.&lt;br&gt;
The customer and service desk hot line calls will be handled by both teams based on the timings.

[[Aptiv Hot-Line support process]]
&lt;br&gt;

=BTO Daily Task for Support Team=

==Monitoring Daily Task==
* Monitor the SN incident queue for every 30 mins for P3/P4
* Monitor the SF &quot;&quot;BTO All Cases&quot;&quot; and update the non-assigned INC with proper project name and also close the Spam INC
* Check If any Aptiv incident with no project or customer ref number and update
* Run &quot;&quot;EMEA BTO Emails&quot;&quot; report and handle the customer new email's
* Check if SF and SN incident counts are always matching 
* Monitor the Aptiv email inbox for every 30 mins for customer updates 
* Monitor the BTO CM email inbox every 30 mins and handle if any new request and clean the inbox
* Prepare the latest update on open incidents/CHG before join the DSSR and CAB meetings

&lt;br&gt;
== Handling RITM tasks ==

At times we get tasks like RITM0065494 e.g. to delete a user from BTO. Use this RITM number to search SN to open up a page headed Request Item. Scroll down the page to find a number like SCTSK0061922. Click it to open up. In the Item Details section, you will find details like Net id and App Login ID: GPiec like data. Go ahead completeing the request, like deleteing GPiec from BTO. Then click on 'Assign to me' so that you can assign it to yourself and mark it completed.


==Check open tickets:==
*  Check SN Incidents in SErvice Now web version https://delphi.service-now.com/navpage.do  after receiving hot line calls from Aptiv Help Desk(for P1 and P2)to check all open tickets.
*  Create Salesforce(SFSC) entries with reference with the SN Incidents number and right site name at https://salesforce.com/
*  Log on to the Aptiv server and start working on it, e.g check ERRORLOG, windows event log etc.
*  Communicate with the user after resolving the issue and send mail to user from SFSC.
*  Update SFSC comment tab with the your findings while resolving the issue.
*  Find out the root cause and update user and SDM and Aptiv help desk of that region within 30 minutes(For Sev 1 and Sev 2)
*  Send update every 30 minutes until the issue is resolved and we get confirmation from the user(For Sev 1 and Sev 2)
*  Close the ticket in both SN Incidents and SFSC after receiving confirmation from the user.
*  Chase the user in case of waiting for user confirmation and update both SN and SFSC about the chasing.
*  If no response from user after continuous 3 trials, we can close the issue both in SN and SFSC
*  If the P1 and P2 ticket can be downgraded to lower severity due to minimal impact, then SIAM team will handle it.
&lt;br&gt;


==SF Documentation== 

Follow the steps while documenting SF cases 
 
* Describe what you are searching for
* Make a SQL that shows the relevant columns, e.g. MODEL And PLANT are not relevant - hopefully the same for all.
* Paste the SQL into the comment
* Paste the result into the comment 
* Comment what the result means ! 


==Replication check==
* Check replication weekly once (every Monday)for all the servers
* Check previous replication status document at t:\Functional entities\Support\SystemStatus\
* If any error found, let the team know about it and create SFSC case with case origin as alert and fix it.
* Update Consolidate Replication check document as well
&lt;br&gt;

==Duplicate Case==
When you have a duplicate case in SFSC , then please remember to save the parent SFSC ticket number in the &quot;Parent Case&quot; field, and also when closing it, then select the field Reason for Close is &quot;Duplicate Case&quot; instead of e.g. &quot;Additional Support Services&quot;.
&lt;br&gt;

==User Account Management Case[Password Reset issue]==
As per user request reset the password and inform user about the modified BTO credentials via email from salesforce &amp; ask for confirmation about case closure.
In case user is not replying then follow the 3 strikes rule i.e send three reminder emails in 3 days and if still no response from user then close the case.
&lt;br&gt;

= Other / Misc =
==Reboot Aptiv servers==
'''We are not allowed to reboot Wintel servers at Aptiv.'''&lt;br&gt;
If it’s necessary to reboot a server, then get the SDIM approval first, then contact Aptiv Service Desk to create a ticket for DXC Hosting Team.&lt;br&gt;

==Aptiv China servers==

'''Note: The below mentioned problem are fixed. Now all China server's CSLMON are running as a service.'''

We know some of the China projects having a problem with printing the local Chinese language when CSLMON running as windows services
and decided to run the CSLMON as an exe under BTO local user accounts, so some of the China servers should always logon with BTO account. 

We usually performing BTO health check and for China projects after server reboot we should logon with BTO user account and start the CSLMON as exe .

The details on below link will help BTO Support team how to logon and start the CSLMON on China servers. 

[[Delphi_China_projects]]</text>
    </revision>
  </page>
  <page>
    <title>Archiver.NET project experiences and ideas</title>
    <id>252</id>
    <revision>
      <id>2556</id>
      <timestamp>2010-07-21T12:35:29Z</timestamp>
      <contributor>
        <username>Dbondare</username>
        <id>4</id>
      </contributor>
      <minor/>
      <text xml:space="preserve">'''NORGAARD:''' This appears to belong to the [[Talk:Archiver|Discussions-page]] for Archiver
&lt;hr&gt;
Some thoughts:

* The old archiver can insert search results directly in a DB2 or Nonstop database. Do we need to close this gap? (see also discussion page)
* Caching was left out for this release. Maybe it could be implemented in a later version  (see also discussion page)
* Column sorting might be nice.
* Columns resizing should be there.
* View should be adjusted to looks nice in the 1024x768 screen resolution
* View should be adjusted to looks similar in FireFox and IE browsers (now IE has essentially wider panel with search fields, different alignment/resizing of grid with search results)
&lt;hr&gt;

'''DBONDARE''': Known Issues
* Delan reported installation issues when was trying to install it on some our VMs. As discovered it could be resolved by ASP.NET re-registration. Use the following command:
&lt;pre&gt;
%WinDir%\Microsoft.NET\Framework\v2.0.50727\aspnet_regiis.exe -i
&lt;/pre&gt;
then start Archiver.Net installer again - it should installed fine.

Next issue - the ''ASP.NET'' web service extension is ''Prohibited'' by default and the ''aspnet_regiis.exe -i'' command is not changing this option. So, you have to enable it manually:
* click [Start] -&gt; Programs -&gt; Administrative Tools -&gt; Internet Information Services (IIS) Manager. 
* select ''Web Service Extensions'' in a tree
* select ''ASP.NET v 2.0.xxxxx'' in a list, click [Allow]
* restart IIS
Try, now it should works.


[[Category:Development]]
[[Category:Feedback]]</text>
    </revision>
  </page>
  <page>
    <title>Auditlog</title>
    <id>160</id>
    <revision>
      <id>3830</id>
      <timestamp>2011-10-05T07:44:52Z</timestamp>
      <contributor>
        <username>Mclausen</username>
        <id>2</id>
      </contributor>
      <comment>link to table AUDITLOG</comment>
      <text xml:space="preserve">= Purpose =
User actions made in BTO Clients should be logged in the AUDITLOG table.
The Action codes are :

&lt;pre&gt;
  // deprecated names of AuditLog actions
  SQL_INSERT  = 101;
  SQL_DELETE  = 102;
  SQL_UPDATE  = 103;
  FILE_OPEN   = 201;
  FILE_CLOSE  = 202;
  SERVER_EXEC = 301;
&lt;/pre&gt;

And here are the correct AuditLog actions:

&lt;pre&gt;
  AUDIT_SQL_INSERT    = 101; // SQL insert
  AUDIT_SQL_DELETE    = 102; // SQL delete
  AUDIT_SQL_UPDATE    = 103; // SQL update
  AUDIT_FILE_OPEN     = 201; // when open document (flow, script, whatever) from host
  AUDIT_FILE_CLOSE    = 202; // (optional) when close opened from host document 
  AUDIT_SERVER_EXEC   = 301; // kick some BTO server
  AUDIT_NOTIFICATION  = 401; // some kind of summary notification (like - N parts imported, N rules created, etc)
  AUDIT_WARNING       = 402; // some kind of warning (like - N orphan records found, etc)
  AUDIT_SUMMARY       = 403; // summary audit info 
  AUDIT_LOGON         = 10010; // this is never written by client! EJISPRIV writes this record on logon
&lt;/pre&gt;

Here is code example - how to write a record to AUDITLOG:

&lt;pre&gt;
TAuditLog.WriteLog(Self.Context.CSL, AUDIT_SQL_INSERT, Self.Context.User,
  AItem.ClassName, '', format('%s%sInsert %s [%s]: %s',
  [
   iif_str(ownTx, 'TX&gt;',''),
   iif_str(Self.SummarizeAudit, '{ROOT}',''),
   tabName, AItem.Name,
   ExtractAuditInfoFromSQL(stmt)
  ]));
&lt;/pre&gt;
Note: as you can see - ''TAuditLog'' class has static function WriteLog, so you do not need to create instance of ''TAuditLog'' class but can use this function.

== Summary Audit Mode ==
To avoid flooding AuditLog with lot of records on massive db updates I have introduced a ''Summary Audit Mode''. It is the special mode when application writes audit record for 1st operation (with prefix &quot;{ROOT}&quot;) and then, when successfully completed last operation, it writes a summary record with counts on how many db insert/updates/etc were performed.

Summary audit mode supported by a new ''DataLayer'' (see core/common/client/UDbLinkedDL.pas).

== Database ==
Please see [[AUDITLOG]]

[[Category:Development]]</text>
    </revision>
  </page>
  <page>
    <title>Automated Testing</title>
    <id>712</id>
    <revision>
      <id>3998</id>
      <timestamp>2011-10-27T12:11:42Z</timestamp>
      <contributor>
        <username>Dbondare</username>
        <id>4</id>
      </contributor>
      <minor/>
      <text xml:space="preserve">{| align=&quot;right&quot;
 | __TOC__
 |}

= Introduction =
We need a kind of ''Q.A. Box''- something that will automatically test BTO tasks and servers after a build.

So, ...

== Wanted Features ==
* some mathematic - perhaps could reuse CalcRPN engine
* command line interface
* reporting - improved reporting 
* support branching of test scenarios and multiple test scenarios per task/server
** example: to provide separate tests for particular bugs 



[[Category:SCM]]
[[Category:Work Queue Task]]</text>
    </revision>
  </page>
  <page>
    <title>B2O</title>
    <id>13</id>
    <revision>
      <id>43</id>
      <timestamp>2007-09-03T10:32:17Z</timestamp>
      <contributor>
        <ip>10.231.2.2</ip>
      </contributor>
      <comment>Redirecting to [[Build-to-order]]</comment>
      <text xml:space="preserve">#REDIRECT [[build-to-order]]</text>
    </revision>
  </page>
  <page>
    <title>BOM</title>
    <id>6</id>
    <revision>
      <id>2839</id>
      <timestamp>2010-09-20T09:39:08Z</timestamp>
      <contributor>
        <username>Dbondare</username>
        <id>4</id>
      </contributor>
      <minor/>
      <text xml:space="preserve">#REDIRECT [[bill of material]]

{| style=&quot;&quot; border=&quot;1&quot; cellspacing=&quot;0&quot; cellpadding=&quot;0&quot;
|- style=&quot;background:#dfefdf;&quot; 
!Field
!Datatype
!Type
!Description
|-
| '''MODEL'''     || CHAR(4)       || PK. || 
|-
| '''PLANT'''     || CHAR(4)       || PK. || 
|-
| '''ORDNR'''     || CHAR(16)      || PK. || 
|-
| '''SUBPROD'''   || CHAR(2)       || PK. || 
|-
| '''CUSPNR'''    || CHAR(22)      || PK. || 
|-
| '''RECVTIME'''  || TIMESTAMP     || PK. || 
|-
| ERRCODE         || SMALLINT      || NPO-specific: Error code || 
|-
| QTY             || FLOAT         || Quantiry || 
|-
| UNIT            || CHAR(8)       || Unit of measure for Qty value || 
|-
| REFNR           || CHAR(16)      || Reference number || 
|-
| ALTCUSPNO       || CHAR(22)      || Alt. customer part number || 
|-
| REVLVL          || SMALLINT      || 2010.1+: part revision level || 
|-
| REVISION        || CHAR(32)      || 2010.1+: part revision ID || 
|-
| VERSIX          || CHAR(8)       || 2010.1+: part revision version || 
|}</text>
    </revision>
  </page>
  <page>
    <title>BTO</title>
    <id>7</id>
    <revision>
      <id>36</id>
      <timestamp>2007-09-03T10:16:32Z</timestamp>
      <contributor>
        <ip>10.231.2.2</ip>
      </contributor>
      <comment>Redirecting to [[Build-to-order]]</comment>
      <text xml:space="preserve">#REDIRECT [[build-to-order]]</text>
    </revision>
  </page>
  <page>
    <title>BTO-QUEUE</title>
    <id>1047</id>
    <revision>
      <id>7088</id>
      <timestamp>2015-11-13T02:46:06Z</timestamp>
      <contributor>
        <username>J1016974</username>
        <id>22</id>
      </contributor>
      <minor/>
      <comment>/* QUEUE */</comment>
      <text xml:space="preserve">[[Category:Core]][[Category:Flow]]
{| align=&quot;top&quot;
   | __TOC__
   |}


==QUEUE==

Queue concept is introduced in BTO to make execution process committed, task by task. i.e. if two tasks (say A &amp; B)are connected via a queue path, then after completion of execution of task ‘A’, it  committed result till Task ‘A’, put things into queue of task ‘B’. So now if task ‘B’ is failing due to some reason then entries will be in queue, waiting until completed by Task B.  But will never execute task A as it was completed and committed. 

Queue concept is mainly dealing with two BTO application assemblies. 
&lt;br&gt; a&gt;	QUESPUT: Responsible for PUTting entries into queue.
&lt;br&gt; b&gt;	QUESDISP: Responsible for DISPatching entries from queue.

[[File:Pic1.0.jpg]]


In pic1.0 we can see task ‘ORDCHK5’ and ‘VALIEXT7’ are connected through each other in queue mode. 
&lt;br&gt;'''Note: if the the connection path is a dotted one, then connection is in QueuePath, where as if the connection is a straight line (pic1.1) then connection is in FastPath.'''

[[File:Pic1.1.jpg]]


So based on pic1.0, please find details of those tasks:
As we can see in pic1.2, task ‘ORDCHK5’ is configured with ‘QUESPUT-Q1’. i.e. QUESPUT dll will put the entries into ‘Q1’ for task ‘ORDCHK5’ and then ORDCHK5 will start execution.

If execution completed then QUESDISP dll will make entries out from queue Q1 for task ‘ORDCHK5’ so that next task’s QUESPUT dll will fetch those and enter into corresponding queue (if connection is in queue mode). If execution fails then entry will be inside Q1 only with task ‘ORDCHK5’

Let say ‘ORDCHK5’ task executed entries successfully. So QUESDISP.dll will make entries out of Q1 for task ‘ORDCHK5’ and make it available for next task. In our case the next task is ‘VALIEXT7’. As per pic1.3, this task is configured with ‘QUESPUT-Q2’. Therefore QUESPUT dll will fetch entries into Q2 for task ‘VALIEXT7’.  

Now let say due to some reason, ‘VALIEXT7’ task failed to execute the entries. Hence execution will not proceed further and stuck at queue ‘Q2’ for task ‘VALIEXT7’, until it process the entry.

[[File:Pic1.2.jpg]]

[[File:Pic1.3.jpg]]


===Tables associated with QUEUE===
 a&gt;	QUEUE : Contains details of all entries in all queue.
 b&gt;	QUESTAT : Contains PUT (QUESPUT) and GET (QUESDISP) details of all queue with respect to task (grouped by Workdate, Model, Plant, Task, Priority)


'''QUESTAT Table:'''

[[File:Pic1.4.jpg]]


As per pic1.4, we have fetched records from QUESTAT table for queue id ‘Q2’.


Certain things please notice:
&lt;br&gt; 1&gt;	PUT -&gt; VALIEXT7 -&gt; ORD101-&gt;(BTSTAMP) 2015-08-01:19:32:37.972001 -&gt; (LTSTAMP) 2015-08-01-19:32:37.972001 -&gt; (Handle Count) 1
&lt;br&gt; 2&gt;	GET -&gt; VALIEXT7 -&gt; ORD101-&gt;(BTSTAMP) 2015-08-01:19:34:37.980001 -&gt; (LTSTAMP) 2015-08-01:19:34:37.980001 -&gt; (Handle Count) 1

From Point 1, we can see there is only one entry (Handle Count) PUT into Q1. The entry process starts, for current WORKDATE, at  ‘2015-08-01:19:32:37.972001’ (BTSTAMP) and last entry to this queue is at 2015-08-01:19:32:37.972001 (LTSTAMP).

From point 2, we can see there is only one entry (Handle Count) GET from Q1. The dispatch process begins at ) 2015-08-01:19:34:37.980001 (BTSTAMP) and last entry it dispatched at ) 2015-08-01:19:34:37.980001 (LTSTAMP). 

'''Note: After successful GET operation, the ORDNR will be in next task’s queue (PUT of NEXT connected task).'''

So here we can see the PUT &amp; GET handle counts are same i.e. 1. This means one entry came into the queue and got processed and out of queue Q1 for task ‘VALIEXT7’. 

If Handle Count for both PUT and GET are same for the same task then no entry will be there in QUEUE table for the same task with same queue.

'''Now let’s have another example:'''

[[File:Example.jpg]]


In above example , one order PUT successfully into queue ‘Q3’  for task ‘EJISDD6’, but not yet processed. Hence it doesn’t have GET operation from QUESTAT table and also we can see the same task is stuck in QUEUE table.

In above case, so many reason because of which entry has not processed from queue. They are:
&lt;br&gt; a&gt;	May be the Q3 is not configured in CSLCFG table.
&lt;br&gt; b&gt;	May be the configuration is wrong. E.g. server application field in CSLCONFIG.exe is ‘QUESPDISP’ instead of ‘QUESDISP’ .
&lt;br&gt; c&gt;	Finally, may be some error in this order, we have to check ERRORLOG table and findout.

In above case, Point 1 is satisfying. Queue Q3 is not configured in CSLCFG. Please find below screenshot, only Q2 is configured and nothing else.

[[File:Pic1.6.jpg]]


Now let’s look into an interesting example.  Please observe the below screenshot properly:

We can see that, the Handle Count value is mismatch for PUT and  GET operations for Queue Q2. Let’s explain this.

&lt;br&gt; Q2 -&gt; PUT -&gt; VALIEXT7 -&gt; ORD103 (Ordnr) -&gt; 2015-08-01-19:32:37.972001 (BTSTmp) -&gt; 2015-08-01:21:56:00.292002 (LTSTmp) -&gt; 3 (Handle Count).
&lt;br&gt; Q2 -&gt; GET -&gt; VALIEXT7 -&gt; ORD101-&gt;(BTSTmp) 2015-08-01:19:34:37.980001 -&gt; (LTSTmp) 2015-08-01:19:34:37.980001 -&gt; (Handle Count) 1

[[File:Pic1.7.jpg]]


This means, PUT operation has started for WORKDATE ‘2015-08-01’ for TASK ‘VALIEXT7’ at ‘2015-08-01-19:32:37.972001’. But latest entry processed into Q2 for task ‘VALIEXT7’ on WORKDATE ‘2015-08-01’ is ORD103 at LTSTAMP ‘-&gt; 2015-08-01:21:56:00.292002’ . 

And GET operation has started for WORKDATE ‘2015-08-01’ for TASK ‘VALIEXT7’ at ‘2015-08-01:19:34:37.980001’. But latest entry processed from Q2 for task ‘VALIEXT7’ on WORKDATE ‘2015-08-01’ is ORD101 at LTSTAMP ‘2015-08-01:19:34:37.980001’ . 


'''Note: We can see there are 3 inputs so far into Q2 for task ‘VALIEXT7’ on ‘2015-08-01’. We can see the first input processed from Q2 on current work date is ORD101. And the latest entry entered into Q2 on current work date is ORD103. And we can’t see the intermediate entries in queue (here ORD102) . This entry we can see from QUEUE table.'''

And once ‘VALIEXT7’ task processed these 2 pending entry in Q2. QUESTAT table HANDLECOUNT column will again becomes 3 for both PUT and GET operations.

Okay, now consider due to some reason ORD102 is processed and then queue stops. So the QUESTAT and QUEUE table entry becomes:

[[File:Pic1.8.jpg]]

Here we can see in GET operation, the Last processed order is ‘ORD102’. And from QUEUE table we can see that ORD103 is still pending in Q2.

'''Note: Apart from PUT &amp; GET, there is another operation called ADJ (Adjust).''' 

When the WORKDATE value for order entry (PUT) and order dispatch (GET) are different, then last days PUT operations are changed to ADJ. 
i.e. PUT and GET can see if WORKDATE of both are same, else PUT become ADJ for next WORKDATE.



==Queue Timings and Delay==
'''Queue Idle Time:''' While queue set-up every queue is configured with an IDLE time (in sec). This is the amount of time queue will sit idle if nothing is to process through it.'''e.g.''' If queue idle time is 120 seconds, then queue will sit idle for 2 minutes if nothing to process through it. After 2 minutes it checks for any task and if found then starts processing it else again sit for 2 minutes idle. &lt;br&gt;'''Note:'''Mean time if QUESPUT program puts some task into queue, then the queue will start processing it immediately without wait till laps of idle time.
&lt;br&gt;&lt;br&gt;
'''Queue Retry:''' While processing, if some error occurred, then queue will become idle and retry after double the IDLE time.'''e.g.''' If queue has idle time 120 seconds and it failed in between then it will retry processing again after 240 seconds.</text>
    </revision>
  </page>
  <page>
    <title>BTO .NET client</title>
    <id>526</id>
    <revision>
      <id>7987</id>
      <timestamp>2017-05-12T09:11:32Z</timestamp>
      <contributor>
        <username>Dbondare</username>
        <id>4</id>
      </contributor>
      <minor/>
      <text xml:space="preserve">= Introduction =
The [http://www.microsoft.com/net .NET Framework] is Microsoft's comprehensive and consistent programming model for building applications that have visually stunning user experiences, seamless and secure communication, and more. 

So, it is a modern, powerful technology providing a good abstraction over the most of existing OS/hardware, so developers can build powerful applications fast and keep it compatible.

But like any technology it has an ''entrance price'' - the price every company pays when starts to develop things in .NET. This price usually includes following items:
# (completed for 75%) investigate the .NET platform
# (completed for 65%) raise level of knowledge and experience of developers in new technology
# (completed for 65%) porting to .NET existing approaches we use in BTO applications
# (completed for 5%) find (and buy if required) appropriate tools/components for .NET&lt;br&gt;'''Note:''' candidates are:&lt;br&gt;* [http://www.devexpress.com DevExpress], recommended package is - [http://www.example.com DXperience™ Universal Subscription]

As you can see we still have to complete some things before we start use .NET in BTO in a full power.

To tell in simple words - we can develop in .NET simple BTO client applications like BTO.exe, Query, EasyLaunch, LogViewer, etc.

But to start developing in .NET applications like PlantCalendar, MDC/Materials, OCS and so on - we need to fully complete first 4 steps I have described above.

Such difference is exists because in case of .NET usage we have to spend a bit more efforts to:
* port existing (or find out what are the new) DayaLayer and GUI approaches from Delphi to .NET
* study typical approaches &amp; practices for .NET (at the moment our level in Delphi is better, so we need to catch up the same for .NET)

The page below describes a status and details of our progress on a way to move to .NET usage in BTO.

== Project History ==
* First version BTO.NET components and and demo client (''Query-Net.exe'') was implemented by [[User:Dbondare]] at mid of 2008.&lt;br&gt;Draft plan, further actions and recommendations was defined about September 2008.
* At ''Dec 2008 - Jan 2009'' Yemi worked on some aspects of BTO.NET components, implemented draft versions of EML, AboutBox, ProgressBar, TAnimationControl components.
* At ''Jun 2010 - Jul 2010'' [[User:Dbondare]] fixed some more issues and released 2 .NET assemblies - ''BtoComponents.dll'' and ''BtoControls.dll'' for internal usage.&lt;br&gt;In particular:
** Implemented ''DDS'' (Dynamic Data Structures) component, which is a storage for BTO communication data structures (request/reply data structures).
** Prepare template of BTO.NET client
** Wrote a kind of ''BTO.NET Quick Start'' manual in wiki (this page)
** Implemented BTO logon form + C# code. Use the ''BtoSecurity'' class. See also example in ''BtoTestApp_04.zip'' .NET project.

== Known Issues ==
This description and sample project still do not cover:
* Progress bars&lt;br&gt;Them are still have some bugs
* Errors handling&lt;br&gt;At the moment we do not have clear descriptions/recommendations on this topic 
* We still use ''win32 DLLs'' in BTO.NET - csl32.dll + csl32tan.dll&lt;br&gt;So, our BTO.NET is a wrapper over ''win32'' csl32*.dll files.&lt;br&gt;It is in plans to implement normal CSL.NET components.
* System BTO logon (which is using a Windows user ID) still not supported. So, it can only logon using a typical BTO logon window.

'''Note:''' because of ''win32 DLLs'' we using in a project we have to avoid using ''Platform Target''=''Any CPU'' in our .NET projects; it should be set to ''Platform Target''=''x86'', otherwise it will fail to start on 64-bit platforms (for example on my PC I'm using Win7 x64 and facing such issue all the time).

But I hope to provide and description and updated project sample soon.

== Experiments with .NET and Related Technologies ==

=== Windows Azure and The Cloud ===
I have developed a simple Windows Azure application (consists of some WebRoles and WorkerRoles) which are able to:
* do the FTP import of EDI messages (or files) and store them in a database (like we have FTPSRCV in BTO)
* do the CSL-to-WCF protocol wrapping, so the .NET service is listening for CSL requests, wraps them into a WCF package and send to a Azure Service in a Cloud

On the the ''Azure/Cloud'' way I have faced following challenges:
* it is not clear how to deal with db transactions in a ''Cloud'' because WebRoles and WorkerRoles in application are state-less, so it is not predictable which role instance will handle the next request.

It looks like that it is a bit &quot;hard&quot; to fit the current BTO architecture into a ''Cloud''. So, the only way to fit is - to adjust the BTO architecture and business model.

== Using .NET in BTO ==

=== Creating a New Project of BTO Client Applciation in .NET ===
Create a New ''Windows Forms'' .NET project in Visual Studio 2005/8.

Ensure to add references to following BTO .NET assemblies:
* BtoComponents.dll
* BtoControls.dll

Ensure to click ''Project Properties'', on the ''Build'' tab, select the ''Platform Target'' = ''x86''.

'''Note:''' otherwise it will not work on x64 platforms! We still use csl32*.dll which is Win32 library, so we have to set ''Platform Target'' to ''x86''. 
Because ''Platform Target'' = ''Any CPU'' means - run application as x64 on 64bit platforms which makes all Win32 libraries fail.

You can take them from ''R:\PowerB2O\.Beta\.NET\''. Better to use a local copy of that files, for example - in a ''bin'' directory of your project.

Please ensure to add &quot;using BTO.Components;&quot; to your code which is supposed to use BTO components.

'''Note:''' last update of .NET binaries on R: is ''July 16, 2010''. Please ensure you are using latest!

=== Adjusting Project ===
==== Preparing GUI ====
Rename main form (file and object) to the ''FormMain''.

Add MainStrip, ToolStrip, StatusStrip components to main form.

Ensure to create appropriate panels in the StatusStrip component:
* Connected/Disconnected. Width = 95. Recommended name = stConnectionStatus
* IP : port. Width = 150. Recommended name = stBtoHostAddress
* System - PathMon. Width = 125. Recommended name = stCslSystem
* model/plant. Width = 85. Recommended name = stBtoModelPlant
* (all other up to you)
'''Note:''' please ensure all ''ToolStripStatusLabel'' components has properties:
* AutoSize=False
* BorderSides=All
* BorderStyle=SunkenOuter

==== Add CslSession Component ====
In the ''Visual Studio'' click menu -&gt; View -&gt; Toolbox, right click the ''Toolbox'' panel, select ''Choose Items...''.
Click [Browse...] button, select the ''BtoComponents.dll'', click [Open], click [Ok], there will be a new component on a ''Toolbox'' panel - ''CslSession''. 
Drop the ''CslSession'' coponent on your form. Optionally, rename it to ''cslEngine''.

'''Note:''' it is also ok to create CslSession component dynamically in code, like this:
&lt;syntaxhighlight lang=&quot;csharp&quot;&gt;

private BTO.Components.CslSession cslEngine = null;

// in the handler of Form_Load event add this:
this.cslEngine = new BTO.Components.CslSession(this.components);
&lt;/syntaxhighlight&gt;

==== Add Some &quot;Typical&quot; BTO Code ====
Create a ''Load'' event handler for the ''FormMain'' and put there a code:
&lt;syntaxhighlight lang=&quot;csharp&quot;&gt;
  cslEngine.Active = true;
  updateConnectionStatus();
&lt;/syntaxhighlight&gt;

Then ensure to add a code of ''updateConnectionStatus()'' method:
&lt;syntaxhighlight lang=&quot;csharp&quot;&gt;
        private void updateConnectionStatus()
        {
            stConnectionStatus.Text = cslEngine.Connected ? &quot;Connected&quot; : &quot;Disconnected&quot;;
            if (cslEngine.Connected)
            {
                stBtoHostAddress.Text = string.Format(&quot;{0}:{1}&quot;, cslEngine.Address, cslEngine.Port);
                stCslSystem.Text = string.Format(&quot;{0} - {1}&quot;, cslEngine.System, cslEngine.PathMon);
                stBtoModelPlant.Text = string.Format(&quot;{0} / {1}&quot;, BtoAppSettings.Settings.Model, BtoAppSettings.Settings.Plant);                  
            }
            else
            {
                stBtoHostAddress.Text = &quot;-&quot;;
                stCslSystem.Text = &quot;-&quot;;
                stBtoModelPlant.Text = &quot;-&quot;;
            }
        }
&lt;/syntaxhighlight&gt;

Ensure ''EasyLaunch'' pointing to the right BTO environment, start your application, enjoy the empty BTO .NET client application. As you can see it displays correct CSL connection status, CSL host parameters and Model, Plant parameters.

=== Sample Project ===
You can use as a template following project: ''R:\PowerB2O\.Beta\.NET\BtoTestApp_01.zip''

=== Useful Code Samples ===
==== Convert TSql resultset to DataSet ====
&lt;syntaxhighlight lang=&quot;csharp&quot;&gt;
        private void SqlApiToDataSet(TSql pSql, ref DataSet pDs)
        {
            pDs.BeginInit();
            try
            {
                pDs.Reset();
                DataTable tab = null;
                if (pDs.Tables.Count == 0)
                    tab = pDs.Tables.Add(&quot;Table1&quot;);
                else
                    tab = pDs.Tables[0];

                tab.Columns.Clear();
                for (int i = 0; i &lt; pSql.FieldDefsCount; i++)
                {
                    TSql.FieldDescriptor field = pSql.FieldDefs[i];
                    DataColumn dc = tab.Columns.Add(field.Name);
                    dc.DataType = typeof(string);
                }

                pSql.First();
                while (!pSql.EOF)
                {
                    List&lt;object&gt; items = new List&lt;object&gt;();
                    for (int i = 0; i &lt; pSql.FieldDefsCount; i++)
                    {
                        items.Add(pSql.Fields[i].AsString);
                    }
                    tab.Rows.Add(items.ToArray());

                    pSql.Fetch();
                }
            }
            finally
            {
                pDs.EndInit();
            }
        }
&lt;/syntaxhighlight&gt;

==== Execute CSL Request in BackgroundWorker object and display a ProgressBar ====
&lt;syntaxhighlight lang=&quot;csharp&quot;&gt;
        public void Execute()
        {
            Trace.WriteLineIf(FormMain.TrcLvl.TraceVerbose, FormMain.TrcLvl.TraceVerbose ? string.Format(
                &quot; * Execute()&quot;) : &quot;&quot;);

            stLab1.Text = &quot;Opening...&quot;;
            stLab2.Text = string.Format(&quot;{0} {1}&quot;, DateTime.Now.ToShortDateString(), DateTime.Now.ToShortTimeString());
            statusStrip1.Refresh();
            this.bsData.DataMember = null;
            using (BackgroundWorker bwExecute = new BackgroundWorker())
            {
                bwExecute.DoWork += new DoWorkEventHandler(this.bwExecute_DoWork);
                FormProgress.ShowProgress(this.Parent as Form, &quot;Open query...&quot;, false, 0, bwExecute);
                try
                {
                    if (FormProgress.WorkResult.Result is Exception)
                        throw (Exception)FormProgress.WorkResult.Result;

                    Trace.WriteLineIf(FormMain.TrcLvl.TraceVerbose, FormMain.TrcLvl.TraceVerbose ? string.Format(
                        &quot; * Execute: displaying data...&quot;) : &quot;&quot;);

                    dgQuery.AutoGenerateColumns = true;
                    this.bsData.DataMember = this.dsData.Tables[0].TableName;
                    this.bsData.ResetBindings(true);
                    dgQuery.Refresh();

                    stLab1.Text = &quot;Ready.&quot;;
                    string descr = string.Format(&quot;{0} rows. Updated {1} {2}&quot;,
                        dsData.Tables[0].Rows.Count, DateTime.Now.ToShortDateString(), DateTime.Now.ToShortTimeString());
                    stLab2.Text = descr;
                    item.Description = descr;
                    statusStrip1.Refresh();
                }
                catch (Exception exc)
                {
                    Trace.WriteLineIf(FormMain.TrcLvl.TraceVerbose, FormMain.TrcLvl.TraceVerbose ? string.Format(
                        &quot; * Execute: {0} {1}&quot;, exc.GetType(), exc.Message) : &quot;&quot;);
                    stLab1.Text = &quot;Error!&quot;;
                    stLab2.Text = exc.Message;
                    statusStrip1.Refresh();
                }
            }
        }

        private void bwExecute_DoWork(object sender, DoWorkEventArgs e)
        {
            Trace.WriteLineIf(FormMain.TrcLvl.TraceVerbose, FormMain.TrcLvl.TraceVerbose ? string.Format(
                &quot;--- bwExecute_DoWork: running...&quot;) : &quot;&quot;);
            try
            {
                string sql_stmt = PrepareSql(txtSQL.Text);
                this.Engine.OpenSQL(sql_stmt);
                FormProgress.SetProgressorText(sql_stmt);
                SqlApiToDataSet(this.Engine, ref this.dsData);
                if (this.item.Owner.SaveDataXml || this.item.Owner.SaveDataScheme)
                {
                    counter++;
                    try
                    {
                        string fn = string.Format(&quot;{0}\\$data-{1}&quot;, this.item.Owner.PathToDataXml, item.Name);
                        if (this.item.Owner.SaveDataXml) dsData.WriteXml(fn + &quot;.xml&quot;);
                        if (this.item.Owner.SaveDataScheme) dsData.WriteXmlSchema(fn + &quot;.xsd&quot;);
                    }
                    catch { }
                }
                e.Result = true;
            }
            catch (Exception exc)
            {
                Trace.WriteLineIf(FormMain.TrcLvl.TraceError, FormMain.TrcLvl.TraceVerbose ? string.Format(
                   &quot; ! SqlError! {0}: {1}&quot;, exc.GetType(), exc.Message) : &quot;&quot;);
                e.Result = exc;
            }
        }
&lt;/syntaxhighlight&gt;

==== Updating GUI from Other Threads ====
&lt;syntaxhighlight lang=&quot;csharp&quot;&gt;
        // this method could be called from everywhere ...
        private void notificationMethod(object pSender, string pInfo)
        {
            Trace.WriteLineIf(TrcLvl.TraceInfo, TrcLvl.TraceInfo ? string.Format(
                &quot; ! got notification from[{0}; {1}] ...&quot;, pSender.GetType(), pInfo) : &quot;&quot;);

            if (pSender == null) return;

            if (string.Compare(pInfo, &quot;Wait&quot;, false) == 0) 
                this.counters.wait++;
            else if (string.Compare(pInfo, &quot;Start&quot;, false) == 0) 
                this.counters.started++;
            else if (string.Compare(pInfo, &quot;Finish&quot;, false) == 0)
                this.counters.finished++;
            // [...]

            // this code invoking the GUI thread method and pass parameters you specified here
            this.BeginInvoke(new UpdateGuiMethod(this.updateGui), new object[] { pSender, pInfo, txtStatus, st});
        }

        // this is delegate (method prototype) to be used in GUI updating...
        internal delegate void UpdateGuiMethod(object pSender, string pInfo, TextBox pBox, string pText);

        private void updateGui(object pSender, string pInfo, TextBox pBox, string pText)
        {
            // only in this method is safe (and allowed) to update a GUI
            pBox.Text = pText;
            if (string.Compare(pInfo, &quot;Start&quot;, false) == 0)
            {
                chkAutoRelease.Enabled = btnRun.Enabled;
            }
            else if (string.Compare(pInfo, &quot;Finish&quot;, false) == 0)
            {
                btnRun.Enabled = (this.counters.finished &gt;= this.executors.Count);
                udThreads.Enabled = btnRun.Enabled;
                txtCounters.Enabled = btnRun.Enabled;
                txtLatchName.Enabled = btnRun.Enabled;
                // [...] 
            }
        }
&lt;/syntaxhighlight&gt;

==== Use a Tracing (Debug Logging) in Your .NET Application ====
'''Note:''' this is also a kind of ''backdoor'' to add any type/assembly to any .NET application - just specify if as a TraceListener (or any such kind of configuratble .NET service objects) in a *.config file.

1) Choose the place/object in your app where you will store the TraceLevel. It could be a number of trace levels - for different aspects.
For example you can have 2 separate trace levels for GUI and for DataLayer objects.

&lt;syntaxhighlight lang=&quot;csharp&quot;&gt;
    public class DataEngine
    {
        public static TraceSwitch TrcLvl = new TraceSwitch(&quot;DataEngine.LogLevel&quot;, &quot;DataEngine.LogLevel&quot;);
        // [...]
    }
&lt;/syntaxhighlight&gt;

2) The use trace write like this:
&lt;syntaxhighlight lang=&quot;csharp&quot;&gt;
    Trace.WriteLineIf(TrcLvl.TraceInfo, TrcLvl.TraceInfo ? string.Format(
        &quot; ! got notification from[{0}; {1}] ...&quot;, pSender.GetType(), pInfo) : &quot;&quot;);
&lt;/syntaxhighlight&gt;

3) Then, to make log file appears on a disk you need to define a trace listener in *.config file for your application:
&lt;syntaxhighlight lang=&quot;xml&quot;&gt;
    &lt;system.diagnostics&gt;
        &lt;switches&gt;
            &lt;add name=&quot;DataEngine.LogLevel&quot; value=&quot;4&quot; /&gt;
        &lt;/switches&gt;
        &lt;trace autoflush=&quot;true&quot; indentsize=&quot;4&quot;&gt;
            &lt;listeners&gt;
                &lt;add name=&quot;myListener&quot; type=&quot;System.Diagnostics.AdvancedTraceListener,XService.Net2&quot;
				  initializeData=&quot;~\$MyApp.log;LinePrefix=[P${PID}/T${TID}]&quot; /&gt;
            &lt;/listeners&gt;
        &lt;/trace&gt;
    &lt;/system.diagnostics&gt;
&lt;/syntaxhighlight&gt;

Pls ensure XService.Net2.dll assembly if located together with application, so it can find it.

'''Note:''' there are 5 trace levels - 0(none), 1(error), 2(warning), 3(info), 4(verbose).
So, value in *.config file defines a level. And the code like ''Trace.WriteLineIf(TrcLvl.TraceInfo, TrcLvl.TraceInfo ? string.Format( '' defines at what level this log record will be visible in a log file.

Examples:
* Trace.WriteLineIf(TrcLvl.TraceError, TrcLvl.TraceError ? string.Format( ... ):&quot;&quot;); - will be visable if log level=1
* Trace.WriteLineIf(TrcLvl.TraceWarning, TrcLvl.TraceWarning ? string.Format( ... ):&quot;&quot;); - will be visable if log level=2
* Trace.WriteLineIf(TrcLvl.TraceInfo, TrcLvl.TraceInfo ? string.Format( ... ):&quot;&quot;); - will be visable if log level=3
* Trace.WriteLineIf(TrcLvl.TraceVerbose, TrcLvl.TraceVerbose ? string.Format( ... ):&quot;&quot;); - will be visable if log level=4

'''Note:''' approach with ''TrcLvl.TraceInfo ? string.Format( ... ) : &quot;&quot;'' is used to avoid calculating log strings if log level is not match it.
So, for example - if log level=2(warning) then ''string.Format(...)'' in this code - ''TrcLvl.TraceInfo ? string.Format( ... ) : &quot;&quot;'' will not even executed which saves application execution resources, allows to avoid performance degradation on logging.

==== BTO Logon ====
Here is the example how to do BTO logon:

&lt;syntaxhighlight lang=&quot;csharp&quot;&gt;
        private void FormMain_Load(object sender, EventArgs e)
        {
            cslEngine.Active = true;
            updateConnectionStatus();
            if (this.useBtoLogon)
            {
                BtoSecurity security = new BtoSecurity(this.cslEngine, &quot;QUERY&quot;);
                bool isOk = security.Logon();
                if (isOk)
                {
                    isOk = security.IsPrivilegeGranted(&quot;QUERY-R&quot;);
                }
                if (!isOk)
                {
                    MessageBox.Show(&quot;You are not authorized to run this program.&quot;, &quot;Error&quot;, MessageBoxButtons.OK, MessageBoxIcon.Error);

                    this.Close();
                    Application.Exit();  
                    return;
                }
                stInfo.Text = security.UserName;  
            }
        }
&lt;/syntaxhighlight&gt;

'''Note:''' the ''BtoSecurity'' class still in a ''draft'' stage but it works, so inputs/feedbacks and how to improve all are welcome.


==== Call BTO Server ====
If you need to call a typical task on ''business flow'' you can use following code:

&lt;syntaxhighlight lang=&quot;csharp&quot;&gt;
        private void callBtoServer()
        {
            try
            {
                string srvClassName = &quot;EJISORCH&quot;;
                BtoServerStructure stRequest = BtoServerStructure.NewRequest(null);
                BtoServerStructure stReply = BtoServerStructure.NewStandardReply();
                // assume FormRequest.Execute(...) ask user for all Standard Request parameters and store all entered values in stRequest structure instance
                if (FormRequest.Execute(this, stRequest, ref srvClassName))
                {
                    ushort nReplySz = 0;
                    byte[] replyData;
                    cslEngine.ServerClassName = srvClassName;

                    stRequest.ClientToHost();

                    cslEngine.Send(stRequest.RawData, (ushort)stRequest.StructType.DataSize,
                        out replyData, out nReplySz, (ushort)stReply.StructType.DataSize);
                    stReply.LoadRawData(replyData);
                    
                    stReply.HostToClient();

                    string info = string.Format(
                        &quot;Reply( RC:{0}; TxCommitted:{1}; MsgId:{2} )&quot;,
                        stReply[&quot;nRC&quot;], stReply[&quot;isTxCommitted&quot;], stReply[&quot;lMsgId&quot;]);

                    MessageBox.Show(info, string.Format(&quot;BTO Server Successfully Called. Info: {0}&quot;, info),
                        MessageBoxButtons.OK, MessageBoxIcon.Information);
                }
            }
            catch (Exception exc)
            {
                MessageBox.Show(string.Format(&quot;{0}: {1}&quot;, exc.GetType(), exc.Message), &quot;Error&quot;, 
                    MessageBoxButtons.OK, MessageBoxIcon.Stop);
            }
        }
&lt;/syntaxhighlight&gt;

If you need to call ''dedicated server'' or call a task on ''business flow'' with non-standard request/reply structures then you need to describe data structures in a application config file or in your code:

&lt;syntaxhighlight lang=&quot;csharp&quot;&gt;
        // you can just copy data structure definitions from C/C++ include files
        protected const string BTO_LOGON_STRUCTURES = &quot;&quot; +
            &quot;typedef struct tag_TReqLogon { &quot; + 
            &quot;  TEuroReqHdr EuroReqHdr; &quot; + 
            &quot;  char szAppName[33]; &quot; + 
            &quot;  char szAppVer[17]; &quot; + 
            &quot;} TReqLogon; &quot; + 
            &quot; &quot; +
            &quot;struct usr_type { &quot; +
            &quot;  char  model[5]; &quot; +
            &quot;  char  plant[5]; &quot; +
            &quot;  char  userid[9]; &quot; +
            &quot;  char  passw[35]; &quot; +
            &quot;  long  options; &quot; +
            &quot;  char  psswlchg[27]; &quot; +
            &quot;  char  usernr[11]; &quot; +
            &quot;  char  deptmt[17]; &quot; +
            &quot;  char  printid[17]; &quot; +
            &quot;  char  jobtitle[33]; &quot; +
            &quot;  char  username[41]; &quot; +
            &quot;  char  email[101]; &quot; +
            &quot;  char  descr[101]; &quot; +
            &quot;  char  acckey[17]; &quot; +
            &quot;}; &quot; +
            &quot; &quot; +
            &quot;typedef struct tag_TRepLogon { &quot; + 
            &quot;  TEuroRplHdr EuroRplHdr; &quot; + 
            &quot;  short nSqlCode; &quot; +
            &quot;  char szTableName[9]; &quot; +
            &quot;  char _filler1; &quot; +
            &quot;  struct usr_type UserRec; &quot; + 
            &quot;} TRepLogon;&quot; +  
            &quot; &quot; + 
            &quot;&quot;; // ... you can add more structures if required - all to a single string

        // this is example how to call dedicated BTO server (in this case - EJISPRIV)
        internal EErrorCodes SendLogonRequest(string pUserName, string pPassword, out string pErrMsg)
        {
            pErrMsg = &quot;&quot;;
            try
            {
                // check if definitions of required data structures loaded or not...
                if (StructureDefinitions.Instance.FindStruct(&quot;TReqLogon&quot;) == null)
                {
                    // call NewStandardRequest to ensure standard Request/Reply structure loaded
                    BtoServerStructure.NewStandardRequest();
                    // load security specific structures if still not loaded (here you are loading your data structure definitions)
                    if (StructureDefinitions.Instance.FindStruct(&quot;TReqLogon&quot;) == null)
                        StructureDefinitions.Instance.Load(BTO_LOGON_STRUCTURES);
                }
                
                // create request,reply structure for logon request
                BtoServerStructure stRequest = BtoServerStructure.NewRequest(&quot;TReqLogon&quot;);
                BtoServerStructure stReply = BtoServerStructure.NewReply(&quot;TRepLogon&quot;);
                if (this.stUserInfo == null)
                    this.stUserInfo = BtoServerStructure.NewRequest(&quot;usr_type&quot;);

                string srvClsName = this.cslEngine.ServerClassName;
                this.cslEngine.ServerClassName = &quot;EJISPRIV&quot;;

                bool isOk = false;
                this.cslEngine.BeginTransaction(); 
                try
                {
                    ushort nReplySz = 0;
                    byte[] replyData = null;

                    stRequest[&quot;EuroReqHdr.szModel&quot;] = BtoAppSettings.Settings.Model;
                    stRequest[&quot;EuroReqHdr.szPlant&quot;] = BtoAppSettings.Settings.Plant;
                    stRequest[&quot;EuroReqHdr.szUserId&quot;] = pUserName;
                    stRequest[&quot;EuroReqHdr.szTaskFunctionName&quot;] = FUNC_SECURITY_LOGON;
                    stRequest[&quot;EuroReqHdr.szRecvTime&quot;] = BtoUtils.DateTimeToNskTimestamp(DateTime.Now);
                    stRequest[&quot;szAppName&quot;] = this.appName;
                    if (!string.IsNullOrEmpty(this.appVersion))
                        stRequest[&quot;szAppVer&quot;] = this.appVersion;

                    stRequest.ClientToHost();

                    this.cslEngine.Send(stRequest.RawData, (ushort)stRequest.StructType.DataSize,
                        out replyData, out nReplySz, (ushort)(stReply.StructType.DataSize + 100));
                    stReply.LoadRawData(replyData);

                    stReply.HostToClient();

                    stUserInfo.LoadRawData(stReply.ExtractRawDataOf(&quot;UserRec&quot;)); // extract single field as raw-data and load into a separate structure instance (stUserInfo)

                    int responseCode = (int)stReply[&quot;EuroRplHdr.lMsgId&quot;];
                    switch (responseCode)
                    {
                        case (int)EErrorCodes.ERROR_OK:
                            pErrMsg = string.Format(&quot;Logon Success&quot;);
                            isOk = ComparePassword(pPassword, (string)stUserInfo[&quot;passw&quot;]);
                            break;
                        case (int)EErrorCodes.ERROR_SQL:
                            pErrMsg = string.Format(&quot;Cannot retrieve user information from the table {0}. SqlCode: {1}&quot;, stReply[&quot;szTableName&quot;], stReply[&quot;nSqlCode&quot;]); 
                            break;
                        case (int)EErrorCodes.ERROR_WRONGFUNCTION:
                            pErrMsg = string.Format(&quot;Incorrect request type {0}&quot;, stRequest[&quot;EuroReqHdr.szTaskFunctionName&quot;]);
                            break;
                        case (int)EErrorCodes.ERROR_WRONGAPPLICATION:
                            pErrMsg = string.Format(&quot;Application version is incorrect&quot;, this.appName);
                            break;
                        case (int)EErrorCodes.ERROR_WRONGUSER:
                            pErrMsg = string.Format(&quot;Incorrect user name or password&quot;);
                            break;
                        case (int)EErrorCodes.ERROR_CHANGEPASSWORD:
                            pErrMsg = string.Format(&quot;Your password has expired. Please change your password&quot;);
                            break;
                        case (int)EErrorCodes.ERROR_TAMPER_ATTEMPT:
                            pErrMsg = string.Format(&quot;Tamper attempt detected&quot;);
                            break;
                        case (int)EErrorCodes.ERROR_RESTRICTED:
                            pErrMsg = string.Format(&quot;You cannot logon because of restrictions&quot;);
                            break;
                        default:
                            pErrMsg = string.Format(&quot;Unknown host error&quot;);
                            break;
                    }

                    try { if (this.cslEngine.Transaction) this.cslEngine.EndTransaction(); }
                    catch { }

                    return (EErrorCodes)responseCode;
                }
                finally 
                {
                    this.cslEngine.ServerClassName = srvClsName;
                }
            }
            catch (Exception exc)
            {
                pErrMsg = string.Format(&quot;ERROR({0}): {1}&quot;, exc.GetType(), exc.Message);

                try { if (this.cslEngine.Transaction) this.cslEngine.AbortTransaction(); }
                catch { }
            }
            return EErrorCodes.ERROR_GENERIC;
        }
&lt;/syntaxhighlight&gt;

In this example (see above) data structures defined directly in a C# code as a string constant.
But also you can overwrite any of your structures using definitions in application config file:

&lt;syntaxhighlight lang=&quot;xml&quot;&gt;
&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot; ?&gt;
&lt;configuration&gt;
  &lt;configSections&gt;
    &lt;section name=&quot;BtoStructures&quot; type=&quot;BTO.Components.BtoStructuresConfig,BtoComponents&quot; /&gt;
  &lt;/configSections&gt;
  &lt;BtoStructures&gt;
    typedef struct tag_ExtDedicatedProtocol
    {
      char  sign[4];                    /// must be &quot;DSRQ&quot;
      unsigned long extra_data_size;    /// size of extra data in request
      unsigned long extra_data_crc;     /// CRC32 of extra data in request
      unsigned long awaited_reply_size; /// awaited reply size
    }
    TExtDedicatedProtocol;

    typedef struct tag_SrvCommRequest
    {
      TEuroReqHdr header;
      TExtDedicatedProtocol extention;
      char szExtraData[29864];
    }
    TSrvCommRequest;
  &lt;/BtoStructures&gt;
&lt;/configuration&gt;
&lt;/syntaxhighlight&gt;

Details:

* The components used to parse data structure definitions, create structure instances and access data are located in the ''BTO.Components.DDS'' namespace.&lt;br&gt;Here are the list of public classes to be used for such purposes: 
** ''StructureDefinitions'' - is a singleton, use the ''StructureDefinitions.Instance'' to access all defined structures and so on
** ''StructureDefinition'' - this object never created directly, use the ''StructureDefinitions.Instance'' to access collection of loaded ''StructureDefinition'' objects
** ''StructureField'' - this object never created directly, use the ''Fields'' property of ''StructureDefinition'' object to access fields defined in a structure
** ''StructureInstance'' - this object never created directly, use the ''New()'' method of ''StructureDefinition'' object to create a new instance of data structure
* Usually you do not need to create DDS objects directly, use the static methods of ''BtoServerStructure'' class to create structure instances you need.&lt;br&gt;For example:
** public static BtoServerStructure NewStandardRequest()
** public static BtoServerStructure NewStandardRequest(string pModel, string pPlant, string pOrdNr, string pSubProd, string pTask)
** public static BtoServerStructure NewStandardReply()
** public static BtoServerStructure NewStandardReply(short pRc, short pTx, int pMsgId, uint pExtraDataSize)
** public static BtoServerStructure NewRequest(string pTypeName)
** public static BtoServerStructure NewReply(string pTypeName)

'''Note:''' the call to ''BtoServerStructure.NewStandardRequest()'' is a typical way to load also all data structure definitions from a application config file.

DDS limitations are:
* Pointers are not supported (it has no sense to send pointers over network)
* You should define all used structure types before using them as a field type in a structure.&lt;br&gt;'''Note:''' if structure ''TReqLogon'' structure need to have a field of ''struct usr_type'' then the ''struct usr_type'' structure must be defined in a ''source'' before the ''TReqLogon'' structure defined.
* Structure cannot be defined ''in-place'' - inside another structure.&lt;br&gt;'''Note:''' so, you cannot have ''struct myType1 { struct myType2 { int a,b; } myField; };''. You should have ''struct myType2 { int a,b; }'' defined first and only then define a field of myType2 in the myType1 - ''struct myType1 { struct myType2 myField; };''.&lt;br&gt;So, this is a difference between how structures can be defined in C/C++ and how how must be defined in BTO.NET application.
* Multi-dimensional arrays are not supported.&lt;br&gt;'''Note:''' so, you can have only single-dimension arrays in your structures.

[[Category:BTO Internals]]
[[Category:Development]]</text>
    </revision>
  </page>
  <page>
    <title>BTO 2010.1 TEMP</title>
    <id>498</id>
    <revision>
      <id>2348</id>
      <timestamp>2010-06-21T11:19:26Z</timestamp>
      <contributor>
        <username>RP-NCO</username>
        <id>6</id>
      </contributor>
      <minor/>
      <comment>Placeholder for 2010.1 release notes</comment>
      <text xml:space="preserve">{| align=&quot;right&quot;
  | __TOC__
  |}
= Release =

{{Contentmissing}}

= Requirements =
== HardWare Requirements == 
=== Servers ===
On the server side, RedPrairie BTO requires either a [[HP NonStop Server|HP NonStop™]] or a [[Microsoft Windows|Windows 20XX]] server. The hardware
requirements depend on the size and complexity of the BTO installation. The requirements specified here are the
minimum requirements.
==== HP NonStop™ server ====
* S74 or higher
* RAM: 256 MB per CPU
* 8 GB per project of hard disk space
==== HPuX™ server ====
* RAM: 256 MB per CPU
* 8 GB per project of hard disk space
==== RedHat Linux™ server ====
* S74 or higher
* RAM: 256 MB per CPU
* 8 GB per project of hard disk space
==== Windows 2000/2003/2008 server ====
* Processor speed: ? GHz
* RAM: ? GB
* 80 GB per project of hard disk space
* Raid Controller with write cache. Raid disk configured in level 5/6
* CD-ROM Drive

=== Clients ===
On the client side, ALTA PowerB2O runs on a PC with [[Microsoft Windows|Windows 2000/XP]] operating system.
==== Windows 2000/XP client ====
* Pentium 3 or newer, 600 MHz
* RAM: 128 MB
* 300 MB free disk space
* TCP/IP.


== Software requirements ==
=== Servers ===
The software requirements on the server side depend on the chosen platform.
==== HP NonStop™ server ====
* Operating system: Guardian G06.22 or higher
* HP NonStop SQL/MP D30
* ALTA CSL, version 2.0
* Pathway TS/MP
* TCP/IP
* Spooler
==== HPuX™ server ====
*
*
==== RedHat Linux™ server ====
*
*
==== Windows 2000/2003 server ====
* Windows 2000/2003 server
* IBM DB2 Universal Database Workgroup Edition Version 9.5
* ALTA Transactions 3.0
* Pc-Duo client version 6.11 (Windows 2003 server: version 8.5) (5 users)
* NetSupport version 11.5

Windows Server 2008 ??

=== Clients ===
The following software requirements apply to the client side.
==== Windows 2000/XP client ====
* Windows 2000, min. service pack 3, or Windows XP, min. service pack 1

Windows Vista ??
Windows 7 ??

== Security Requirements ==

=== Windows Server ===
RedPrairie requirements for installing, maintaining and providing technical support on PowerB2O for the database platform and for the RedPrairie BTO software:
The User Account must:
* have rights to install the database platform according to the requirement from the vendor: E.g. [[IBM DB/2]] Universal Database installation requirements at http:\\www.ibm.com (Click link to see requirements) E.g: »User account requirements: 
# Act as part of the operating system 
# Create token object 
# Increase quotas 
# Lock pages in memory 
# Logon as service 
# Replace a process level token
* be a member of the local Administrators Group on the PowerB2O Server.
* have rights to operate with the Event Viewer of the Operating System like Application- / Security- / System Events.
* have full rights to install / modify / remove software on the Drives of the Server. This includes the Drive of the Operating System (drive C:) since several data have to beinstalled in folders of the Operating System. The DB2 are usually installed at C:\SQLLIB.
* have full rights to install / modify / remove / ‘logon as’ Services.
* have rights to run standard Operating Services and programs like: FTP, Telnet Sessions, File Explorer, etc.
* have access to a CD or DVD drive
* have information about Username and Password for the User Account used to install/run the RedPrairie BTOsoftware (e.g. BTO, DB/2, Oracle and other DB systems)
* have remotely access to the Servers (primary/secondary) using NetSupport or PCDUO (Vector Networks) remote access sw. Username and password must be given to the operating staff at RedPrairie whenever support is needed and thus the remote software must be enabled.


= Release notes =

Redprairie BTO® release 2010.1
''Release Notes''

== What's new ==
The scope of functionality introduced/added in module releases since [[BTO_2009.1|2009.1]] is as follows.

=== [[:Category:Core|Core Module]] ===

=== [[:Category:Shopfloor Management|Shopfloor Management module]] ===

=== [[:Category:Documents &amp; Reports|Documents &amp; Reports module]] ===

=== [[:Category:Dispatch Management|Dispatch Management module]] ===

=== [[:Category:Data Management|Data Management module]] ===

=== [[:Category:Order Management|Order Management module]] ===

=== [[:Category:Business Interfaces|Business Interfaces module]] ===

== Bugs corrected ==

= Compatibility =
The 2010.1 product release is partly compatible with [[BTO_2009.1|2009.1]]:
* Database has changed – please refer to corresponding migration guides for more details

= References =
* Installation manual for RedPrairie BTO™ 2010.1 on NSK
* Installation manual for RedPrairie BTO™ 2010.1 on Linux Redhat 15
* Installation manual for RedPrairie BTO™ 2010.1 on HP Unix
* Installation manual for RedPrairie BTO™ 2010.1 on Windows 2000/2003 Server
* Installation manual for RedPrairie BTO™ 2010.1 on Windows 2000/XP client

[[Category:Releases]]</text>
    </revision>
  </page>
  <page>
    <title>BTO Backup</title>
    <id>934</id>
    <revision>
      <id>5904</id>
      <timestamp>2014-06-02T13:57:22Z</timestamp>
      <contributor>
        <username>Dbondare</username>
        <id>4</id>
      </contributor>
      <comment>Created page with &quot;= BTO Backup Recommendations =  First – with my “business as usual”-hat on: We recommend to  * run a Daily Export of all tables (from BTO Maintain package) * run a Weekly M…&quot;</comment>
      <text xml:space="preserve">= BTO Backup Recommendations =

First – with my “business as usual”-hat on:
We recommend to 
* run a Daily Export of all tables (from BTO Maintain package)
* run a Weekly Maintain job for reorg + runstat + bind (from BTO Maintain package)
* run a DB2 Task for Online DB backup
* cleanup old/obsolete data in BTO on daily/weekly basis (when orders are produced and delivered, BTO can then archive and cleanup data)

But there are some potential issues with the two first tasks – they have to run in Offline mode.

I have investigated what we can change in Weekly Maintain , so it can run in Online mode, but it requires some code changes, QA, documentation etc.

With the “Daily Export” of a project can be used for building up the database for other project – but remember – they are by default having same Model and Plant values.
And besides of the exported data, we also need backup/copy of server side files like BIN/BIND/CSLMON/CLIENTS/MAINTAIN directories.

Recovery from “catastrophic failures” based on “old Daily Exports” (even a day old), can be really hard ; what about new orders in system , changes of current orders, changes to master data etc since that given “export” ?
There are different ways to get a better uptime &amp; recovery success, e.g. by using 2 individual servers with one-way-database-replication, but in theory a setup w VMWare and vMotion should also increase uptime.
Even though most of our customers are using the concept w database replication, the majority of the projects are made with servers next to each other (or in same rack)..

We have recovered systems based on a “not-up-to-date export”, which required a lot of manual updates based on all the orders in warehouse and production, and it was absolutely not a method we can recommend (production was stopped for many hours)


Please let me know if you would like to have a concall regarding all this..

Kind regards
Mikael</text>
    </revision>
  </page>
  <page>
    <title>BTO Development Training</title>
    <id>960</id>
    <revision>
      <id>6201</id>
      <timestamp>2015-04-08T15:04:50Z</timestamp>
      <contributor>
        <username>Dbondare</username>
        <id>4</id>
      </contributor>
      <minor/>
      <text xml:space="preserve">Please start by watching video lectures from here &lt;code&gt;&quot;T:\Functional entities\PD\BTO Dev Package\DevCourse\&quot;&lt;/code&gt;.

'''Please note:''' drive T: is a mapped network drive of &lt;code&gt;\\socrates\alta&lt;/code&gt;. If you do not have access please ask HelpDesk.

You could download all content of &lt;code&gt;&quot;T:\Functional entities\PD\BTO Dev Package\DevCourse\&quot;&lt;/code&gt; then open &lt;code&gt;index.html&lt;/code&gt; file and see what lectures available, brief descriptions, text of lectures and so on.

For the moment of this page updated there was following lectures:
* L-02. BTO Development Field Overview (video and text)
* L-03. BTO Product Components Overview
** Part 1. BTO Product Components Overview (video and text)
* L-04. BTO Processes and Structures
** Part 1. Practical Example (video and text)
* L-05. BTO Server Class Development
** Part 1. Theory. (video and text)
** Part 2. Practical Example (video and text)
* L-06. BTO Client Development
** Part 1. Overview. (video and text)

[[Category:Development]]</text>
    </revision>
  </page>
  <page>
    <title>BTO Internal Training</title>
    <id>1013</id>
    <revision>
      <id>8463</id>
      <timestamp>2020-08-26T13:57:28Z</timestamp>
      <contributor>
        <username>J1016974</username>
        <id>22</id>
      </contributor>
      <minor/>
      <text xml:space="preserve">[[Category:Core]][[Category:Flow]]
{| align=&quot;right&quot;
   | __TOC__
   |}

==BTO server Side programs==

There are 3 programs running in BTO server side: 

&lt;b&gt;CSLmon.exe&lt;/b&gt;&lt;br&gt;
Is the core process which is handling 
* Queue dispatchers
* Polling services
* Request from BTO clients
The log file names are in format &lt;tt&gt;MO&lt;YYYYMMDD&gt;.LOG&lt;/tt&gt; (&lt;tt&gt;YYYY&lt;/tt&gt;: Year, &lt;tt&gt;MM&lt;/tt&gt;: Month, &lt;tt&gt;DD&lt;/tt&gt;: Day), example: &lt;tt&gt;mo20150720.log&lt;/tt&gt;.

&lt;b&gt;Executor.exe&lt;/b&gt;&lt;br&gt;
The executor is handling all the requests (from Queues, Polling services and Requests from BTO Clients), by loading various DLL's (representing the different task types in flow, and other server side modules (eg. SQLSDYNA for Dynamic SQL from client side). &lt;br&gt;
Entries to the ERRORLOG table is handled by the LOGSERR.EXE process&lt;br&gt;
The Executor log files are in fomrat format &lt;tt&gt;EX&lt;YYYMMDD&gt;_&lt;hhmmss&gt;_&lt;PID&gt;.log&lt;/tt&gt; (&lt;tt&gt;YYYY&lt;/tt&gt;: Year, &lt;tt&gt;MM&lt;/tt&gt;: Month, &lt;tt&gt;DD&lt;/tt&gt;: Day, &lt;tt&gt;hh&lt;/tt&gt;: Hour, &lt;tt&gt;mm&lt;/tt&gt;: Minute, &lt;tt&gt;ss&lt;/tt&gt;: Second, &lt;tt&gt;PID&lt;/tt&gt;: Processed ID). The timestamp in the filename is the startig time of the given executor process.&lt;br&gt;
Example &lt;tt&gt;EX20150720-121100-19736.log&lt;/tt&gt;.&lt;br&gt;

Configuration in CSLMON,  parameters INACTIVE-TIMEOUT and IO-CLEANUP-COUNT tells when Executor should recycle .

'''For more information about executor's functionality, [http://btowiki.jda.corp.local/index.php/BTO_Internal_Training/Executor_functioning Click here]'''

&lt;b&gt;LogsErr.exe :&lt;/b&gt; &lt;br&gt;Is separate program running in server side and handling requests Executor.exe processes, and makes seperate database transactions for storing entries into ERRORLOG table.&lt;br&gt;
This construction is necessary to ensure data is kept in ERRORLOG in case of rollback in Executor process.

&lt;br&gt; Here is a description of the functioning of the executor in a bit more detail

==CSL(Client Server Link)==
Client Server is something which acts as a connector between the BTO client and server.

Usually BTO server application will be installed in a centralized server (CSLmon.exe) and BTO client apps will install in individual user machine. The client app, with help csl configuration, can able to connect with a particular server.

CSL configuration can achieve by EasyLaunch client app.

EasyLaunch configuration of individual client machine will be saved in registry of the same machine (Run -&gt; regedit -&gt; HKEY_CURRENT_USER -&gt; HKEY_CURRENT_USER -&gt; Software  -&gt; ALTA -&gt; BTO -&gt; CSL). Then every client, while connecting to server, fetch server information (whichever is checked/select in Easy Launch) likes csl address, csl pathmon, csl port etc. from the windows registry.

==Registry:==
Registry information will be stored under Current user and next time when try to open EasyLauch, information will be fetched from the registry.

[[File:Reg.png]]


The newer version of CLSMON is set to use Windows TCP/IP KEEPALIVE to avoid the connection lose from Clients 

 Windows Registry Editor Version 5.00
 [HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Services\Tcpip\Parameters]
 &quot;KeepAliveTime&quot;=dword:7530
 &quot;KeepAliveInterval&quot;=dword:3e8
 &quot;TcpMaxDataRetransmissions&quot;=dword:a


The Keep Alive time is hex 7530 = 30.000 (milliseconds) = 30 seconds
Keep Alive Interval is hex 3e8 = 1000 (milliseconds) = 1 second
And TcpMaxDataRetransmission = hex A = 10

This means: The TCP keep alive is checked after 30 seconds, and if it fails 10 times with 1 second interval, then TCP session is shut down.
This gives a time of appr 40 seconds

[[File:TCP_setting.JPG]]

==CSLmon(Client Server Link Monitor)==
We can check whether cslmon is running or not by cheking in two places,in services.msc or in task manager&lt;br&gt;
CSLmon can run as cslmon.exe by taking the configuration from .ini file or it can run as service by taking the configuration from Database.&lt;br&gt;
To make CSLmon run using database, the parameter &quot;-cst=db&quot; should be passed while configuring it as service.&lt;br&gt;

'''CSLmon.ini:'''  When CSLmon is configured to run as exe, it takes the information from  cslmon.ini file&lt;br&gt;
'''CSLmon.ref:''' When CSLmon is configured to run using database, it takes the required information from cslmon.ref file

==BTO Modules==
===[[Business Interfaces]]===
===[[Orders Management]]===
===[[Orders Production System(OPS)]]===
===[[Production Schedule (PSC)]]===
===[[Shop floor stations]]===
===[[Inventory Management]]===
===[[Pack and Dispatch]]===
===[[Documents and Reports]]===

==BTO Clients==

===[[Business Configurator]]===
===[[Business Integrator]]===

==BTO Matain Package==

===[[BTO-PRINTERS]]===
===[[BTO-QUEUE]]===
===[[Batch_Table]]===

==BTO Archiving==
===[[Archiving]]===
Archiving is the process of storing of old processed orders for a longer period of time (in years) either in local server or in archive server (DEWUP-AP59) for future reference. For more information archiving process, [http://btowiki/index.php/Archiving Click here]
==BTO SECURITY==

&lt;br&gt;BTO security.exe allows us to maintain all the user accounts accessing BTO. 
&lt;br&gt;We can create an account for each user with his details like his Name, NETID, position, address, department, phone number etc. 
&lt;br&gt;The client also allows us to link the user to different user groups. Each user group has rights to access a set of BTO clients as per the specification. The creation of a new user group with a set of rights defined would need the approval of the SDM. So, does the creation of a new user and the permission to add him to a specified group.
&lt;br&gt;We can also reset the password of any user in case it expires. There is also a provision to decide if the password should expire or not. We generally create a user account and him to the groups as per the request and create our own password and give the user the credentials. We can specify the option where the system prompts the user to change the password after first time log in where in the user can set his own password.
&lt;br&gt;Sometimes we can see that the user is not able to log on to his account because his account is invalidated. This is indicated by a red mark on his account. We have the option to 'Validate' his account in such cases by a single right click. Once validated, user can access his account.

&lt;br&gt;Creation of new users and adding them to respective groups, Reset of a user password are two very common issues received by BTO support. Creation of a new user account requires the user entitlement form to be filled by the user with details along with the approval of the SDM.

===Issue points and security===

&lt;br&gt;We have the control on deciding which user can access which issue point. 'Tools -&gt; Entry Point' in the business configurator, provides us a list of issue points used in the projects. 
&lt;br&gt;Once we choose to 'Edit' an entry point, the 'sharing' tab lists all the User groups available. We can check the user groups who can access the issue points.
&lt;br&gt;In case a user wants access to an issue point he is not authorized to, he needs to get the approval of the SDM for either of the 2 ways we can provide him access,

&lt;br&gt;&lt;b&gt;1.&lt;/b&gt; We can add him to a group that already has access to the issue point if the SDM approves.
&lt;br&gt;&lt;b&gt;2.&lt;/b&gt;We can create a new user group and include this in the list of groups that have access to the issue point again if the SDM approves.

&lt;br&gt;The SDM decides which of the above options can he approve.
&lt;br&gt; For more details on security please visit [[BTO_Security]].

=='''SCRIPT''' ==
'''Definition and use of Script:'''

Build to Order Script is an object-based scripting language like other scripting languages (Ex: JavaScript).

BTO Script is used to extend the existing PowerB2O business functionality . We can also  develop our own business applications regarding BTO based on the requirement by which we can perform  custom data processing.

The business applications developed in BTO Script are executed as part of business flow (Business configurator) by special Script task.  The task look line below image.

[[File:script task1.png]]

A script where we write the custom code looks like below.

[[File:script.png]]

As per above image, the Integrated Development Environment (IDE) of the script  has four windows: 

'''The Project Explorer window''' located to the left. It lists the functions that are included in the currently open project in a functions tree. The content of the selected function is displayed in the Editor window. 

'''The Editor window''' is located in the center. The  custome code is written here for a particular function, which is selected in the functions tree.
 
'''The Code Browser window''' is located to right. It contains either the Data Tree which enables you to inspect the values of the pre-defined and custom variables or the low level code of the function selected in the Project Explorer window 

'''The Output window''' is located at the bottom. It is used for debugging purposes. In the Output window you may track the values of variables while debugging, see the error and information messages and access the history of function calls

'''NOTE:''' Main function is the first function which is executed while an application is started. The main function must be present in a project. However, when a new script (also called as “project”) is created, the main function is created automatically. 

'''Way to  Debug the Script :'''

   Below are the steps 

1&gt;	First we have to put values to request parameters and option values at Menu bar.  “Script Client -&gt; Debug -&gt; Define Request Parameters”  and  “Script Client -&gt; Debug -&gt; Define TaskOptions” respectively. &lt;br&gt;
2&gt;	Put a break point where ever you want to look while debugging. Debug mode looks like below.

[[File:scriptdebug.png]]

3&gt;	Select a particular item / variable, right click and add  Watch, so that we can see the value of the variable during debugging. &lt;br&gt;
4&gt;	For any type of complex output (like table, object etc) we can look into Data Tree (On right side pane) -&gt; Script Const Extern Class -&gt; long:live &lt;br&gt;
5&gt;	After run debugging, we can navigate through the script by pressing F7 or F8. F7 is for Trace into. F8 is for step over.

===BTO Translation===

Purpose of Translation is to convert customer parts in to Delphi modules and add them in to BOM parts in BOM table 
This can be done usign the BTO task servcer class &quot;EJISTRAM&quot; details about task [[EJISTRAM]] 

Translation data are created and updloaded by Delphi enginerring team, the data should be in VLVMAIN,VLVBOM,VLVPARTS tbales and the converted trablsation details will be updated in BOM table .Engineering team uploading the masterdata using the BTO client translator.exe  the updated versions for the group can be identified like 

There are 5 types of Translation issues we have found so far.

1. XREF value empty

2. XREF wrong group

3. BOM parts empty

4. Subprod Missing - (user trying to translate from Master LOT)

5. No Master data - VLV Table data missing

6. BASPARTN missing

7. VLVMAIN table should not contain the main part family, but only the translated part family values. i.e. In VLVMAIN table subprod column should contain [BX,BZ,CX,CZ etc..] but it should not contain [B,C etc...]. [SF#01103908, SF#01021684]  

All above issues we have to inform customer to handle.

If user trying to translate from master lot then the only solution is &quot;To move those entries to Temp Z-queues&quot; 


Ex: When we wanted to see the structure version added for a group 

 SELECT strucver, count(*), min(valid) FROM vlvmain
 WHERE model = '@Model@' AND plant = '@Plant@' and group_ = 'FLH'
 group by strucver
 order by 3

Ex: the strucver details

 SELECT * FROM vlvmain
 WHERE model = '@Model@' AND plant = '@Plant@' 
   AND strucver = 'ERH140514' and group_='ERH'
 order by ID
 fetch first 10 rows only
 BROWSE ACCESS  



Ex: Delphi parts for the strucver , Translation will be taken the latest structure version and update the Delphi modules .

 SELECT id, option_
 FROM vlvparts
 WHERE model = '@Model@' AND plant = '@Plant@' 
   AND strucver = 'ERH140514' 
 order by ID
 fetch first 20 rows only
 BROWSE ACCESS 

Ex: Check if the BOM parts with translation parts 

 SELECT id, option_
 FROM vlvparts
 WHERE model = '@Model@' AND plant = '@Plant@' 
   AND strucver = 'ERH140514' 
 and id in 
 (select distinct id
 from vlvparts p, bom b
 where p.model = '@Model@' AND p.plant = '@Plant@' AND p.strucver = 'ERH140514'  
  and  b.model = p.model and b.plant= p.plant and b.ordnr = '921633' and subprod = 'C'
  and b.cuspnr = option_)
 order by id desc
 fetch first 20 rows only
 BROWSE ACCESS

==[[Useful BTO Query]]==

==DB2 Replication==
===[[Replication Setup Steps]]===

==MUTEX Function ==

Description :


Function : Mutex(Item,value)
&lt;Pre&gt;
var SQL_code;
Toolkit.ExecSQL(&quot;@set dbupdate on&quot;);

SQL_code = Toolkit.ExecSQL(
  &quot;UPDATE datachg &quot;
  &quot;SET chgtime = CURRENT TIMESTAMP &quot;
  &quot;WHERE model = ? AND plant = ? AND item = ? AND value = ?&quot;,
  request.Model, request.Plant, item, value);

if (SQL_code != 0)
{
  if (SQL_code == 100)
  {
    SQL_code = Toolkit.ExecSQL(
      &quot;INSERT INTO datachg &quot;
      &quot;VALUES (?, ?, ?, ?, CURRENT TIMESTAMP) &quot;,
      request.Model, request.Plant, item, value);
    if (SQL_code != 0)
    {
      throw(format(
        &quot;{halt}: INSERT into datachg failed for item = %s and value = %s. SQL code = %s&quot;, 
        item, value, SQL_code));
    }
  }
  else
  {
    throw(format(
      &quot;{halt}: UPDATE of datachg failed for item = %s and value = %s. SQL code = %s&quot;, 
      item, value, SQL_code));
  }
}
return 0;
&lt;/pre&gt;

==[[BTO TCP Gateway]]==

==[[FTP Return Code]]==

==Navistar Plausi Check Logic==

These are part families for orders in Matamoros - IP and IS.
IS part numbers are sent via transmission from Navistar 
All the IP part numbers have an alternate cuspnr that is mapped to an IS part number in the material table. 

There are 4 types of parts that the orders have that are picked up for plausi check by the ORDERSETUP script

1. Housing MUX
   Eg. HZNCP-DIN-S2
   Part Family in material = HS

2. Housing LCM
   Eg. HZNHSG-LCM-OPT
   Part Family in material = HS
   
3. Switch MUX
   Eg. S1
   Part Family in material = SW

4. Switch LCM
   Eg. C1
   Part Family in material = SW
   
The ORDERSETUP script only picks up the above 4 type of parts and prepares a dataset where it validates it with the corresponding IS parts. 
Within the dataset, it also validates if all the child parts(Switch MUX and Switch LCM) have their corresponding parent housing parts (Housing MUX and Housing LCM).

Based on the parts in the data set, the target part family is decided.

1. For Switch MUX parts, the target part family is determined based on the following 

   S1-S6 parts will have part family M1
   S7-S12 parts will have part family M2
   S13-S18 parts will have part family M3
   And so on...
   Target part family is based on multiples of 6 here which is derived from the formula
   
   M% = ((i - 1) / 6) + 1
   % = result of the formula
   i = The integer value in the Switch MUX part (1 if the part is S1)
   
2. For Housing MUX parts, the part family would be M% where % is the integer value in the part number. 

    For example, if the part is HZNCP-DIN-S1, part family is M1
    If the part is HZNCP-DIN-S2, part family is M2
    And if the part is HZNCP-DIN-S3, part family is M3
				
3. For Housing LCM and Switch LCM parts, the target part family is &quot;LM&quot;


So, after plausi check, the orders will have LM, M1, M2, M3..... parts in addition to IP and IS. 
After creation of these part families, the script will look at the dataset and determine if the Plausi Check is successful or not. If it fails, it can give the following errors based on certain conditions. 


1. Error no 1. 
  Target Part number or Target part family is empty (In case the script was not able to calculate M1,M2,....,LM)
  
2. Error no 10. 
   Here, it is validating with parent count and item count. Housing parts are parents and Switch parts are item. The script is incrementing the item count every time a Housing Mux finds a 
   Switch Mux and a housing LCM finds a switch LCM. 
   In the dataset, for Housing Mux or Housing LCM, if the Item count is less than ITEM_MIN, which is always 0 or if Item count is &gt; ITEM_MAX (which is ideally same as item count) then this 
   error is thrown. 
   For Swicth Mux or Switch LCM, if the PARENT_CNT &lt;&gt; 1, then error 10 is thrown. That is each item should have only 1 parent. It should not have more than one or missing parents. 
  
3. Error 100. 
   There are 3 conditions that are checked here. 
   a. There is a null SEQ_PART in the data set. 
   b. The material in masterdata has statuspart other than 1 (2,8 or 9) that is, STATUSPART in the data set is &lt;&gt; 1
   c. The VALID in dataset is &lt;&gt; 1 (Material is Valid)

4. Error 1000
   If the total quantities of Housing or the Switches fall outside the Qty limit defined in the task options (Options.LCM_QTY_MIN, Options.LCM_QTY_MAX, Options.MUX_QTY_MIN, 
   Options.MUX_QTY_MAX)
   Then, this error is thrown

==Quick steps to identify Navistar Plausi issues==

1. Get the order number. 


2. Use the following query to find the parts that may either be absent in order BOM or in the material master data. This query returns the ALTCUSPNO (Process code word or EDI code word as customer calls it) and null as corresponding part numbers having an issue. The error code in error log for this condition is 100. Most of the errors are seen for this problem. If this query returns empty, there is no problem with part numbers in order. Just change the order number in these queries.

   SELECT X.ALTCUSPNO as ProcessCodeWord,X.SEQ_PARTNO as PARTNO FROM (select 2 as ITEM_LVL, 'SWITCH' as ITEM_TYPE 
         , BP.CUSPNR as PID_PARTNO, BP.ALTCUSPNO 
         , Coalesce(BS.CUSPNR,'null') as SEQ_PARTNO, Coalesce(BS.QTY,0.0) as SEQ_QTY 
         , case when BP.cuspnr like 'S__%' then 'MUX' else case when BP.cuspnr like 'C__%' then 'LCM' else 'null' end end as COMMODITY 
         , Coalesce(M.GRPNAME,'null') as GRPNAME, Coalesce(M.SUBPROD,'null') as PF 
         , Coalesce(M.STATUSPART,0) as STATUSPART 
         , Case When M.VALIDFROM Is NULL Then 0 Else Case When M.VALIDFROM &gt; Date(Current Timestamp) Then 0 Else 1 End End as VALID 
         , Coalesce(M.XNO1,-1) as ITEM_MIN 
         , Coalesce(M.XNO2,-1) as ITEM_MAX 
         , '' as TARGET_PF, '' as TARGET_PARTNO, 0 as TARGET_ITEM, 0 as ITEM_CNT, 0 as PARENT_CNT, 0 as ERROR_CODE 
      from BOM BP 
      left join MATERIAL M                 
        on M.MODEL = 'NAHZ' and M.PLANT = 'DA26' 
       and M.XREF1 = BP.ALTCUSPNO 
       and M.GRPNAME = 'SWITCH' 
      left join BOM BS 
        on BS.MODEL = 'NAHZ' and BS.PLANT = 'DA26' 
       and BS.ordnr = '125466' and BS.subprod = 'IS' 
       and BS.CUSPNR = M.PARTNO 
     where BP.MODEL = 'NAHZ' and BP.PLANT = 'DA26'
       and BP.ordnr = '125466' and BP.subprod = 'IP'
       and (BP.cuspnr like 'C__%' or BP.cuspnr like 'S__%') 
  UNION 
  select 1 as ITEM_LVL, 'HOUSING' as ITEM_TYPE 
         , BP.CUSPNR as PID_PARTNO, BP.ALTCUSPNO 
         , BS.CUSPNR as SEQ_PARTNO, BS.QTY as SEQ_QTY 
         , case when BP.cuspnr like 'HZNCP-DIN-S_%' then 'MUX' else case when BP.cuspnr like 'HZNHSG-LCM-OPT%' then 'LCM' else 'null' end end as COMMODITY 
         , M.GRPNAME, M.SUBPROD as PF 
         , M.STATUSPART 
         , Case When M.VALIDFROM &gt; Date(Current Timestamp) Then 0 Else 1 End as VALID 
         , M.XNO1 as ITEM_MIN 
         , M.XNO2 as ITEM_MAX 
         , '' as TARGET_PF, '' as TARGET_PARTNO, 0 as TARGET_ITEM, 0 as ITEM_CNT, 0 as PARENT_CNT, 0 as ERROR_CODE 
      from BOM BP, BOM BS, MATERIAL M 
     where BP.MODEL = 'NAHZ' and BP.PLANT = 'DA26' 
       and BS.MODEL = 'NAHZ' and BS.PLANT = 'DA26'
       and  M.MODEL = 'NAHZ' and  M.PLANT = 'DA26' 
       and BP.ordnr = '125466' and BP.subprod = 'IP'
       and BS.ordnr = '125466' and BS.subprod = 'IS'
       and ((BP.cuspnr like 'HZNCP-DIN-S_%' and GRPNAME = 'SWITCHPACK') or 
            (BP.cuspnr like 'HZNHSG-LCM-OPT%' and GRPNAME = 'LCM') 
           ) 
       and M.PARTNO = BS.CUSPNR ) AS X
      WHERE X.SEQ_PARTNO = 'null'


3. After having the list ALTCUSPNO from the previous query, use this query to see if parts are present in material master data. The parts that the query returns are present in material master data with the right ALTCUSPNO. These parts needed to be added to ORDER BOM by Navistar and re-transmitted. If the Query returns empty, then, none of the parts corresponding to ALTCUSPNO is in master data. They have to be added. The error code is 100 in error log. 

      SELECT partno,xref1 as ProcessCodeWord FROM material
 WHERE model = '@Model@' AND plant = '@Plant@' 
   AND xref1 in (SELECT X.ALTCUSPNO FROM (select 2 as ITEM_LVL, 'SWITCH' as ITEM_TYPE 
         , BP.CUSPNR as PID_PARTNO, BP.ALTCUSPNO 
         , Coalesce(BS.CUSPNR,'null') as SEQ_PARTNO, Coalesce(BS.QTY,0.0) as SEQ_QTY 
         , case when BP.cuspnr like 'S__%' then 'MUX' else case when BP.cuspnr like 'C__%' then 'LCM' else 'null' end end as COMMODITY 
         , Coalesce(M.GRPNAME,'null') as GRPNAME, Coalesce(M.SUBPROD,'null') as PF 
         , Coalesce(M.STATUSPART,0) as STATUSPART 
         , Case When M.VALIDFROM Is NULL Then 0 Else Case When M.VALIDFROM &gt; Date(Current Timestamp) Then 0 Else 1 End End as VALID 
         , Coalesce(M.XNO1,-1) as ITEM_MIN 
         , Coalesce(M.XNO2,-1) as ITEM_MAX 
         , '' as TARGET_PF, '' as TARGET_PARTNO, 0 as TARGET_ITEM, 0 as ITEM_CNT, 0 as PARENT_CNT, 0 as ERROR_CODE 
      from BOM BP 
      left join MATERIAL M                 
        on M.MODEL = 'NAHZ' and M.PLANT = 'DA26' 
       and M.XREF1 = BP.ALTCUSPNO 
       and M.GRPNAME = 'SWITCH' 
      left join BOM BS 
        on BS.MODEL = 'NAHZ' and BS.PLANT = 'DA26' 
       and BS.ordnr = '125466' and BS.subprod = 'IS' 
       and BS.CUSPNR = M.PARTNO 
     where BP.MODEL = 'NAHZ' and BP.PLANT = 'DA26'
       and BP.ordnr = '125466' and BP.subprod = 'IP'
       and (BP.cuspnr like 'C__%' or BP.cuspnr like 'S__%') 
  UNION 
  select 1 as ITEM_LVL, 'HOUSING' as ITEM_TYPE 
         , BP.CUSPNR as PID_PARTNO, BP.ALTCUSPNO 
         , BS.CUSPNR as SEQ_PARTNO, BS.QTY as SEQ_QTY 
         , case when BP.cuspnr like 'HZNCP-DIN-S_%' then 'MUX' else case when BP.cuspnr like 'HZNHSG-LCM-OPT%' then 'LCM' else 'null' end end as COMMODITY 
         , M.GRPNAME, M.SUBPROD as PF 
         , M.STATUSPART 
         , Case When M.VALIDFROM &gt; Date(Current Timestamp) Then 0 Else 1 End as VALID 
         , M.XNO1 as ITEM_MIN 
         , M.XNO2 as ITEM_MAX 
         , '' as TARGET_PF, '' as TARGET_PARTNO, 0 as TARGET_ITEM, 0 as ITEM_CNT, 0 as PARENT_CNT, 0 as ERROR_CODE 
      from BOM BP, BOM BS, MATERIAL M 
     where BP.MODEL = 'NAHZ' and BP.PLANT = 'DA26' 
       and BS.MODEL = 'NAHZ' and BS.PLANT = 'DA26'
       and  M.MODEL = 'NAHZ' and  M.PLANT = 'DA26' 
       and BP.ordnr = '125466' and BP.subprod = 'IP'
       and BS.ordnr = '125466' and BS.subprod = 'IS'
       and ((BP.cuspnr like 'HZNCP-DIN-S_%' and GRPNAME = 'SWITCHPACK') or 
            (BP.cuspnr like 'HZNHSG-LCM-OPT%' and GRPNAME = 'LCM') 
           ) 
       and M.PARTNO = BS.CUSPNR ) AS X
     WHERE X.SEQ_PARTNO = 'null')
     BROWSE ACCESS


4. If the result of the first query is empty, then try the below query to check if any part is marked as inactive or is not valid in material master data. In such case user has to check and mark the part as active or Valid correspondingly. This is also a part of error code 100 in error log

       SELECT X.ALTCUSPNO as ProcessCodeWord,X.SEQ_PARTNO as PARTNO FROM (select 2 as ITEM_LVL, 'SWITCH' as ITEM_TYPE 
         , BP.CUSPNR as PID_PARTNO, BP.ALTCUSPNO 
         , Coalesce(BS.CUSPNR,'null') as SEQ_PARTNO, Coalesce(BS.QTY,0.0) as SEQ_QTY 
         , case when BP.cuspnr like 'S__%' then 'MUX' else case when BP.cuspnr like 'C__%' then 'LCM' else 'null' end end as COMMODITY 
         , Coalesce(M.GRPNAME,'null') as GRPNAME, Coalesce(M.SUBPROD,'null') as PF 
         , Coalesce(M.STATUSPART,0) as STATUSPART 
         , Case When M.VALIDFROM Is NULL Then 0 Else Case When M.VALIDFROM &gt; Date(Current Timestamp) Then 0 Else 1 End End as VALID 
         , Coalesce(M.XNO1,-1) as ITEM_MIN 
         , Coalesce(M.XNO2,-1) as ITEM_MAX 
         , '' as TARGET_PF, '' as TARGET_PARTNO, 0 as TARGET_ITEM, 0 as ITEM_CNT, 0 as PARENT_CNT, 0 as ERROR_CODE 
      from BOM BP 
      left join MATERIAL M                 
        on M.MODEL = 'NAHZ' and M.PLANT = 'DA26' 
       and M.XREF1 = BP.ALTCUSPNO 
       and M.GRPNAME = 'SWITCH' 
      left join BOM BS 
        on BS.MODEL = 'NAHZ' and BS.PLANT = 'DA26' 
       and BS.ordnr = '125466' and BS.subprod = 'IS' 
       and BS.CUSPNR = M.PARTNO 
     where BP.MODEL = 'NAHZ' and BP.PLANT = 'DA26'
       and BP.ordnr = '125466' and BP.subprod = 'IP'
       and (BP.cuspnr like 'C__%' or BP.cuspnr like 'S__%') 
  UNION 
  select 1 as ITEM_LVL, 'HOUSING' as ITEM_TYPE 
         , BP.CUSPNR as PID_PARTNO, BP.ALTCUSPNO 
         , BS.CUSPNR as SEQ_PARTNO, BS.QTY as SEQ_QTY 
         , case when BP.cuspnr like 'HZNCP-DIN-S_%' then 'MUX' else case when BP.cuspnr like 'HZNHSG-LCM-OPT%' then 'LCM' else 'null' end end as COMMODITY 
         , M.GRPNAME, M.SUBPROD as PF 
         , M.STATUSPART 
         , Case When M.VALIDFROM &gt; Date(Current Timestamp) Then 0 Else 1 End as VALID 
         , M.XNO1 as ITEM_MIN 
         , M.XNO2 as ITEM_MAX 
         , '' as TARGET_PF, '' as TARGET_PARTNO, 0 as TARGET_ITEM, 0 as ITEM_CNT, 0 as PARENT_CNT, 0 as ERROR_CODE 
      from BOM BP, BOM BS, MATERIAL M 
     where BP.MODEL = 'NAHZ' and BP.PLANT = 'DA26' 
       and BS.MODEL = 'NAHZ' and BS.PLANT = 'DA26'
       and  M.MODEL = 'NAHZ' and  M.PLANT = 'DA26' 
       and BP.ordnr = '125466' and BP.subprod = 'IP'
       and BS.ordnr = '125466' and BS.subprod = 'IS'
       and ((BP.cuspnr like 'HZNCP-DIN-S_%' and GRPNAME = 'SWITCHPACK') or 
            (BP.cuspnr like 'HZNHSG-LCM-OPT%' and GRPNAME = 'LCM') 
           ) 
       and M.PARTNO = BS.CUSPNR ) AS X
      WHERE X.statuspart &lt;&gt; 1 OR X.valid &lt;&gt;1


5. If all the 3 above queries return empty, then the error could be number 10. Which means, in the data set, any of child switch parts may be missing the parent Housing part. For example switch mux part S10 should have parent housing mux part HZNCP-DIN-S2 present in the data set. Switch LCM part should have corresponding housing LCM part HZNHSG-LCM-OPT-2SW. Similarly, parent housing parts should have corresponding child switch parts like HZNCP-DIN-S3 should have atleast one among S13 to S18 switch mux parts. Similarly for others. 


6. If all the above conditions don't fail, plausi could fail due to mismatch of items between parents and child as mentioned in the Plausi Logic in previous update. This will give error 1000. Else, the target part family in dataset could be empty which means the script failed to calculate any of LM,M1,M2,M3... parts from existing Switch parts. 


In most cases, points 2, 3 and 4 are helpful, in solving cases.

==BTO Z-Entries Removal Process==

After removal of entry from queue (either by changing queueid to Z% or by changing model/plant value or creating any temporary table), its important to cleanup them on time. Below are steps to follow to make it possible:


1. There is a share excel (BTO_Z-Entries_Report.xlsx) in BTO Supprt Team group in MS-Teams.

2. If any change in any project w.r.t queue, then he/she will update this template with date and change details in the shared excel.

3. We will schedule an activity everyday after completeion of BTO export process for all projects (e.g. 19:00 IST / 15:30 CPH time). According to it we will remove all z-entries reported in the shared excel and mark it completed.

4. So till the immidiate export file(produce on next day of queue change) is available in system (e.g for 5 days / 7 days) the backup of Z-entris will remian, then it automatically cleanup by system. 


In this way we can avoid multiple backups of Z-entries and also can ensure the temporary data (rows/tables) cleaning up in a regular basis.</text>
    </revision>
  </page>
  <page>
    <title>BTO Maintenance and Cleanup page</title>
    <id>881</id>
    <revision>
      <id>5354</id>
      <timestamp>2013-06-07T09:45:24Z</timestamp>
      <contributor>
        <username>Piyali.roykarjee</username>
        <id>15</id>
      </contributor>
      <comment>/* Questions: */</comment>
      <text xml:space="preserve">BTO Maintenance and cleanup Activity

Refer to the page &quot; '''Maintain''' &quot;
[http://btowiki.cph.redprairie.com/btowiki/index.php/Maintain]

1.Maintain 
2. Prune 
3. Import 
4. Export 


The above programs are meant to service the BTO installation in various ways, such as reindexing database tables, cleaning up log directories and backing up the database

Usually system should run:
----

'''export''' - every day in shift breaks or other suitable non-working time (ex: at IAC it runs at 5:00 AM)
'''maintain''' - every week at weekend or other suitable non-working time (ex: at IAC it runs every Sunday at 6:00 AM)

----

'''Prune''' log files incase running out of disk space



== Questions: ==

1. What is difference between maintain and export?
2. What is BTO Health Check?</text>
    </revision>
  </page>
  <page>
    <title>BTO Release DB Layout Delta</title>
    <id>1208</id>
    <revision>
      <id>8505</id>
      <timestamp>2021-06-11T15:11:18Z</timestamp>
      <contributor>
        <username>Dbondare</username>
        <id>4</id>
      </contributor>
      <text xml:space="preserve">= Itroduction =
Desribing here DB layout delta between different BTO releases.

= DB Layout of BTO Release 2020.1.1 Comparing to Release 2020.1 =

&lt;pre&gt;
FTPHEAD
* filename char(250) // before it was char(32)

ORDERHST
+ bodystyle char(16)
+ changed timestamp

PSLOTLIN
- removed index by +INTREPRODNO+EXTREPRODNO
- removed index by +PARENTLINNO

PSVALSTR
+ woc char(16)

removed RELAY table

SUBHST
+ rework smallint
&lt;/pre&gt;</text>
    </revision>
  </page>
  <page>
    <title>BTO Scripting</title>
    <id>698</id>
    <revision>
      <id>3714</id>
      <timestamp>2011-09-08T17:16:26Z</timestamp>
      <contributor>
        <username>Dbondare</username>
        <id>4</id>
      </contributor>
      <minor/>
      <text xml:space="preserve">= Introduction =
Here are recommendations and hints about best practices to be used in BTO scripting.

== Typical Errors ==

=== Double Assign of RowSet Object ===
'''Note:''' the same is related to any object created in script (not only to RowSet).

Below is code example:

&lt;syntaxhighlight lang=&quot;cpp&quot;&gt;
Declare(root, &quot;dsA&quot;);
Declare(root, &quot;dsB&quot;);
Declare(root, &quot;dsC&quot;);
Declare(root, &quot;dsD&quot;);

#global dsA &quot;root/dsA&quot;
dsA = Toolkit.CreateObject (&quot;ALTADB.RowSet&quot;);

#global dsB &quot;root/dsB&quot;
dsB = Toolkit.CreateObject (&quot;ALTADB.RowSet&quot;);

#global dsC &quot;root/dsC&quot;
dsC = Toolkit.CreateObject (&quot;ALTADB.RowSet&quot;);

#global dsD &quot;root/dsD&quot;
dsD = Toolkit.CreateObject (&quot;ALTADB.RowSet&quot;);

// ... and then, in other place in code there something like this:

#global dsB &quot;root/dsB&quot;;
dsB = Toolkit.OpenSQL(
  &quot;SELECT c.ordnr, c.subprod, t.thuno &quot;
  &quot;FROM pdithuco c, pdithu t &quot;
  &quot;WHERE t.model = ? AND t.plant = ? AND t.shipmno = int(?) &quot;
  &quot;  AND c.model = t.model AND c.plant = t.plant AND c.thuno = t.thuno &quot;
  &quot;  AND t.thutype in (select thutype from pdithuty where model = ? and plant = ? and descr like '%M2%') &quot;
  &quot;  AND c.subprod in ('B','C','H') &quot;
  &quot;ORDER BY c.ordnr, c.subprod, t.thuno &quot;
  &quot;BROWSE ACCESS&quot;, -1,
  request.Model, request.Plant, iShipmentNo, request.Model, request.Plant);

&lt;/syntaxhighlight&gt;

The ''Toolkit.OpenSQL'' create RowSet object and returns it as a function result. 
But(!), ''dsB'' already assigned before with the result of ''Toolkit.CreateObject(&quot;ALTADB.RowSet&quot;)'', which makes ScriptVM crashing.

'''Please note:''' assign/re-assign scalar values is ok, but objects (like Row, RowSet and so on) is a bit different thing which is stored in script DataTree in a special way (by reference), so reassigning an object variable in ScriptVM cause internal problems.

'''Please note:''' the ''#global'' directive is not a element of BTO Script language but is a compiler directive. Thus, it do not need a enclosing &quot;;&quot; after it.

The correct ways to do such things are:
* do not initialize variables like dsA,dsB,dsC,dsD with objects. It would be better if you initialize them with ''null'' (or ''empty'') - special values defined by ScriptVM. in such case you can assign dsA,dsB,dsC,dsD variables with result returned by Toolkit.OpenSQL() method and it will work fine.

So, the working code is following:

&lt;syntaxhighlight lang=&quot;cpp&quot;&gt;
Declare(root, &quot;dsA&quot;);
Declare(root, &quot;dsB&quot;);
Declare(root, &quot;dsC&quot;);
Declare(root, &quot;dsD&quot;);

#global dsA &quot;root/dsA&quot;
dsA = empty;

#global dsB &quot;root/dsB&quot;
dsB = empty;

#global dsC &quot;root/dsC&quot;
dsC = empty;

#global dsD &quot;root/dsD&quot;
dsD = empty;

// ... and then, in other place in code there something like this:

#global dsB &quot;root/dsB&quot;;
dsB = Toolkit.OpenSQL(
  &quot;SELECT c.ordnr, c.subprod, t.thuno &quot;
  &quot;FROM pdithuco c, pdithu t &quot;
  &quot;WHERE t.model = ? AND t.plant = ? AND t.shipmno = int(?) &quot;
  &quot;  AND c.model = t.model AND c.plant = t.plant AND c.thuno = t.thuno &quot;
  &quot;  AND t.thutype in (select thutype from pdithuty where model = ? and plant = ? and descr like '%M2%') &quot;
  &quot;  AND c.subprod in ('B','C','H') &quot;
  &quot;ORDER BY c.ordnr, c.subprod, t.thuno &quot;
  &quot;BROWSE ACCESS&quot;, -1,
  request.Model, request.Plant, iShipmentNo, request.Model, request.Plant);

&lt;/syntaxhighlight&gt;



=== Wrong Usage of Request Fields ===
First of all any request field should be trimmed of spaces before using its value!

So, should be something like this:
&lt;syntaxhighlight lang=&quot;cpp&quot;&gt;
request.OrdNr = TrimRight(request.OrdNr, &quot; &quot;);
&lt;/syntaxhighlight&gt;

In some special cases (when script task was called by SHPSWOB/Shopfloor) - request field should be trimmed of \r, \n, \t chars also. So, should be something like this:
&lt;syntaxhighlight lang=&quot;cpp&quot;&gt;
request.OrdNr = TrimRight(request.OrdNr, &quot; \r\n\t&quot;);
request.TaskFunctionName = TrimRight(request.TaskFunctionName, &quot; \r\n\t&quot;);
&lt;/syntaxhighlight&gt;

If it is expected that request field will contain a number should be a special validation code, like this:

&lt;syntaxhighlight lang=&quot;cpp&quot;&gt;
request.OrdNr = TrimRight(request.OrdNr, &quot; \r\n\t&quot;);
var isGoodNumber = ( (request.OrdNr != &quot;&quot;) &amp;&amp; (Trim(request.OrdNr, &quot;0123456789&quot;) == &quot;&quot;) );
if (!isGoodNumber)
  throw(format(&quot;Invalid numeric value (%s)!&quot;, request.OrdNr));
&lt;/syntaxhighlight&gt;


=== LogLevel Was Not Set ===
Here is example of code which may not make log file written:

&lt;syntaxhighlight lang=&quot;cpp&quot;&gt;
if (debugMode)
  ToLog(17, Format(&quot;%s. Start&quot;, ts()));
&lt;/syntaxhighlight&gt;

And here is a correct code:
&lt;syntaxhighlight lang=&quot;cpp&quot;&gt;
if (debugMode)
{
  script.logger.LogLevel(&quot;DEBUG&quot;);
  ToLog(17, Format(&quot;%s. Start&quot;, ts()));
}
&lt;/syntaxhighlight&gt;


== Workarounding ScriptVM Limitations ==

=== Avoid Using Direct RowSet Field Refs ===
In case when you are modifying RowSet object in script (adding/removing rows) please avoid using the direct field references.
Below are 2 examples which are showing the difference.

Using ''direct RowSet field references'':
&lt;syntaxhighlight lang=&quot;cpp&quot;&gt;
    if (rsBomItems[1] != rsStockRefs[2]) {
      rsStockRefs.MoveFirst();
      while (!rsStockRefs.IsEOF()) {
        if (rsBomItems[2] == rsStockRefs[0])) { 
          RecalculateStatistic(rsBomItems[1], rsStockRefs[2]);
        }
&lt;/syntaxhighlight&gt;

Using ''scalar values'' from RowSet:
&lt;syntaxhighlight lang=&quot;cpp&quot;&gt;
    if (AsInt(rsBomItems[1]) != AsInt(rsStockRefs[2])) {
      rsStockRefs.MoveFirst();
      while (!rsStockRefs.IsEOF()) {
        if (AsString(rsBomItems[1]) == AsString(rsStockRefs[3]))) { 
          RecalculateStatistic(AsInt(rsBomItems[1]), AsInt(rsStockRefs[2]));
        }
&lt;/syntaxhighlight&gt;

So, to convert ''direct RowSet field reference'' to ''scalar value'' you need to use standard datatype conversion functions like AsInt(), AsString(). 

When script use lot of ''direct RowSet field reference'' and modifying RowSet objects on-fly it may lead to ScriptVM crash.


== Recommended Approaches vs Non-recommended Ones ==

=== Defining Global Variables ===
Following code shows an approach which is not recommended:

&lt;syntaxhighlight lang=&quot;cpp&quot;&gt;
Declare(root, &quot;dsA&quot;);
Declare(root, &quot;dsB&quot;);
Declare(root, &quot;dsC&quot;);
Declare(root, &quot;dsD&quot;);

#global dsA &quot;root/dsA&quot;
dsA = ...;

#global dsB &quot;root/dsB&quot;
dsB = ...;

[...and so on...]
&lt;/syntaxhighlight&gt;

As you can see - it create every global variable separately.
If script need to manipulate only 1-2 global variables that is ok, but if there are lot of global variables that may became quite inconvenient to use such approach.

Here is the code sample showing recommended approach:
&lt;syntaxhighlight lang=&quot;cpp&quot;&gt;
Declare(root, &quot;Context&quot;);
#global Context &quot;Context&quot;;
Context = Toolkit.CreateObject (&quot;ALTADB.Row&quot;);
Context.configure(
  &quot;dsA,dsB,dsC,dsD:empty;&quot;
  &quot;DebugMode:bool;&quot;
  &quot;RunMode:int;&quot;
  &quot;MaxTHUs:int;&quot;
  );

#global DebugMode &quot;Context/DebugMode&quot;
DebugMode = false;

#global dsA &quot;Context/dsA&quot;
dsA = Toolkit.OpenSQL(...);
&lt;/syntaxhighlight&gt;

As you can see - you can define all your global variables inside a container - the ''Context'' global variable.
The benefits are:
* you can define all by one call (''Context.configure(...)'' method)
* it is easier to track such global variables - easier to write to log and so on</text>
    </revision>
  </page>
  <page>
    <title>BTO TCP Gateway</title>
    <id>1093</id>
    <revision>
      <id>7625</id>
      <timestamp>2016-10-25T05:20:49Z</timestamp>
      <contributor>
        <username>Piyali.roykarjee</username>
        <id>15</id>
      </contributor>
      <minor/>
      <text xml:space="preserve">&lt;b&gt;Introduction&lt;br&gt;&lt;/b&gt;
The purpose of this software component is to provide the ability to call into BTO from outside, using a simple TCP/IP socket interface.&lt;br&gt;
This particular implementation utilizes the script task’s ability to process incoming calls, without programming however you can also develop special dedicated BTO Server Class to handle such calls.&lt;br&gt;
The BtoGwSrvc.exe process listens for connections on a dedicated, specified port.&lt;br&gt;
Furthermore, this process acts as a client against an existing BTO environment, to route traffic into BTO. In essence it acts as a simple gateway for a BTO environment.&lt;br&gt;
[[File:Tcp1.png]]&lt;br&gt;
&lt;b&gt;Files&lt;/b&gt;&lt;br&gt;
•	BtoGwSrvc.exe, BTO.Core.dll, BTO.Csl.Client.dll, XService.Net2.dll, XService.UI.dll – Service executables.&lt;br&gt;
•	BtoGwSrvc.exe.config – Configuration file of .NET application, all service definitions are described here.&lt;br&gt;
•	installServices.bat, unInstallServices.bat, DotNet.bat – Sample scripts showing how to install/uninstall services.&lt;br&gt;
•	KRNSSCR2 – BTO Script task with critical bug fixed (required to make the solution working correctly when return data from BTO to the service)&lt;br&gt;&lt;br&gt;
&lt;b&gt;Installing and Uninstalling&lt;/b&gt;&lt;br&gt;
To run built-in installer helper tool you need to start main service executable with “-installer” command line parameter:
&lt;pre&gt;
BtoGwSrvc.exe -installer
&lt;/pre&gt;

It will show UI like this:&lt;br&gt;
[[File:Tcp2.png]]
&lt;br&gt;
You need to select a service from the “List of Services” and click [Install] or [Uninstall] for it.&lt;br&gt;
Also you can start/stop installed services from this UI.&lt;br&gt;
In case when “built-in installer helper tool” was started in a restricted mode it will indicate that with appropriate message and color at the top of UI form:&lt;br&gt;
[[File:Tcp3.png]]
&lt;br&gt;
In such “restricted mode” you cannot install or uninstall services. So, you need to run this command from a shell started as administrator.&lt;br&gt;
All of the service instances will be installed as path to the same executable with service name specified as command line parameter. For example:&lt;br&gt;
[[File:Tcp4.png]]
&lt;br&gt;
Specified service name should match name of &lt;Service&gt; section in application config file.&lt;br&gt;&lt;br&gt;

&lt;b&gt;Config File&lt;/b&gt;&lt;br&gt;
Application config file (BtoGwSrvc.exe.config) is supposed to contain one mandatory section - &lt;Services&gt; with definitions of TCP-to-BTO communication services. Also, there should be .NET config section handler descriptor for that &lt;Services&gt; section, like this:&lt;br&gt;
&lt;pre&gt;
&lt;configSections&gt;
    &lt;section name=&quot;Services&quot; type=&quot;XService.Configuration.ConfigXml, XService.Net2&quot; /&gt;
  &lt;/configSections&gt;
&lt;/pre&gt;

&lt;i&gt;Note:  .NET does not start application without such .NET config section handler descriptor.&lt;/i&gt;
All rest of the sections are optional.&lt;br&gt;
For example, &lt;system.diagnostics&gt; section is used to describe/enable application trace logging.&lt;br&gt;

&lt;b&gt;Service Definitions&lt;/b&gt;&lt;br&gt;
All services are described in &lt;Services&gt; section in application config file. Every service instance should be described inside &lt;Service&gt; section there.&lt;br&gt;
For example:&lt;br&gt;
&lt;pre&gt;
&lt;Services&gt;

    &lt;Service name=&quot;BtoTcpGw_7050&quot;&gt;
      ListenPort = 7050
      Task = $BTO-308-A
      Protocol = 1
      General_HostType = 1
      BtoEnvironment = btoDevVmW2k8:20151, MPDI/BUGA, $BTO-308-A/krnsscr2
    &lt;/Service&gt;

    &lt;Service name=&quot;BtoTcpGw_7060&quot;&gt;
      ListenPort = 7060
      Task = $BTO-308-B
      Protocol = 1
      General_HostType = 1
      BtoEnvironment = btoDevVmW2k8:20151, MPDI/BUGA, $BTO-308-A/krnsscr2
    &lt;/Service&gt;

  &lt;/Services&gt;
&lt;/pre&gt;&lt;br&gt;
To reduce amount of duplicated parameters you can move out some common parameters into &lt;CommonServiceParams&gt; section. &lt;br&gt;

For example:&lt;br&gt;
&lt;pre&gt;  
&lt;Services&gt;

    &lt;!-- Section to place parameters which are common for all services --&gt;
    &lt;CommonServiceParams&gt;
      DisplayName = BuildToOrder TCP Gateway ($(Port))
      Protocol = 1
      General_HostType = 1
      BtoEnvironment = btoDevVmW2k8:20151, MPDI/BUGA, $BTO-308-A/krnsscr2
    &lt;/CommonServiceParams&gt;

    &lt;Service name=&quot;BtoTcpGw_7050&quot;&gt;
      ListenPort = 7050
      Task = $BTO-308-A
    &lt;/Service&gt;

    &lt;Service name=&quot;BtoTcpGw_7060&quot;&gt;
      ListenPort = 7060
      Task = $BTO-308-B
    &lt;/Service&gt;

  &lt;/Services&gt;
&lt;/pre&gt;&lt;br&gt;
&lt;b&gt;List of Supported Service Parameters&lt;/b&gt;&lt;br&gt;

{| border=&quot;1&quot; cellpadding=&quot;4&quot; cellspacing=&quot;0&quot; 
|- style=&quot;background:#dfefdf;&quot;
! Parameter 
! Description
|-
| ListenPort
| Mandatory.&lt;br&gt; 
It defines on which port it will start TCP listener to handle incoming requests.&lt;br&gt;
&lt;i&gt;Note: You can also use shorter name of this parameter – “Port”.&lt;/i&gt;
|-
| BtoEnvironment
| Mandatory.&lt;br&gt; 
Mandatory. 
Describes target BuildToOrder environment to connect.&lt;br&gt;
It expects following format:
   &lt;pre&gt; CslHost:CslPort, Model/Plant, Task/ServerClassName&lt;/pre&gt;&lt;br&gt;
For example:
   &lt;pre&gt; btoDevVm2:20151, ABX/P001, BTO308-A/KRNSSCR2&lt;/pre&gt;&lt;br&gt;
&lt;i&gt;Note: You can also specify all BTO environment parameters as separate parameters. Please see below description of CslHost, CslPort, Model, Plant, Task, ServerClass parameters.&lt;/i&gt;
|-
| CslHost, CslPort, 
Model, Plant,
Task, ServerClass
| Optional.&lt;br&gt; 
Using these parameters, you can overwrite certain values specified in BtoEnvironment parameters
|-
| General_HostType
| Optional.&lt;br&gt;
It allows changing host type parameter for CSL protocol. 0 is for NSK, 1 is for Windows NT, 2 is for AIX, 3 is for Linux, etc.
By default, value is “1”.
|-
| BtoProtocol&lt;br&gt;
| Optional.&lt;br&gt;
It allows switching to different communication protocol when calling BTO task. By default, value is 1 (extended-text-protocol), but in case when in future dedicated server class will be developed you can change it to 0 (simplified-straight-forward protocol).
|-
| UseTransaction
| Optional.&lt;br&gt;
You can choose if it should explicitly start CSL transaction when calling BTO task. By default, it is “1” (enabled).
|-
| IP-Allow
| Optional.&lt;br&gt;
List of IP addressed, or IP address masks which are allowed to connect.&lt;br&gt;
When this parameter is not specified all IP addressed are allowed.&lt;br&gt;
When this parameter is specified only these IP addressed are allowed.&lt;br&gt;
|-
| IP-Deny
| Optional.&lt;br&gt;
List of IP addressed, or IP address masks which are denied to connect.&lt;br&gt;
When this parameter is not specified no IP addressed are denied.&lt;br&gt;
When this parameter is specified only these IP addressed are denied.&lt;br&gt;
|-
| MsgOnCslError
| Optional.
It defines which message it should respond to TCP client back when BTO task call fails.
Following macro names are supported:&lt;br&gt;
$(MessageID) – Message type-ID (it should not be longer than 16 chars).&lt;br&gt;
$(Message) – Full text of incoming message which fails.&lt;br&gt;
$(ErrorCode) – Error code.&lt;br&gt;
$(ErrorName) – Error code name.&lt;br&gt;
$(ErrorInfo) – Additional error information.&lt;br&gt;
By default, value is &lt;br&gt;
  &lt;pre&gt; ERRR|$(MessageID)|ErrCode=$(ErrorCode)/$(ErrorName)
 |ErrInfo=$(ErrorInfo)|Msg:$(Message)&lt;/pre&gt;
|-
| MESSAGEID_EXTRACTOR
| Optional.&lt;br&gt;
It is used to define regular expression to extract Message Type ID from incoming message. It is only used when reporting an error.
By default, value is – &lt;pre&gt;“^(\w+)\|“.&lt;/pre&gt;
|-
| BUFFER_SIZE
| Optional.&lt;br&gt;
It is &lt;i&gt;internal parameter for fine tuning. &lt;/i&gt;
It allows changing size of communication buffer. By default, value is 65536.
|-
| MAX_ATTEMPTS_TO_RECOGNIZE
| Optional.&lt;br&gt; 
&lt;i&gt;It is internal parameter for fine tuning. &lt;/i&gt;
It allows to control how many attempts it will make to recognize valid incoming message in TCP receive buffer. When max attempts exceed, it will drop data in TCP receive buffer and continue from scratch. 
By default, value is 30.
|-
| MAX_CLIENT_SESSIONS
| Optional.&lt;br&gt; 
It is internal parameter for fine tuning. 
It allows to control how many TCP clients can connect the same service.
By default, value is 3.
|-
| MESSAGE_TERMINATOR
| Optional. 
It is internal parameter for fine tuning. 
It allows to specify what character to use as message terminator when recognizing incoming messages.
By default, value is “\n”.
&lt;i&gt;Note: C-style escape sequences are supported. For example: you can specify “\r” that will mean chr(13), “\n” means chr(10), “\x1B” means chr(27) and so on – just all the standard escape sequences supported in C/C++/C#/JavaScript.&lt;/i&gt;
|-
| DisplayName
| Optional.&lt;br&gt;
It is install-time parameter. It plays role only during service installation.
It defines template to format service display name.
By default, it 
|-
| StartType
| Optional.&lt;br&gt;
It is install-time parameter. It plays role only during service installation.
It defines system service start type – “Automatic”, “Manual” or “Disabled”.
By default, value is “Manual”.
|-
| ServiceDescription
| Optional.&lt;br&gt;
It is install-time parameter. It plays role only during service installation.
It defines description of system service which will be installed.
|-
| DependentServices
| Optional.
It is install-time parameter. It plays role only during service installation.
It defines which other system services should be specified as dependencies for this service when installing.
|}
&lt;br&gt;
&lt;b&gt;Trace Logging&lt;/b&gt;&lt;br&gt;
In a sample application config file trace logging is enabled (that is defined in &lt;system.diagnostics&gt;). Log files will be saved at %TEMP% directory for the user account which is used to run a service. For example: for LocalSystem user account that will be “C:\Windows\Temp” directory, for LocalService user account that will be “C:\Windows\ServiceProfiles\LocalService\AppData\Local\Temp” directory, for real user accounts that most probably will be something like this – &lt;br&gt;“C:\Users\%UserName%\AppData\Local\Temp”.&lt;br&gt;
Log file name is generated by following template - &quot;%TEMP%\$BtoGwSrvc-${PID}.log” and also a part of log filename which determines a log filenames routing by time – “TimeRouteFilenamePattern=yyyyMMdd”. &lt;br&gt;
So, every service instance will use own log file distinguishing by {PID} (ProcessID) value and piece of timestamp in a filename. You can change these templates in application config file if you wish. Example of log file name: “$BtoGwSrvc-5917-20160422.log”.&lt;br&gt;
Default application config file defines automatic cleanup of log files older than 7 days, please see the “CleanupOlderThan=7days” parameter there. You can change it if required.&lt;br&gt;

&lt;b&gt;Trace Log Levels&lt;/b&gt;&lt;br&gt;
You can control amount of data in log by changing log levels. As any.NET application which uses standard trace logging levels are following: 0 – off, 1 – errors only, 2 – warnings, 3 – information, 4 – verbose.&lt;br&gt;
Following named trace switches are supported:
&gt;&lt;br&gt;

{| border=&quot;1&quot; cellpadding=&quot;4&quot; cellspacing=&quot;0&quot; 
|- style=&quot;background:#dfefdf;&quot;
! LogLevel 
! Description
|-
| Service
| It defines level of details for the service itself – when it was started/stopped, etc.
|-
| Engine
| It defines level of details for service engine – when TCP clients connected, what data received, what messages extracted, how BTO task called, etc.
|-
| BTO.Core.CSL.Client.CslSession
| It defines level of details for CSL protocol when it is communicating BTO host.</text>
    </revision>
  </page>
  <page>
    <title>BTO Terms</title>
    <id>938</id>
    <revision>
      <id>5916</id>
      <timestamp>2014-06-23T10:33:42Z</timestamp>
      <contributor>
        <username>Dbondare</username>
        <id>4</id>
      </contributor>
      <comment>Created page with &quot;= Introduction = Just to collect definitions of typical ''BTO terms''.  = Moving Goods = * '''PUTAWAY'''&lt;br&gt;Goods are received in the plant. The truck is unloaded, and the incomi…&quot;</comment>
      <text xml:space="preserve">= Introduction =
Just to collect definitions of typical ''BTO terms''.

= Moving Goods =
* '''PUTAWAY'''&lt;br&gt;Goods are received in the plant. The truck is unloaded, and the incoming goods, container and palettes are all checked. When all is ok, they are moved into the WH, and stored there. The MOVE of the containers, typically by a forklift, from receiving area, to a place inside the warehouse, is PUT AWAY. This is moving of goods, from one place to another, inside the warehouse.

* '''REPLEN'''&lt;br&gt;When they produce material in production, they consume raw material. Sooner or later, they a low/out of raw material. When they are low (QTY &lt; MIN), we must move a new container or box, from the main warehouse/store, to production. The MOVE of the containers, typically by a forklift, from the main store, to the production area, at lineside for example, is REPLEN. This is also moving of goods, from one place to another, inside the warehouse.

* '''PICKING'''&lt;br&gt;Picking is about taking material from the warehouse, and ship it out. For example here, KANBAN. The customer is ordering full boxes of raw material. So like when Neovia needs material in Neovia production, the OEM also needs raw material. This is not shipped in sequence, because it is simple material – boxes of 20, 50 100, etc. parts of the same trivial components. This is called PICKING, which is the last we do with the container, before shipping. Picking removes (deletes) the container from the WH – There is no MOVE. This is why it is relevant to have a dedicated MOVETYPE, as it is very different from the two other above. Under no circumstances can a PICK job be mistaken for a REPLEN or PUTAWAY job.</text>
    </revision>
  </page>
  <page>
    <title>BTO Weekend Activity</title>
    <id>1192</id>
    <revision>
      <id>8339</id>
      <timestamp>2018-10-03T13:40:56Z</timestamp>
      <contributor>
        <username>Pratitshetty</username>
        <id>18</id>
      </contributor>
      <minor/>
      <comment>moved [[Weekend Activity]] to [[BTO Weekend Activity]]</comment>
      <text xml:space="preserve">For any changes planned on the weekends on servers hosting the BTO application, the Aptiv Vendors create a child change record for JDA with details of the change they are implementing. JDA needs to check the health of servers mentioned in the record after the change as per the “downtime end” mentioned in the record. 

Most of the weekend activities involve the server patching performed every month by DXC. For these, We receive an excel sheet with details of the patching time start and end for each server planned for the weekend. We receive this info in the bto.cm@jda.com account. So, based on the information (Child change record and excel sheet) Bangalore COE BTO support team prepares the weekend activity email with an internally agreed template and send it across the team. Health check/implementation activities are performed in the weekend as per this schedule.

BTO support team monitors the bto.cm@jda.com inbox and the &quot;changes assigned to my group&quot; in Service Now every shift to see any information regarding changes planned during the week/weekend.</text>
    </revision>
  </page>
  <page>
    <title>BWI-JLR EDI WebService</title>
    <id>827</id>
    <revision>
      <id>4784</id>
      <timestamp>2012-09-24T10:01:30Z</timestamp>
      <contributor>
        <username>Dbondare</username>
        <id>4</id>
      </contributor>
      <minor/>
      <text xml:space="preserve">= Designing =

== Database tables ==

=== Configuration ===

Assume configuration approach should be similar to the one we are using for FTP and Email tasks.

So, it should be a WEBSSRVC task which will create an empty record in the WEBSRVC table with an idea that a separate client application (like SecureFTP) will be able to edit such record to specify all the required ''webservice binding'' parameters there.

So, table could looks like this:

{| border=&quot;1&quot; cellpadding=&quot;4&quot; cellspacing=&quot;0&quot; 
|- style=&quot;background:#dfefdf;&quot; 
! Field !! Type !! Comment
|- 
| TASK || CHAR(16) || a reference to the WEBSSRVV task on biz-flow
|- 
| HANDLERID || CHAR(40) || a web-service logic handler ID. Is defining what particular web-service logic handler to choose. Example of ID: &quot;BWI-JLR&quot;.
|- 
| URL || CHAR(250) || an url of web-service 
|- 
| WSUSER || CHAR(80) || a web-service login: user name 
|- 
| WSPASSW || CHAR(250) || a web-service login: password
|- 
| OPTIONS || INT || bit flag options for this record
|- 
| EXTRAPROPS || VARCHAR(4000) || a text block containing extra properties. Here could be extra HTTP headers and so on.
|}


=== EDI Messages ===

Assume we do not need separate tables for EDI messages received via web-service. 

Assume we will use existing FTP tables with an idea that bigger messages could be parse/split into smaller ones before them stored in FTP tables.


== Questions and Challenges ==

* How to handle the ''manual mode'' of web-service calls? So, how exactly user could do ''re-load'\ operation for particular EDI message?&lt;br&gt;Note: I mean such API functions like: GetMessage, GetMessagesSinceMessageID, GetMessagesForOrder and so on.
* How to handle the ''feedback mode''?&lt;br&gt;Note: I mean such API function like: SubmitFeedback.


= Delivery =

== WebServer call issues ==

As discovered from live server at BWI we can call the webservice at JLR QA system but cannot call webservice at JLR Live system.

=== Investigation ===
Following actions were completed:
{| border=&quot;1&quot; cellpadding=&quot;4&quot; cellspacing=&quot;0&quot; 
|- style=&quot;background:#dfefdf;&quot; 
! Action !! Result !! Comment
|-
| Call WS with defau settings || QA = OK&lt;br&gt;LIVE = FAIL || 
|}


=== Stack Traces ===
&lt;pre&gt;
at System.ServiceModel.Channels.HttpChannelUtilities.ProcessGetResponseWebException(WebException webException, HttpWebRequest request, HttpAbortReason abortReason)
at System.ServiceModel.Channels.HttpChannelFactory.HttpRequestChannel.HttpChannelRequest.WaitForReply(TimeSpan timeout)
at System.ServiceModel.Channels.RequestChannel.Request(Message message, TimeSpan timeout)
at System.ServiceModel.Channels.SecurityChannelFactory`1.SecurityRequestChannel.Request(Message message, TimeSpan timeout)
at System.ServiceModel.Dispatcher.RequestChannelBinder.Request(Message message, TimeSpan timeout)
at System.ServiceModel.Channels.ServiceChannel.Call(String action, Boolean oneway, ProxyOperationRuntime operation, Object[] ins, Object[] outs, TimeSpan timeout)
at System.ServiceModel.Channels.ServiceChannelProxy.InvokeService(IMethodCallMessage methodCall, ProxyOperationRuntime operation)
at System.ServiceModel.Channels.ServiceChannelProxy.Invoke(IMessage message)
at System.Runtime.Remoting.Proxies.RealProxy.PrivateInvoke(MessageData&amp;amp; msgData, Int32 type)
[...skip...]
&lt;/pre&gt;</text>
    </revision>
  </page>
  <page>
    <title>BWI Luton Jaguar</title>
    <id>694</id>
    <revision>
      <id>3679</id>
      <timestamp>2011-09-01T08:45:16Z</timestamp>
      <contributor>
        <username>Dbondare</username>
        <id>4</id>
      </contributor>
      <minor/>
      <comment>/* Database Dictionary */</comment>
      <text xml:space="preserve">[[Category:Plant]][[Category:BWI Project]]
=Plant=
{| align=&quot;right&quot;
   | __TOC__
   |}

== Contacts ==
{| border=&quot;1&quot; cellpadding=&quot;4&quot; cellspacing=&quot;0&quot; 
|- style=&quot;background:#dfefdf;&quot; 
!Name
!Title
!Phone number
!Email
|-
| ?
| ?
| 
* ?
| ?
|}


= Project =

== Configuration ==

== Development ==

= Support = 

== Database Dictionary ==
This section describes custom db fields and customized db field headings.
{| border=&quot;1&quot; cellpadding=&quot;4&quot; cellspacing=&quot;0&quot; 
|- style=&quot;background:#dfefdf;&quot; 
! DB Field
! Project-specific field name
! Comment
|- 
| MATERIAL.XREF1 || JRL Material Number || 
|- 
| MATERIAL.IDNR || SAP PartNo || 
|- 
| MATERIAL.ALTPNO || Colour Code || 
|}

== Known issues ==</text>
    </revision>
  </page>
  <page>
    <title>Batch Table</title>
    <id>1049</id>
    <revision>
      <id>7039</id>
      <timestamp>2015-11-06T23:16:43Z</timestamp>
      <contributor>
        <username>J1016974</username>
        <id>22</id>
      </contributor>
      <minor/>
      <comment>Created page with &quot;[[Category:Core]][[Category:Flow]] {| align=&quot;top&quot;    | __TOC__    |}  = BATCH TABLE =  &lt;br&gt;The Back flush, Stock transfer or Goods Issue or ASN or SOP or EOL tasks triggered from…&quot;</comment>
      <text xml:space="preserve">[[Category:Core]][[Category:Flow]]
{| align=&quot;top&quot;
   | __TOC__
   |}

= BATCH TABLE =

&lt;br&gt;The Back flush, Stock transfer or Goods Issue or ASN or SOP or EOL tasks triggered from the plant calendar or polling services (at specified intervals) look for the orders in the batch table with corresponding tasks and TXFNO = -1 and prepare the respective files and send them to the Data Export. 
&lt;br&gt;A new TXFNO (Maximum plus 1) is assigned for all the files to be picked up from each trigger.
&lt;br&gt;In support cases where we need to retrieve the orders from a particular exported file, we can get them from the batch table by looking for the maximum TXFNO and task.
&lt;br&gt;However, it is not always that the Export task picks up orders to generate export files from the Batch table. In certain plants, it picks them up from the BOOKINGS table using a certain TXFNO. 
&lt;br&gt;The business flow is built as per the requirements of the plant.

&lt;br&gt;&lt;b&gt;Chunk in Bookings&lt;/b&gt;

&lt;br&gt;There is also a term called 'Chunk' that we can use to associate the TXFNO with the orders that have been shipped. One chunk is a set of orders that have the same TXFNO. There can be multiple chunks per booking id in the booking table. In such a case, each booking id has multiple TXFNO. 

&lt;br&gt;There can be a set of parameters that decide the formation of a chunk. For example, in Audi Q7 project in Sannicolou Mare, a chunk is formed based on 2 conditions

&lt;br&gt;In a booking,

&lt;br&gt;1. There should not be more than 999 unique part numbers in a chunk
&lt;br&gt;2. The number of orders per part number should not exceed 250

If any of the above conditions hold false, an extra chunk is formed for the booking.</text>
    </revision>
  </page>
  <page>
    <title>Binary files compare</title>
    <id>85</id>
    <revision>
      <id>1538</id>
      <timestamp>2010-05-20T09:22:25Z</timestamp>
      <contributor>
        <username>Dbondare</username>
        <id>4</id>
      </contributor>
      <minor/>
      <text xml:space="preserve">== How to compare binary files in RHEL system: ==

* &lt;code&gt;&lt;pre&gt; diff --binary file1 file2 &lt;/pre&gt;&lt;/code&gt; (but output will be simple: differ or not)
* &lt;code&gt;&lt;pre&gt; sha1sum file1 file2 &lt;/pre&gt;&lt;/code&gt;
* &lt;code&gt;&lt;pre&gt; md5sum file1 file2 &lt;/pre&gt;&lt;/code&gt;

[[Category:Linux]]
[[Category:Development]]
[[Category:VShkil_Pages]]</text>
    </revision>
  </page>
  <page>
    <title>BtoSrvKick</title>
    <id>363</id>
    <revision>
      <id>7635</id>
      <timestamp>2016-10-27T09:57:34Z</timestamp>
      <contributor>
        <username>Dbondare</username>
        <id>4</id>
      </contributor>
      <minor/>
      <comment>/* Get Source Code Revisions for All BTO Server Classes */</comment>
      <text xml:space="preserve">{{BTO_Tool|Name=BtoSrvKick.exe|Module=|Version=3.3.2.2|Image=Blank.gif}}
[[Category:BTO Tools]][[Category:Something]]

== Definition ==
BtoSrvKick is a Command Line tool for triggering events in BTO from external elements such as 3rd party tools.

== Usage ==
Usage: 
&lt;pre&gt;BtoSrvKick command [options]&lt;/pre&gt;

=== Commands ===
Supported commands are:
* kick  - (default) kick server class
* execSQL  - execute SQL statement, not expected to return resultset
* openSQL  - execute SQL statement, expected to return resultset
 
=== Options ===
Supported options are:
{| border=&quot;1&quot;  cellpadding=&quot;5&quot; cellspacing=&quot;0&quot; style=&quot;text-align: center; 
|- style=&quot;background:#dfefdf;&quot;
! Long form
! Short form
! Description
! Example
|-
| --AbortOnError={NO/yes}
| -ae
| Abort transaction on error, by default = no
| 
|-
| --authKey={secured-text}
| 
| (reserved) encrypted package with security parameters
| 
|- style=&quot;background:#efefef;&quot;
| --ChangeDir={path}
| -CD
| Change current directory
| 
|-
| -Csl={CslParamsDefs}
| &amp;nbsp;
| Define CSL parameters (if not specified it uses CSL parameters defined by EasyLaunch application).
Parameters should be defined in form: FieldName1:Value1; FieldName2:Value2; ...
Supported field names are (long and short form): 
* Address (A)
* Port (P)
* PathMon (PM)
* System (S)
* TerminalName (TN)
* Timeout (TO)
If this parameter specified CSL parameters defined by EasyLaunch ignored.
| 
|- style=&quot;background:#efefef;&quot;
| -CslLog={Level[,LogFileName]}
| 
| set log level and file for CSL. Level is one of:
* Trace
* Debug
* All
* Exception
* None
| 
|-
| -HKLM=(YES/no)
| 
| If CSL parameters defined by EasyLaunch application, this parameter define the regystry root key to read CSL parameters.
hklm=yes means - read from HKEY_LOCAL_MACHINE, otherwise - from HKEY_CURRENT_USER.
| 
|- style=&quot;background:#efefef;&quot;
| -HKCU=(YES/no)
| 
| The same as -hklm parameter but read CSL params from HKEY_CURRENT_USER. 
By default CSL parameters read from HKEY_CURRENT_USER.
| 
|-
| -Log=(LogFileName)
| 
| Write log to specified file
| 
|- style=&quot;background:#efefef;&quot;
| --KickFile=(FileName)
| -KF
| File with server kick definitions
| 
|-
| --minimize
| -min
| Minimize this window when running
| 
|-
| --max-reply
| -mxrpl
| Max reply size
| 
|- style=&quot;background:#efefef;&quot;
| -Pause
| 
| Pause at end (wait until user press [Enter])
| 
|-
| --QueryResultFile=filename
| -qrf
| Change filename to save query result into. By default it save resultset in ADODB XML file format
| 
|- style=&quot;background:#efefef;&quot;
| --Request={RequestFieldsDefs}
| -r
| Define a fields of EuroRequest structure in form: FieldName1:Value1; FieldName2:Value2; ...
Supported field names are (long and short form): 
* Model (M)
* Plant (P)
* OrdNr (O)
* SubProd (S)
* Task (T)
* TaskFunctionName (TFN)
* RecvTime (RT)
* UserId (U)
* Language (L)
* Endian (E).
You can use C/C++ style escape sequences here (like \r, \n, \x1B, etc).
| 
|-
| --ResuestExtra={Text}
| -rqex
| Define content of extra part of request
| 
|- style=&quot;background:#efefef;&quot;
| --RequestFile={FileName}
| -rqf
| Load request structure from file
| 
|-
| --ReplyFile={FileName}
| -rplf
| Save reply to file (binary format)
| 
|- style=&quot;background:#efefef;&quot;
| --Server={ServerClassName}
| -s
| Name of server class to kick
| 
|-
| -Sql=SQL
| 
| SQL statement
| 
|- style=&quot;background:#efefef;&quot;
| -SqlFile=filename
| 
| Filename with a number of SQL statements (delimited with &quot;;&quot;)
| 
|-
| --Transaction={YES/no}
| 
| -tx
| 
|-
|}

=== Security ===
According to [[User:Mclausen]] we need to be able:
* Restrict using this tool for specified IP/hostname
* Allow to call only specified servers/tasks

'''Note:''' new version of ''BtoSrvKick.exe'' requires also a ''secur.dll'' (in addition to ''csl32*.dll'' files)!

So, here are the rules I can think of:
&lt;pre&gt;
    HOST-ALLOW:10.27.1*.*
    HOST-DENY:*
    COMPUTER-ALLOW:??WS*.*
    COMPUTER-DENY:*

    HOST-FUNC-ALLOW:10.27.1*.*/Kick
    HOST-FUNC-DENY:*/ExecSQL
    COMPUTER-FUNC-ALLOW:??WS*.*/ExecSQL
    COMPUTER-FUNC-DENY:*/OpenSQL

    TASK-ALLOW:*
    TASK-DENY:PSC_XBA_L01

    SRV-ALLOW:*
    SRV-DENY:KRNSSCR2

    HOST-TASK-ALLOW:10.27.11.110,PSC_XBA_L01
    HOST-TASK-DENY:10.27.11.110,*
    COMPUTER-TASK-ALLOW:10.27.11.110,PSC_XBA_L01
    COMPUTER-TASK-DENY:10.27.11.110,*

    HOST-SRV-ALLOW:10.27.11.110,KRNSSCR2
    HOST-SRV-DENY:10.27.11.110,*
    COMPUTER-SRV-ALLOW:10.27.11.110,KRNSSCR2
    COMPUTER-SRV-DENY:10.27.11.110,*
&lt;/pre&gt;

'''Note:''' here are some security check rules:
* as you can see it supports ''wildcards'' with * and ? (like filemasks)
* if no security rules defined at all - it means ''restricted''
* if call restricted by any of setting the other allowing setting do not matter
* if call is not denied and not allowed it is ''allowed''
* ''Function'' means - utility function - one of &quot;Kick&quot;, &quot;ExecSQL&quot;, &quot;OpenSQL&quot;

==== List of Supported Security Functions ====
Here is the list of security functions supported at the moment.
{| border=&quot;1&quot;  cellpadding=&quot;5&quot; cellspacing=&quot;0&quot; style=&quot;text-align: center; 
|- style=&quot;background:#dfefdf;&quot;
! Function
! Short*
! Value
! Description
|-
| HOST-ALLOW&lt;br&gt;HOST-DENY || HA&lt;br&gt;HD || {IpAddress} || Enable/disable specified computer by a IP address
|-
| COMPUTER-ALLOW&lt;br&gt;COMPUTER-DENY || CA&lt;br&gt;CD || {ComputerName} || Enable/disable specified computer by a computer network name
|-
| WINUSER-ALLOW&lt;br&gt;WINUSER-DENY || WUA&lt;br&gt;WUD || {WinUserName} || Enable/disable specified windows user
|-
| HOST-FUNC-ALLOW&lt;br&gt;HOST-FUNC-DENY || HFA&lt;br&gt;HFD || {IpAddress}/{Function} || Enable/disable specified function for specified IP address
|-
| COMPUTER-FUNC-ALLOW&lt;br&gt;COMPUTER-FUNC-DENY || CFA&lt;br&gt;CFD || {ComputerName}/{Function} || Enable/disable specified function for specified computer network name
|-
| SRV-ALLOW&lt;br&gt;SRV-DENY || SA&lt;br&gt;SD || {BtoServerClassName} || Enable/disable specified BTO server class to call
|-
| TASK-ALLOW&lt;br&gt;TASK-DENY || TA&lt;br&gt;TD || {BtoTaskName} || Enable/disable specified BTO task to call
|-
| HOST-TASK-ALLOW&lt;br&gt;HOST-TASK-DENY || HTA&lt;br&gt;HTD || {IpAddress}/{BtoTaskName} || Enable/disable to call specified BTO task for specified IP address
|-
| COMPUTER-TASK-ALLOW&lt;br&gt;COMPUTER-TASK-DENY || CTA&lt;br&gt;CTD || {ComputerName}/{BtoTaskName} || Enable/disable to call specified BTO task for specified computer network name
|-
| HOST-SRV-ALLOW&lt;br&gt;HOST-SRV-DENY || HSA&lt;br&gt;HSD || {IpAddress}/{BtoServerClassName} || Enable/disable to call specified BTO server class for specified IP address
|-
| COMPUTER-SRV-ALLOW&lt;br&gt;COMPUTER-SRV-DENY || CSA&lt;br&gt;CSD || {ComputerName}/{BtoServerClassName} || Enable/disable to call specified BTO server class for specified computer network name
|}
* '''Note:''' security ''Function'' in BTO is limited by char(32), so in most cases you'd better use the short form to save some space and be able specifying more longer values.

==== Configuring Security for BtoSrvKick ====
Please do following:
* define the ''BTOSRVKICK'' application in BTO security
* define security rules as functions for the ''BTOSRVKICK'' application 
* define the ''UTIL'' user with password = ''forget'' 
* define ''UTILS'' group, add a ''UTIL'' user to the ''UTILS'' group
* grant functions of the ''BTOSRVKICK'' application to the ''UTILS'' group
** as a functions for a ''BTOSRVKICK'' you can use any combination of security rules defined above.
* if no security defined at all it means - all disabled
* if there is something granted of ''BTOSRVKICK'' functions (even if invalid) it means - all that is not disabled directly is enabled

==== Example ====
If we need to:
* disable any BtoSrvKick calls from 192.168.x.x
* disable any calls of ''KRNSSCR2'' 
* disable any ExecSQL calls though the ''BtoSrvKick'' for all except 127.0.0.1

Then we should define something like following:
* define the &quot;HOST-DENY:192.168.*.*&quot; (or short form - &quot;HD:192.168.*.*&quot;) security function for a ''BTOSRVKICK'' application, grant it to a ''UTILS'' group
* define the &quot;SRV-DENY:KRNSSCR2&quot; (or short form - &quot;SD:KRNSSCR2&quot;) security function for a ''BTOSRVKICK'' application, grant it to a ''UTILS'' group
* define the &quot;HOST-FUNC-DENY:*.*.*.*/ExecSQL&quot; (or short form - &quot;HFD:*.*.*.*/ExecSQL&quot;) security function for a ''BTOSRVKICK'' application, grant it to a ''UTILS'' group
* define the &quot;HOST-FUNC-ALLOW:127.*.*.*/ExecSQL&quot; (or short form - &quot;HFA:127.*.*.*/ExecSQL&quot;) security function for a ''BTOSRVKICK'' application, grant it to a ''UTILS'' group

=== Output ===
&lt;pre&gt;
Instance [$01063AA4]: Automation object mode
RedPrairie BTO Server Kick utility. Version 3.3.2.2

Running instance is $01063AA4
 * CSL - successfully connected (10.27.11.79 : 6999, PM=; Sys=, Term=CSLTERM200)

 * HostType is (type # 1; Platform=NT; Endian=Low; FpNum=1)
 * CSL - calling server (KRNSSCR2)...
 * Request is {size=120; {M:R56; P:U020; O:AL4010000; S:; T:SERIAL_TRANSLATE; Fn:; L:; RT:; U:; E: }}
 * CSL - server call finished. Reply is {size=8; {RC=0; Tx=1; Msg=0}}
 * exit code is 13
&lt;/pre&gt;

== Error Codes ==

=== Errorlevel codes ===
  0 - success
  1 - generic utility error
  2 - parameters error
  3 - CSL connection error
  4 - CSL send error
  5 - BTO security error

=== Kick errors ===
In case of Kick command:
  10 - request was sent, RC=ERR, Commited=false.
  11 - request was sent, RC=ERR, Commited=true
  12 - request was sent, RC=OK, Commited=false
  13 - request was sent, RC=OK, Commited=true

=== SQL errors ===
In case of ExecSQL/OpenSQL command:
  12 - SQL error.
  13 - SQL successfully executed/opened.

== Examples ==
&lt;pre&gt;
btosrvkick kick -r=O:AL4010000;T:SERIAL_TRANSLATE -Csl=A:10.27.11.79;P:6999 -S=KRNSSCR2
&lt;/pre&gt;

=== Get Versions of All BTO Server Classes ===
'''Note:''' this will work only with latest BtoSrvKick tool (because old has some bugs with big-reply handling). Latest BtoSrvKick tool supports --max-reply cmdline parameter and it is correctly handling big-replies. Also old version ignored -reply-file cmdline option, so it was impossible to save received reply.

You can use following CMD/BAT-file which should be run on server in &quot;BTO\bin&quot; folder:
&lt;pre&gt;
@echo off

set outputFile=versions.txt
echo.&gt; %outputFile%

for %%A in (*.dll) do (
  echo processing [%%A]...
  if exist reply.bin del /q reply.bin
  BtoSrvKick -s=%%~nA -r=t:$TASKA$;tfn:$VERSION$E; -max-reply=1024 -rplf=reply.bin 
  echo.&gt;&gt; %outputFile%
  copy %outputFile%+reply.bin %outputFile%
  )
&lt;/pre&gt;

It will generate output like this:
&lt;pre&gt;
�HeapChunk=24. Heap=Ok(1). Win32/DB2 by MSVS#1200. Version of [ABSSCHK.DLL] is [9.0.0.1/1.2.3.12]. Built by dbondare on BUILD-N-DEV in D:/R2016A/build at 2016-08-30 13:31:18 Romance Standard Time as part of LTS(Lead Times) module. Build # 9510/216B71D9-A934-4432-B847-B8EDAE8EB38B, category Release, authorization key # 7784.DB2 V9.x supported=1
�HeapChunk=24. Heap=Ok(1). Win32/DB2 by MSVS#1200. Version of [ABSSTOK.DLL] is [9.0.0.1/1.2.3.12]. Built by dbondare on BUILD-N-DEV in D:/R2016A/build at 2016-08-30 13:31:18 Romance Standard Time as part of LTS(Lead Times) module. Build # 9510/216B71D9-A934-4432-B847-B8EDAE8EB38B, category Release, authorization key # 7784.DB2 V9.x supported=1
�HeapChunk=24. Heap=Ok(1). Win32/DB2 by MSVS#1200. Version of [BISSEXP.DLL] is [9.0.0.1/2.1.6.12]. Built by dbondare on BUILD-N-DEV in D:/R2016A/build at 2016-08-30 12:49:14 Romance Standard Time as part of BEX(Business Export) module. Build # 9496/0FC6C004-861B-4403-BF47-520095C283FE, category Release, authorization key # 7770.DB2 V9.x supported=1
�HeapChunk=24. Heap=Ok(1). Win32/DB2 by MSVS#1200. Version of [BISSIMP.DLL] is [9.0.0.1/2.4.4.12]. Built by dbondare on BUILD-N-DEV in D:/R2016A/build at 2016-08-30 12:52:24 Romance Standard Time as part of BIM(Business Import) module. Build # 9497/D575D4E6-C786-4D0B-9078-E1F84F8E2D8E, category Release, authorization key # 7771.DB2 V9.x supported=1
�HeapChunk=24. Heap=Ok(1). Win32/DB2 by MSVS#1200. Version of [DLX70201.DLL] is [9.0.0.1/1.4.18.20]. Built by dbondare on BUILD-N-DEV in D:/R2016A/build at 2016-09-27 16:35:15 Romance Standard Time as part of ORD(Orders) module. Build # 9631/5F49DAD1-FF26-4106-9268-2B22B3B3434A, category Release, authorization key # 7905.DB2 V9.x supported=1
�HeapChunk=24. Heap=Ok(1). Win32/DB2 by MSVS#1200. Version of [DLX70201.DLL] is [9.0.0.1/1.4.18.20]. Built by dbondare on BUILD-N-DEV in D:/R2016A/build at 2016-09-27 16:35:15 Romance Standard Time as part of ORD(Orders) module. Build # 9631/5F49DAD1-FF26-4106-9268-2B22B3B3434A, category Release, authorization key # 7905.DB2 V9.x supported=1
�HeapChunk=24. Heap=Ok(1). Win32/DB2 by MSVS#1200. Version of [EDISEDIF.DLL] is [9.0.0.1/2.4.4.12]. Built by dbondare on BUILD-N-DEV in D:/R2016A/build at 2016-08-30 12:52:24 Romance Standard Time as part of BIM(Business Import) module. Build # 9497/D575D4E6-C786-4D0B-9078-E1F84F8E2D8E, category Release, authorization key # 7771.DB2 V9.x supported=1
�HeapChunk=24. Heap=Ok(1). Win32/DB2 by MSVS#1200. Version of [EDISSPLT.DLL] is [9.0.0.1/2.4.4.12]. Built by dbondare on BUILD-N-DEV in D:/R2016A/build at 2016-08-30 12:52:24 Romance Standard Time as part of BIM(Business Import) module. Build # 9497/D575D4E6-C786-4D0B-9078-E1F84F8E2D8E, category Release, authorization key # 7771.DB2 V9.x supported=1
�HeapChunk=24. Heap=Ok(1). Win32/DB2 by MSVS#1200. Version of [EJIBEDIF.DLL] is [9.0.0.1/2.4.4.12]. Built by dbondare on BUILD-N-DEV in D:/R2016A/build at 2016-08-30 12:52:24 Romance Standard Time as part of BIM(Business Import) module. Build # 9497/D575D4E6-C786-4D0B-9078-E1F84F8E2D8E, category Release, authorization key # 7771.DB2 V9.x supported=1
�HeapChunk=24. Heap=Ok(1). Win32/DB2 by MSVS#1200. Version of [EJISBATA.DLL] is [9.0.0.1/1.4.18.20]. Built by dbondare on BUILD-N-DEV in D:/R2016A/build at 2016-09-27 16:35:15 Romance Standard Time as part of ORD(Orders) module. Build # 9631/5F49DAD1-FF26-4106-9268-2B22B3B3434A, category Release, authorization key # 7905.DB2 V9.x supported=1
�HeapChunk=24. Heap=Ok(1). Win32/DB2 by MSVS#1200. Version of [EJISCLAN.DLL] is [9.0.0.1/1.2.5.14]. Built by dbondare on BUILD-N-DEV in D:/R2016A/build at 2016-08-30 15:10:30 Romance Standard Time as part of CLN(CleanUp) module. Build # 9531/D883D200-6F9B-404E-9217-724A2FB48144, category Release, authorization key # 7805.DB2 V9.x supported=1
�HeapChunk=24. Heap=Ok(1). Win32/DB2 by MSVS#1200. Version of [EJISDD.DLL] is [9.0.0.1/3.5.24.12]. Built by dbondare on BUILD-N-DEV in D:/R2016A/build at 2016-08-30 13:13:11 Romance Standard Time as part of DOC(Documents) module. Build # 9504/EBC84ABB-0093-4917-A86E-C91F2CAE8EB8, category Release, authorization key # 7778.DB2 V9.x supported=1
�HeapChunk=24. Heap=Ok(1). Win32/DB2 by MSVS#1200. Version of [EJISDDDS.DLL] is [9.0.0.1/3.5.24.12]. Built by dbondare on BUILD-N-DEV in D:/R2016A/build at 2016-08-30 13:13:11 Romance Standard Time as part of DOC(Documents) module. Build # 9504/EBC84ABB-0093-4917-A86E-C91F2CAE8EB8, category Release, authorization key # 7778.DB2 V9.x supported=1
�HeapChunk=56. Heap=Ok(1). Win32/DB2 by MSVS#1200. Version of [EJISDDF.DLL] is [9.0.0.1/1.4.3.9]. Built by dbondare on BUILD-N-DEV in D:/R2016A/build at 2016-09-06 14:50:17 Romance Standard Time as part of MDC(Master Data Console) module. Build # 9539/B7B734E3-1F3F-4237-AC7A-3569914E93F2, category Release, authorization key # 7813.DB2 V9.x supported=1
[...]
&lt;/pre&gt;

=== Get Source Code Revisions for All BTO Server Classes ===
&lt;pre&gt;
@echo off

set outputFile=revisions.txt
echo.&gt; %outputFile%

for %%A in (*.dll) do (
  echo processing [%%A]...
  if exist reply.bin del /q reply.bin
  BtoSrvKick -s=%%~nA -r=t:$TASKA$;tfn:$REVISIONS$E; -max-reply=30000 -rplf=reply.bin 
  if exist reply.bin (
    echo.&gt;&gt; %outputFile%
    echo ---------[%%~nA]---------&gt;&gt; %outputFile%
    copy %outputFile%+reply.bin %outputFile%
    echo.&gt;&gt; %outputFile%
    )
  )
&lt;/pre&gt;

It will generate output like this:
&lt;pre&gt;
[...]

---------[EJISPRIV]---------
õ$Date: 2010/03/09 16:53:06Z $ $RCSfile: ntpower.c $ $State: release $ $Author: DBONDARE $ $Revision: 1.10 $ $Locker: $ $Name: R9_0_0_1 $
$Date: 2013/07/12 15:00:11Z $ $RCSfile: ejidpriv.c $ $State: release $ $Author: dbondare $ $Revision: 1.8 $ $Locker: $ $Name: R9_0_0_1 $
$Date: 2009/07/10 10:31:52Z $ $RCSfile: ejifpriv.cpp $ $State: release $ $Author: DBONDARE $ $Revision: 1.14 $ $Locker: $ $Name: R9_0_0_1 $
$Date: 2008/05/08 17:34:07Z $ $RCSfile: ejitpriv.cpp $ $State: release $ $Author: DBONDARE $ $Revision: 1.5 $ $Locker: $ $Name: R9_0_0_1 $
$Date: 2010/03/05 20:13:50Z $ $RCSfile: sysuser.cpp $ $State: release $ $Author: DBONDARE $ $Revision: 1.8 $ $Locker: $ $Name: R9_0_0_1 $
$Date: 2007/01/30 11:10:34Z $ $RCSfile: md5.c $ $State: release $ $Author: DBONDARE $ $Revision: 1.6 $ $Locker: $ $Name: R9_0_0_1 $
$Date: 2008/05/08 17:35:16Z $ $RCSfile: md5crypt.c $ $State: release $ $Author: DBONDARE $ $Revision: 1.5 $ $Locker: $ $Name: R9_0_0_1 $
$Date: 2005/06/17 14:06:58Z $ $RCSfile: encoder.c $ $State: release $ $Author: dbo $ $Revision: 1.8 $ $Locker: $ $Name: R9_0_0_1 KER_3_2_1 $
$Date: 2010/03/05 20:18:16Z $ $RCSfile: Rc4.cpp $ $State: release $ $Author: DBONDARE $ $Revision: 1.2 $ $Locker: $ $Name: R9_0_0_1 $
$Date: 2015/12/16 17:48:23Z $ $RCSfile: strutils.cpp $ $State: release $ $Author: dbondare $ $Revision: 1.54 $ $Locker: $ $Name: R9_0_0_1 $
$Date: 2009/05/07 11:08:25Z $ $RCSfile: inidtab.c $ $State: release $ $Author: DBONDARE $ $Revision: 1.8 $ $Locker: $ $Name: R9_0_0_1 $
$Date: 2015/12/18 09:06:25Z $ $RCSfile: datetime.cpp $ $State: release $ $Author: dbondare $ $Revision: 1.44 $ $Locker: $ $Name: R9_0_0_1 $
$Date: 2015/12/17 04:49:37Z $ $RCSfile: dbglog.c $ $State: release $ $Author: dbondare $ $Revision: 1.26 $ $Locker: $ $Name: R9_0_0_1 $
$Date: 2015/12/19 18:34:11Z $ $RCSfile: srvc.c $ $State: release $ $Author: dbondare $ $Revision: 1.57 $ $Locker: $ $Name: R9_0_0_1 $
$Date: 2008/05/27 16:59:52Z $ $RCSfile: btoaudit.c $ $State: release $ $Author: DBONDARE $ $Revision: 1.3 $ $Locker: $ $Name: R9_0_0_1 $
$Date: 2015/03/19 07:01:30Z $ $RCSfile: xxxfut01.c $ $State: release $ $Author: dbondare $ $Revision: 1.7 $ $Locker: $ $Name: R9_0_0_1 $
$Date: 2013/05/29 17:10:02Z $ $RCSfile: ntlogevt.cpp $ $State: release $ $Author: dbondare $ $Revision: 1.7 $ $Locker: $ $Name: R9_0_0_1 $
$Date: 2010/03/05 11:59:33Z $ $RCSfile: logderr.c $ $State: release $ $Author: dbondare $ $Revision: 1.5 $ $Locker: $ $Name: R9_0_0_1 $
$Date: 2010/03/05 12:49:49Z $ $RCSfile: xntdut01.c $ $State: release $ $Author: dbondare $ $Revision: 1.4 $ $Locker: $ $Name: R9_0_0_1 $
$Date: 2010/03/05 12:31:35Z $ $RCSfile: xxxftime.c $ $State: release $ $Author: dbondare $ $Revision: 1.4 $ $Locker: $ $Name: R9_0_0_1 $
$Date: 2010/03/09 16:53:05Z $ $RCSfile: cextdecs.c $ $State: release $ $Author: DBONDARE $ $Revision: 1.8 $ $Locker: $ $Name: R9_0_0_1 $
$Date: 2010/03/05 11:51:26Z $ $RCSfile: ejiftmf.c $ $State: release $ $Author: dbondare $ $Revision: 1.3 $ $Locker: $ $Name: R9_0_0_1 $
$Date: 2010/03/05 11:55:21Z $ $RCSfile: filflib.c $ $State: release $ $Author: dbondare $ $Revision: 1.5 $ $Locker: $ $Name: R9_0_0_1 $
$Date: 2010/03/05 13:32:27Z $ $RCSfile: createpr.cpp $ $State: release $ $Author: DBONDARE $ $Revision: 1.11 $ $Locker: $ $Name: R9_0_0_1 $
$Date: 2015/02/24 16:06:24Z $ $RCSfile: xxxtuxdl.cpp $ $State: release $ $Author: dbondare $ $Revision: 1.13 $ $Locker: $ $Name: R9_0_0_1 $
$Date: 2015/07/15 14:17:10Z $ $RCSfile: ntlogwrt.cpp $ $State: release $ $Author: dbondare $ $Revision: 1.14 $ $Locker: $ $Name: R9_0_0_1 $

[...]

---------[PDISHKEP]---------
ô�
$Date: 2016/02/09 11:53:35Z $ $RCSfile: pdiFhkep.cpp $ $State: Exp $ $Author: dbondare $ $Revision: 1.9 $ $Locker: $ $Name: $
$Date: 2016/09/26 11:33:17Z $ $RCSfile: pdiOengn.cpp $ $State: release $ $Author: dbondare $ $Revision: 1.186 $ $Locker: $ $Name: R9_0_0_1 $
$Date: 2016/09/16 13:43:05Z $ $RCSfile: pdiOshpl.cpp $ $State: release $ $Author: dbondare $ $Revision: 1.55 $ $Locker: $ $Name: R9_0_0_1 $
$Date: 2016/07/11 08:25:27Z $ $RCSfile: pdiOsytk.cpp $ $State: release $ $Author: dbondare $ $Revision: 1.31 $ $Locker: $ $Name: R9_0_0_1 $
$Date: 2016/06/17 11:05:13Z $ $RCSfile: pdiOmd.cpp $ $State: release $ $Author: dbondare $ $Revision: 1.13 $ $Locker: $ $Name: R9_0_0_1 $
$Date: 2016/08/30 15:36:23Z $ $RCSfile: pdiOrtd.cpp $ $State: release $ $Author: dbondare $ $Revision: 1.145 $ $Locker: $ $Name: R9_0_0_1 $
$Date: 2016/07/01 09:47:04Z $ $RCSfile: pdiOpcal.cpp $ $State: release $ $Author: dbondare $ $Revision: 1.21 $ $Locker: $ $Name: R9_0_0_1 $
$Date: 2016/06/17 09:40:47Z $ $RCSfile: krnOcumd.cpp $ $State: Exp $ $Author: dbondare $ $Revision: 1.11 $ $Locker: $ $Name: $
$Date: 2015/05/27 12:47:14Z $ $RCSfile: krnOord.cpp $ $State: Exp $ $Author: dbondare $ $Revision: 1.3 $ $Locker: $ $Name: $
$Date: 2016/06/17 09:42:39Z $ $RCSfile: pdidmd.c $ $State: release $ $Author: dbondare $ $Revision: 1.16 $ $Locker: $ $Name: R9_0_0_1 $
$Date: 2016/06/08 15:19:10Z $ $RCSfile: pdidrtd.c $ $State: release $ $Author: dbondare $ $Revision: 1.57 $ $Locker: $ $Name: R9_0_0_1 $
$Date: 2016/07/01 09:46:16Z $ $RCSfile: pdidpcal.c $ $State: release $ $Author: dbondare $ $Revision: 1.11 $ $Locker: $ $Name: R9_0_0_1 $
$Date: 2016/06/17 09:41:03Z $ $RCSfile: krndcumd.c $ $State: Exp $ $Author: dbondare $ $Revision: 1.7 $ $Locker: $ $Name: $
$Date: 2015/05/27 12:46:51Z $ $RCSfile: krndord.c $ $State: Exp $ $Author: dbondare $ $Revision: 1.4 $ $Locker: $ $Name: $
$Date: 2013/01/17 19:57:45Z $ $RCSfile: comdnrs.c $ $State: Exp $ $Author: dbondare $ $Revision: 1.10 $ $Locker: $ $Name: $
$Date: 2009/05/07 11:08:25Z $ $RCSfile: inidtab.c $ $State: Exp $ $Author: DBONDARE $ $Revision: 1.8 $ $Locker: $ $Name: $
$Date: 2009/05/07 18:06:13Z $ $RCSfile: srvsync.c $ $State: Exp $ $Author: DBONDARE $ $Revision: 1.3 $ $Locker: $ $Name: $
$Date: 2015/08/05 16:02:10Z $ $RCSfile: syncer.cpp $ $State: Exp $ $Author: dbondare $ $Revision: 1.7 $ $Locker: $ $Name: $
$Date: 2015/08/06 15:21:56Z $ $RCSfile: BtoTask.cpp $ $State: Exp $ $Author: dbondare $ $Revision: 1.11 $ $Locker: $ $Name: $
$Date: 2012/05/21 16:11:54Z $ $RCSfile: clss.cpp $ $State: Exp $ $Author: dbondare $ $Revision: 1.47 $ $Locker: $ $Name: $
$Date: 2015/12/18 09:06:25Z $ $RCSfile: datetime.cpp $ $State: Exp $ $Author: dbondare $ $Revision: 1.44 $ $Locker: $ $Name: $
$Date: 2015/12/17 04:49:37Z $ $RCSfile: dbglog.c $ $State: Exp $ $Author: dbondare $ $Revision: 1.26 $ $Locker: $ $Name: $
$Date: 2015/08/05 11:35:53Z $ $RCSfile: except.cpp $ $State: Exp $ $Author: dbondare $ $Revision: 1.21 $ $Locker: $ $Name: $
$Date: 2015/12/19 18:34:11Z $ $RCSfile: srvc.c $ $State: Exp $ $Author: dbondare $ $Revision: 1.57 $ $Locker: $ $Name: $
$Date: 2015/12/16 17:48:23Z $ $RCSfile: strutils.cpp $ $State: Exp $ $Author: dbondare $ $Revision: 1.54 $ $Locker: $ $Name: $
$Date: 2014/11/20 11:16:36Z $ $RCSfile: srvdcfg.c $ $State: Exp $ $Author: dbondare $ $Revision: 1.5 $ $Locker: $ $Name: $
$Date: 2014/11/06 11:57:18Z $ $RCSfile: srvocfg.cpp $ $State: Exp $ $Author: dbondare $ $Revision: 1.4 $ $Locker: $ $Name: $
$Date: 2015/07/01 15:00:38Z $ $RCSfile: timemeas.cpp $ $State: Exp $ $Author: dbondare $ $Revision: 1.31 $ $Locker: $ $Name: $
$Date: 2015/07/01 14:25:53Z $ $RCSfile: xdom.cpp $ $State: Exp $ $Author: dbondare $ $Revision: 1.21 $ $Locker: $ $Name: $
$Date: 2005/06/17 14:04:10Z $ $RCSfile: d5compat.cpp $ $State: Exp $ $Author: dbo $ $Revision: 1.3 $ $Locker: $ $Name: KER_3_2_1 $
$Date: 2015/03/04 09:25:32Z $ $RCSfile: dtit.cpp $ $State: Exp $ $Author: dbondare $ $Revision: 1.47 $ $Locker: $ $Name: $
$Date: 2016/01/27 16:22:42Z $ $RCSfile: dtitex.cpp $ $State: Exp $ $Author: dbondare $ $Revision: 1.21 $ $Locker: $ $Name: $
$Date: 2005/06/17 14:06:58Z $ $RCSfile: encoder.c $ $State: Exp $ $Author: dbo $ $Revision: 1.8 $ $Locker: $ $Name: KER_3_2_1 $
$Date: 2005/06/17 14:08:04Z $ $RCSfile: xvarconv.cpp $ $State: Exp $ $Author: dbo $ $Revision: 1.20 $ $Locker: $ $Name: KER_3_2_1 $
$Date: 2013/05/29 17:10:02Z $ $RCSfile: ntlogevt.cpp $ $State: Exp $ $Author: dbondare $ $Revision: 1.7 $ $Locker: $ $Name: $
$Date: 2010/03/05 11:59:33Z $ $RCSfile: logderr.c $ $State: Exp $ $Author: dbondare $ $Revision: 1.5 $ $Locker: $ $Name: $
$Date: 2011/09/19 17:20:57Z $ $RCSfile: tsktopt^R2007.c $ $State: Exp $ $Author: dbondare $ $Revision: 1.13 $ $Locker: $ $Name: $
$Date: 2013/06/17 17:18:44Z $ $RCSfile: tuxtapi.c $ $State: Exp $ $Author: dbondare $ $Revision: 1.11 $ $Locker: $ $Name: $
$Date: 2010/03/09 17:37:42Z $ $RCSfile: tskdapi.c $ $State: Exp $ $Author: DBONDARE $ $Revision: 1.8 $ $Locker: $ $Name: $
$Date: 2010/03/09 16:53:06Z $ $RCSfile: ntpower.c $ $State: Exp $ $Author: DBONDARE $ $Revision: 1.10 $ $Locker: $ $Name: $
$Date: 2015/03/19 07:01:30Z $ $RCSfile: xxxfut01.c $ $State: Exp $ $Author: dbondare $ $Revision: 1.7 $ $Locker: $ $Name: $
$Date: 2010/03/05 12:49:49Z $ $RCSfile: xntdut01.c $ $State: Exp $ $Author: dbondare $ $Revision: 1.4 $ $Locker: $ $Name: $
$Date: 2010/03/05 12:31:36Z $ $RCSfile: xxxoutil.c $ $State: Exp $ $Author: dbondare $ $Revision: 1.4 $ $Locker: $ $Name: $
$Date: 2010/03/05 12:31:35Z $ $RCSfile: xxxfnult.c $ $State: Exp $ $Author: dbondare $ $Revision: 1.3 $ $Locker: $ $Name: $
$Date: 2015/02/24 16:06:24Z $ $RCSfile: xxxtuxdl.cpp $ $State: Exp $ $Author: dbondare $ $Revision: 1.13 $ $Locker: $ $Name: $
$Date: 2010/03/05 12:31:35Z $ $RCSfile: xxxftime.c $ $State: Exp $ $Author: dbondare $ $Revision: 1.4 $ $Locker: $ $Name: $
$Date: 2010/03/09 16:53:05Z $ $RCSfile: cextdecs.c $ $State: Exp $ $Author: DBONDARE $ $Revision: 1.8 $ $Locker: $ $Name: $
$Date: 2010/03/05 11:51:26Z $ $RCSfile: ejiftmf.c $ $State: Exp $ $Author: dbondare $ $Revision: 1.3 $ $Locker: $ $Name: $
$Date: 2010/03/05 11:55:21Z $ $RCSfile: filflib.c $ $State: Exp $ $Author: dbondare $ $Revision: 1.5 $ $Locker: $ $Name: $
$Date: 2010/03/05 13:32:27Z $ $RCSfile: createpr.cpp $ $State: Exp $ $Author: DBONDARE $ $Revision: 1.11 $ $Locker: $ $Name: $
$Date: 2015/07/15 14:17:10Z $ $RCSfile: ntlogwrt.cpp $ $State: release $ $Author: dbondare $ $Revision: 1.14 $ $Locker: dbondare $ $Name: R9_0_0_1 $

[...]

---------[SQLSDYNA]---------
L�
$Date: 2012/10/25 15:18:37Z $ $RCSfile: sqlftcpnt.c $ $State: Exp $ $Author: dbondare $ $Revision: 1.15 $ $Locker: $ $Name: $
$Date: 2015/12/17 04:49:37Z $ $RCSfile: dbglog.c $ $State: Exp $ $Author: dbondare $ $Revision: 1.26 $ $Locker: $ $Name: $
$Date: 2009/05/07 11:08:25Z $ $RCSfile: inidtab.c $ $State: Exp $ $Author: DBONDARE $ $Revision: 1.8 $ $Locker: $ $Name: $
$Date: 2015/07/01 15:00:38Z $ $RCSfile: timemeas.cpp $ $State: Exp $ $Author: dbondare $ $Revision: 1.31 $ $Locker: $ $Name: $
$Date: 2013/05/29 17:10:02Z $ $RCSfile: ntlogevt.cpp $ $State: Exp $ $Author: dbondare $ $Revision: 1.7 $ $Locker: $ $Name: $
$Date: 2010/03/05 11:59:33Z $ $RCSfile: logderr.c $ $State: Exp $ $Author: dbondare $ $Revision: 1.5 $ $Locker: $ $Name: $
$Date: 2010/03/09 16:53:06Z $ $RCSfile: ntpower.c $ $State: Exp $ $Author: DBONDARE $ $Revision: 1.10 $ $Locker: $ $Name: $
$Date: 2013/05/10 13:20:29Z $ $RCSfile: sqldstab.cpp $ $State: Exp $ $Author: dbondare $ $Revision: 1.14 $ $Locker: $ $Name: $
$Date: 2013/05/10 13:19:44Z $ $RCSfile: sqldbrow.cpp $ $State: Exp $ $Author: dbondare $ $Revision: 1.16 $ $Locker: $ $Name: $
$Date: 2015/07/01 14:25:53Z $ $RCSfile: xdom.cpp $ $State: Exp $ $Author: dbondare $ $Revision: 1.21 $ $Locker: $ $Name: $
$Date: 2015/12/16 17:48:23Z $ $RCSfile: strutils.cpp $ $State: Exp $ $Author: dbondare $ $Revision: 1.54 $ $Locker: $ $Name: $
$Date: 2008/12/17 09:56:10Z $ $RCSfile: dynautil.c $ $State: Exp $ $Author: DBONDARE $ $Revision: 1.3 $ $Locker: $ $Name: $
$Date: 2015/12/19 18:34:11Z $ $RCSfile: srvc.c $ $State: Exp $ $Author: dbondare $ $Revision: 1.57 $ $Locker: $ $Name: $
$Date: 2015/03/19 07:01:30Z $ $RCSfile: xxxfut01.c $ $State: Exp $ $Author: dbondare $ $Revision: 1.7 $ $Locker: $ $Name: $
$Date: 2010/03/05 12:49:49Z $ $RCSfile: xntdut01.c $ $State: Exp $ $Author: dbondare $ $Revision: 1.4 $ $Locker: $ $Name: $
$Date: 2015/02/24 16:06:24Z $ $RCSfile: xxxtuxdl.cpp $ $State: Exp $ $Author: dbondare $ $Revision: 1.13 $ $Locker: $ $Name: $
$Date: 2010/03/05 12:31:35Z $ $RCSfile: xxxftime.c $ $State: Exp $ $Author: dbondare $ $Revision: 1.4 $ $Locker: $ $Name: $
$Date: 2010/03/09 16:53:05Z $ $RCSfile: cextdecs.c $ $State: Exp $ $Author: DBONDARE $ $Revision: 1.8 $ $Locker: $ $Name: $
$Date: 2010/03/05 11:51:26Z $ $RCSfile: ejiftmf.c $ $State: Exp $ $Author: dbondare $ $Revision: 1.3 $ $Locker: $ $Name: $
$Date: 2010/03/05 11:55:21Z $ $RCSfile: filflib.c $ $State: Exp $ $Author: dbondare $ $Revision: 1.5 $ $Locker: $ $Name: $
$Date: 2010/03/05 13:32:27Z $ $RCSfile: createpr.cpp $ $State: Exp $ $Author: DBONDARE $ $Revision: 1.11 $ $Locker: $ $Name: $
$Date: 2015/07/15 14:17:10Z $ $RCSfile: ntlogwrt.cpp $ $State: release $ $Author: dbondare $ $Revision: 1.14 $ $Locker: dbondare $ $Name: R9_0_0_1 $

[...]

&lt;/pre&gt;

== Notes ==
Please use [[PlantCalendar]] if you do not need dynamic parameters.&lt;br&gt;

This has to be run from a project client folder, since it uses the CSL* components from there.

== Known Issues ==
=== Utility Logon Failure ===
If utility reports &quot;Utility logon failure!&quot; error it maybe caused by expired password for the ''UTILS'' group.

To check this please use following approach:
* grant app=QUERY, function=QUERY-R permission to a ''UTILS'' group 
* start ''Query.exe'' and login as ''UTIL'' user
If there are any login problems you will see it.

It is recommended to set PasswordExpiration interval for the ''UTILS'' group to ''99999 days'' to avoid such issues.
Newer BTO releases (starting from 6.3sp2) assume that expiration=0 days 0 hours 0 mins means ''password expiration check'' disabled. 


== Audit Log ==
Latest version of ''BtoSrvKick'' writing data to ''AuditLog''. Example:
&lt;pre&gt;
TSTAMP=2010-06-08:17:56:51.970256
ACTION=301
USERID=UTIL
CLIENT=BtoSrvKick.exe/3.3.1.59
CLASSID=SrvCall
SUBJECT={P4520/DBONDARE@DOM1/10.27.2.4=CPHNBDBOND}
DESCR=(MLNX/PLNX)-&gt;KRNSSCR2[MYTASKX](123/ZZ/) as
&lt;/pre&gt;

It write a record to ''AuditLog'' before doing any action, so in case if system hang/lock/wait you can execute query with &quot;browse access&quot; over ''AuditLog'' and see if it could be caused by ''BtoSrvKick''.

== Installations ==

{| border=&quot;1&quot;  cellpadding=&quot;5&quot; cellspacing=&quot;0&quot; style=&quot;text-align: center; 
|- style=&quot;background:#dfefdf;&quot;
! Customer
! Site
! Version
! Usage
|-
| BWI || BMW Mini, Luton, UK || N/A || VBScript triggering processing of serial-no (create inventory)
|- 
| Delphi || Audi C7, SNM, RO || 3.x.y.z || Send events from Offline Station based on created file, to server when user click a button
|-
| Magna || Ford Transit, Gulcuk, TR  || ServerTest&lt;sup&gt;1&lt;/sup&gt; x.y || Trigger reports from Windows Scheduler&lt;sup&gt;2&lt;/sup&gt;
|-
| Magna || ??, Poznan, PL || 6.3.0.10 || Used to call back-flush once a day, also to call export and cleanup 4 times a day (between shifts)
|}

1: This is old version, must be replaced ASAP&lt;br&gt;
2: This use should be replaced with Plant Calendar, pending customer review&lt;br&gt;

== See also ==
* [[PlantCalendar|BTO Plant Calender]] for triggering regular events.</text>
    </revision>
  </page>
  <page>
    <title>Bto Test Environments</title>
    <id>239</id>
    <revision>
      <id>2709</id>
      <timestamp>2010-09-03T09:01:11Z</timestamp>
      <contributor>
        <username>Dbondare</username>
        <id>4</id>
      </contributor>
      <minor/>
      <text xml:space="preserve">== Windows + DB2 v8.x ==
It is an BTO-TEST-ENV8 VM (10.27.2.6). 

There are a number of different BTO releases running side-by-side:

* &lt;u&gt;'''6.3'''&lt;/u&gt;
** cslmon port 6301, management console on port 6108
** dbname=P6301
** location=D:\BTO63A
** executor name = executor-63a.exe

* &lt;u&gt;'''6.3 sp2'''&lt;/u&gt;
** cslmon port 6302, management console port 6309
** dbname=PT63B
** location=D:\BTO63B
** executor name = executor-63b.exe

* &lt;u&gt;'''2007.2'''&lt;/u&gt;
** cslmon port 20072, management console port 20079
** dbname=PT2K7B
** location=D:\BTO2007B
** executor name = executor-2k7.exe

* &lt;u&gt;'''2009.1'''&lt;/u&gt;
** cslmon port 20091, management console on port 20099
** dbname=BTO2K9
** location=D:\BTO2009A
** executor name = executor-2k9.exe

* &lt;u&gt;'''2010.1'''&lt;/u&gt;
** cslmon port 20101, management console on port 20109
** dbname=PT2010
** location=D:\BTO2010A
** executor name = executor-2kA.exe
'''Note:''' it is running in the ''config-in-database'' mode.

* &lt;u&gt;'''Development release (for experimenting and so on)'''&lt;/u&gt;
** cslmon port 6100, management console on port 6109
** dbname=DEVX
** location=D:\PowerB2O
** executor name = executor-b2o.exe

== Windows + DB2 v9.x ==
It is an BTO-TEST-ENV9 VM (10.27.2.9). 

There are a number of different BTO releases running side-by-side - see a summary table below.

If you need such environment pls let me ([[user:dbondare]]) know so I can prepare it.

== Summary Table ==
[[File:Bto-test-envs.png]]

[[Category:Development]]</text>
    </revision>
  </page>
  <page>
    <title>Build-to-order</title>
    <id>8</id>
    <revision>
      <id>1667</id>
      <timestamp>2010-05-20T11:19:01Z</timestamp>
      <contributor>
        <username>Dbondare</username>
        <id>4</id>
      </contributor>
      <minor/>
      <text xml:space="preserve">==Definition==
Building and delivering a product based upon a customer-specific order. Pull is a core concept of Build-To-Order. Build-To-Order is a significant trend in the automotive industry for Original Equipment Manufacturers to fulfill individual customer requirements. The case for Build-To-Order is broadly accepted in Europe; however, the challenge is to build to order with reliable and reasonable Lead-times that most consumers find acceptable. Most Original Equipment Manufacturers have declared their intention to cut [[Order-To-Delivery]] [[Lead-times|lead-time] and increase the proportion of vehicles built to order. Ford’s “Order-To-Delivery” target is 15 days, Volkswagen’s “Kunde-Kunde” target is 14 days and BMW’s “Kundenorientierter Vertriebs-und Produktionsprozess (KOVP)” target is 10 days. Nissan is the first Japanese manufacturer in Europe to follow this path with its “SCOPE” project. [[RedPrairie BTO]] is a true pull-based system, developed for Build-To-Order requirements and aimed at cutting [[Order-To-Delivery]] [[Lead-times|lead-time]].

==Synonyms==
* BTO
* B2O


[[Category:Releases]]
[[Category:Glossary]]</text>
    </revision>
  </page>
</mediawiki>
